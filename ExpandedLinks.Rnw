\documentclass[10pt]{article}
\usepackage{xspace,colortbl,comment}
\usepackage{overcite,setspace,rotating,newcent,url,hyperref}
\usepackage[color=green!10,textsize=footnotesize]{todonotes}
\usepackage{listings}
\lstloadlanguages{SAS}
\lstset{basicstyle=\footnotesize,keywordstyle=\color{blue},showstringspaces=false,commentstyle=\color{red}}

\setlength{\parindent}{0em}
\setlength{\parskip}{2ex}
\setlength{\topmargin}{-0.5in}
\setlength{\textheight}{9.0in}
\setlength{\textwidth}{6.0in}
\setlength{\oddsidemargin}{0.25in}

\raggedright
\makeatletter \renewcommand\@biblabel[1]{#1.} \makeatother

\setcounter{secnumdepth}{0}

\setlength{\marginparwidth}{1in}

\newcommand\bvm{\begin{verbatim}}
\newcommand\evm{\end{verbatim}}
\newcommand\bfs{\begin{footnotesize}}
\newcommand\efs{\end{footnotesize}}
\newcommand\rr{\raggedright}

\specialcomment{detail}{\rule{1ex}{1ex}\hspace{1ex}\rule{1ex}{1ex}\begin{small}
   {\it begin analysis details}\\}
   {\rule{1ex}{1ex}{\it \ end analysis details}\end{small}}

\begin{document}
%\excludecomment{detail}
\pagestyle{myheadings}

\section{Create expanded linked CHARS and death files}

Eric Ossiander\\
\today

This describes how I created the expanded linked chars-death
files. The expanded files have the all the deaths occurring in 2010,
2011, and 2012 linked to the CHARS records for 2009--2012. The first
parts of this document describes the production of the standard DIHD
files, which contain the deaths for each year 2010, 2011, and 2012
linked to the hospitalizations occurring in the year of death and the
previous year. To create the expanded files, I only need to link the
2012 deaths to the 2009 and 2010 CHARS records, and link the 2011
deaths to the 2009 CHARS records, and then to combine those links with
the standard DIHD files.

I used the following fields in the linking process:

\begin{tabular}{l}
birth date \\
name       \\
last 4 digits of SSN \\
sex                  \\
zipcode of residence \\
county of residence  \\
hospital code        \\
death date           \\
Hispanic ethnicity   \\
race                 \\
state of residence   \\
\end{tabular}

I used the
RecordLinkage package in R for most of the linking. In all of the record
linking that I did in R, I used birth date as a blocking field (i.e. I
required that the birth date on the death certificate match the birth
date on the hospitalization record). First, I computed
a probabilistic linkage weight for each record pair. Second, I used a
machine learning algorithm to predict which record pairs were links.
(This required me to manually code a training set once, to create a
statistical model for predicting links. Then I used the statistical
model for each subsequent year of data.) Then I manually reviewed all
of the record pairs which were
predicted not to be a link by the machine learning algorithm, but
which had a high probabilistic weight, and all
record pairs which were predicted to be a link, but had a low weight. I
also used a SAS program to compute a probabilistic linkage weight for
all record pairs (i.e. not blocking on birth date), and manually
reviewed all of the record pairs that had a high probabilistic weight
 in which the death certificate birth
date did not match the hospitalization birth date. I combined the
three linked sets (the machine-linked pairs, the manual review of the
machine linking, and the manual coding of the non-birth date matching
pairs). Then I checked for hospitalization records that linked to
more than one death record, and manually adjudicated those links.


\begin{detail}

\subsection{Process}

\subsubsection{Death file}

Items that help identify people in the death file

\begin{tabular}{l}
name \\
dob \\
social security number\\
age at death \\
date of death \\
sex \\
race, ethnicity \\
place of residence (address, county, zipcode) \\
place of death (county, city, facility, facility type \\
\end{tabular}

These items are split between the public use file and the death names
file, so I will need to combine those files and extract the relevant fields.

\subsubsection{CHARS file}

items that help identify people in the CHARS file

\begin{tabular}{l}
name \\
dob \\
social security number (last 4 digits) \\
age \\
sex \\
race, ethnicity \\
discharge date \\
discharge status \\
hospital code \\
place of residence (zipcode and county)
\end{tabular}

All of these items are in the confidential files (names {\tt
  chr\_r2012.sas7bdat}, etc).

It looks like names are present on a few records in 2008, and on
almost all records in 2009 and following years. In 2007 and earlier
(and in the 2008 records that don't have names), first two letters of
names are on the files. Birthdates are apparently on all files. SSN is
two-thirds missing in 2008, better in 2009, and about 20\% missing in
2012. It is almost entirely missing in 2007. Race is reported on about
40\% of 2008 records, very few before that year, and almost all
records after that year.

\subsubsection{linking}

If the availability of birth date is good on both files, I will study
whether that can be used for blocking. After that I will probably use
these for linking:

\begin{tabular}{ll}
death          & CHARS \\ \hline
name           & name  \\
first 2 chars  & first 2 chars \\
soundex(name)  & soundex(name) \\
SSN (last 4)   & SSN   \\
sex            & sex   \\
race           & race  \\
hispanic       & hispanic \\
zipcode of res & zipcode of res \\
county of res  & county of res (unless this is only derived from
zipcode)\\
facility code  & hospital code \\
place of death & hospital location (unless facility code-hospital code
link makes this redundant) \\
\end{tabular}

\subsection{Create death file}

The death file items that I can use for linking are split across the statistical
file and the names file. Here, I combine the two files, keeping certificate
number and the items I will use in linking.

\begin{lstlisting}[language=sas,caption=create death file for linking]
Steps:
1. read the death file with names
2. merge with standard death file to add dob, age, sex, race,
*/
/*
Step 1. read the death file with names
*/
data names;
   infile "c:\data\death\deathnames\deathnamesv3.2012" lrecl=241;
   input
      @1   certno     $char10.
      @11  lastname   $char50.
      @61  firstname  $char30.
      @91  middlename $char40.
      @131 suffix     $char4.
      @142 ssnL4      $char4.
      @146 street     $char35.
      @181 city       $char30.
      @213 statecode  $char2.
      ;
run;
/*
Step 2. merge with standard death file
*/
proc sort data=names;
   by certno;
run;
proc sort data=death.dea2012
      out=stats(keep=certno age dob sex cnty_res zipcode dth_date race_wht race_blk
      race_ami race_asi race_chi race_fil race_gua race_haw race_jap race_kor
      race_opi race_oas race_oth race_sam race_vie hisp zipcode facility fac_type);
   by certno;
run;
/*
combine statistical and name files, and recode race fields to match the reduced
set in the CHARS file (which has only white, black, american indian or alaska
native, asian, hawaiian or other Pacific Islander)
*/
data dwnames(drop=sum_race_asi sum_race_haw race_temp1 race_temp2 race_chi race_fil
          race_gua race_jap race_kor race_opi race_oas race_oth race_sam
          race_vie firsttemp lasttemp middlename hisp firsttemp2 lasttemp2);
   length firstname lastname $ 20 miname hispanic $ 1 lastname_sdx firstname_sdx $ 4
          firsttemp2 lasttemp2 $ 25;
   merge stats(rename=(race_asi=race_temp1 race_haw=race_temp2))
         names(rename=(firstname=firsttemp lastname=lasttemp));
   by certno;
   firsttemp2 = compress(firsttemp," '`-_,.&");
   lasttemp2  = compress(lasttemp," '`-_,.&");
   firstname = substr(firsttemp2,1,20);
   lastname  = substr(lasttemp2,1,20);
   miname    = substr(middlename,1,1);
   sum_race_asi = min(1,(race_chi='Y')+(race_fil='Y')+(race_jap='Y')+(race_kor='Y')+
                    (race_oas='Y')+(race_vie='Y')+(race_temp1='Y'));
   sum_race_haw = min(1,(race_gua='Y')+(race_opi='Y')+(race_sam='Y')+(race_temp2='Y'));

   if sum_race_asi = 0 then race_asi = 'N';
   else                     race_asi = 'Y';
   if sum_race_haw = 0 then race_haw = 'N';
   else                     race_haw = 'Y';
   if race_ami in ('') then race_ami = 'U';
   if race_asi in ('') then race_asi = 'U';
   if race_blk in ('') then race_blk = 'U';
   if race_haw in ('') then race_haw = 'U';
   if race_wht in ('') then race_wht = 'U';
   select(hisp);
      when('0')                 hispanic = 'N';
      when('1','2','3','4','5') hispanic = 'Y';
      when('','9')              hispanic = 'U';
      end;
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);

   format dob mmddyy10.;
run;
\end{lstlisting}

\subsection{Create CHARS file}


\begin{lstlisting}[language=sas,caption=Create CHARS file for linking]
proc format;
   value $stateres
     'AL' = '01'
     'AK' = '02'
     'AZ' = '03'
     'AR' = '04'
     'CA' = '05'
     'CO' = '06'
     'CT' = '07'
     'DE' = '08'
     'DC' = '09'
     'FL' = '10'
     'GA' = '11'
     'HI' = '12'
     'ID' = '13'
     'IL' = '14'
     'IN' = '15'
     'IA' = '16'
     'KS' = '17'
     'KY' = '18'
     'LA' = '19'
     'ME' = '20'
     'MD' = '21'
     'MA' = '22'
     'MI' = '23'
     'MN' = '24'
     'MS' = '25'
     'MO' = '26'
     'MT' = '27'
     'NE' = '28'
     'NV' = '29'
     'NH' = '30'
     'NJ' = '31'
     'NM' = '32'
     'NY' = '33'
     'NC' = '34'
     'ND' = '35'
     'OH' = '36'
     'OK' = '37'
     'OR' = '38'
     'PA' = '39'
     'RI' = '40'
     'SC' = '41'
     'SD' = '42'
     'TN' = '43'
     'TX' = '44'
     'UT' = '45'
     'VT' = '46'
     'VA' = '47'
     'WA' = '48'
     'WV' = '49'
     'WI' = '50'
     'WY' = '51'
     'PR' = '52'
     'VI' = '53'
     'GU' = '54'
     'AS' = '60'
     'MP' = '69'
      ;
run;
data clink1112(keep=seq_no_enc adm_date age country countyres dis_date dob firstname
                ssnL4 hispanic hospital lastname miname race_ami race_asi race_blk
                race_haw race_wht sex statecode status zipcode zipplus4
                lastname_sdx firstname_sdx suffix);
   length firstname lastname $ 20 suffix $ 4 lastname_sdx firstname_sdx $ 4 statecode $ 2;
   set chars.chr_r2011(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp))
       chars.chr_r2012(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp));
   if race_ami in ('','R') then race_ami = 'U';
   if race_asi in ('','R') then race_asi = 'U';
   if race_blk in ('','R') then race_blk = 'U';
   if race_haw in ('','R') then race_haw = 'U';
   if race_wht in ('','R') then race_wht = 'U';
   if hispanic in ('','R') then hispanic = 'U';
/*
remove the suffixes II, III, IV, V, VI, VII, VIII, ESQ, JR, and SR
from lastnames and place them in a separate suffix field.
Used with UB04 data.
*/
   if _N_ = 1 then do;
   	retain __re __reIII;
   	pattern = "/( II| III| IV| V| VI| VII| VIII| ESQ|.JR|.SR)$/i";
   	__re = prxparse(pattern);
   	__reIII = prxparse('/III$/');
   end;
   lasttemp = translate(lasttemp,' ','.,');
   call prxsubstr(__re, TRIM(lasttemp), position, length);
   if position ^= 0 then do;
   	suffix    = substr(lasttemp, position + 1, length - 1);
   	lasttemp2 = substr(lasttemp, 1, position - 1);
   end;
   else lasttemp2 = lasttemp;

   firstname = compress(firsttemp," '`-_,.&");
   lastname  = compress(lasttemp2," '`-_,.&");
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);
   statecode = put(stateres,$stateres.);
   if not ('01' le statecode le '69') then statecode = '99';
run;
\end{lstlisting}

\subsection{Test birthdate as a blocking field}

I will use a SAS program to compute a linkage score for every pair of records in
the match between the 2012 death file and 2012 CHARS file. I will evaluate the
scores to see if there are any high scores for pairs in which the birthdate does
not match. If there are not any such pairs, then birthdate is a good blocking
field. I might also evaluate last name in the same way.

Fields I will use, and the points I will give for a matching value are:

\begin{tabular}{lll}
item        &  match                    &  different \\ \hline
age         &   5                       &    -5      \\
birthdate   &  20                       &    -20     \\
firstname   &  10 (2 for soundex match) &    -10     \\
lastname    &  15 (4 for soundex)       &    -15     \\
middleinit  &   2                       &    -3      \\
sex         &   2                       &    -20     \\
zipcode     &   3                       &    -2      \\
county      &   3                       &    -5      \\
ssnL4       &  15                       &    -10     \\
race\_ami   &   5                       &    -5      \\
race\_asi   &   5                       &    -5      \\
race\_blk   &   5                       &    -5      \\
race\_haw   &   5                       &    -5      \\
race\_wht   &   5                       &    -5      \\
hispanic    &   5                       &    -5      \\
statecode   &   1                       &    -5      \\
deathdate   &  10                       &    -10     \\
hospital    &   5                       &    -10     \\ \hline
\end{tabular}

\begin{lstlisting}[language=sas,caption=compute test link scores]
libname dihd 'c:\data\dihd';

/*
For each record, I will evaluate its similarity with each of the other records
by computing a score using the points described above. In the output dataset,
I will keep records that have a score of at least 0.
Maximum score is 112.
*/
data dihd.link2012;
   set clink1112(rename=(
     age           = c_age
     countyres     = c_cnty_res
     dob           = c_dob
     firstname     = c_firstname
     hispanic      = c_hispanic
     lastname      = c_lastname
     miname        = c_miname
     race_ami      = c_race_ami
     race_asi      = c_race_asi
     race_blk      = c_race_blk
     race_haw      = c_race_haw
     race_wht      = c_race_wht
     sex           = c_sex
     zipcode       = c_zipcode
     firstname_sdx = c_firstname_sdx
     lastname_sdx  = c_lastname_sdx
     ssnl4         = c_ssnl4
     statecode     = c_statecode
     ));
   do i = 1 to 51241;
      set dwnames point=i;
      score =
      (age           = c_age           and age          ne .)*5  +
      (age           ne c_age          )*(-5) +
      (cnty_res      = c_cnty_res      and cnty_res     ne '')*3  +
      (cnty_res      ne c_cnty_res     )*(-5) +
      (dob           = c_dob           and dob          ne .)*20  +
      (dob           ne c_dob          )*(-20) +
      (firstname     = c_firstname     and firstname    ne '')*10  +
      (firstname     ne c_firstname    )*(-10) +
      (hispanic      = c_hispanic      and hispanic     ne '')*5  +
      (hispanic      ne c_hispanic     )*(-5) +
      (lastname      = c_lastname      and lastname     ne '')*15  +
      (lastname      ne c_lastname     )*(-15) +
      (miname        = c_miname        and miname       ne '')*2  +
      (miname        ne c_miname       )*(-3) +
      (race_ami      = c_race_ami      and race_ami     ne '')*5  +
      (race_ami      ne c_race_ami     )*(-5) +
      (race_asi      = c_race_asi      and race_asi     ne '')*5  +
      (race_asi      ne c_race_asi     )*(-5) +
      (race_blk      = c_race_blk      and race_blk     ne '')*5  +
      (race_blk      ne c_race_blk     )*(-5) +
      (race_haw      = c_race_haw      and race_haw     ne '')*5  +
      (race_haw      ne c_race_haw     )*(-5) +
      (race_wht      = c_race_wht      and race_wht     ne '')*5  +
      (race_wht      ne c_race_wht     )*(-5) +
      (sex           = c_sex           and sex          ne '')*2  +
      (sex           ne c_sex          )*(-20) +
      (zipcode       = c_zipcode       and zipcode      ne '')*3  +
      (zipcode       ne c_zipcode      )*(-2) +
      (firstname_sdx = c_firstname_sdx and firstname_sdx ne '')*2  +
      (firstname_sdx ne c_firstname_sdx)*(-10) +
      (lastname_sdx  = c_lastname_sdx  and lastname_sdx ne '')*4  +
      (lastname_sdx  ne c_lastname_sdx )*(-10) +
      (ssnl4         = c_ssnl4         and ssnl4        ne '')*15  +
      (ssnl4         ne c_ssnl4        )*(-10) +
      (statecode     = c_statecode     and statecode       ne '')*1  +
      (statecode     ne c_statecode    )*(-5) +
      (status = '20' and dth_date = dis_date)*10 +
      (status = '20' and dth_date ne dis_date)*(-10) +
      (status = '20' and facility = substr(hospital,1,3))*5 +
      (status = '20' and facility ne substr(hospital,1,3))*(-10)
      ;

      if score ge 0 then output;
      *output;

      end;
run;

proc print data=dihd.link2012(obs= );
   var score certno firstname c_firstname lastname c_lastname miname c_miname dob c_dob
       ssnL4 c_ssnL4 age c_age sex c_sex cnty_res c_cnty_res statecode c_statecode
       race_ami c_race_ami race_asi c_race_asi race_blk c_race_blk race_haw c_race_haw
       race_wht c_race_wht hispanic c_hispanic;
run;
/*
did any pairs have a high score without birthdate matching?
*/
proc freq data=dihd.link2012;
   where dob ne c_dob;
   tables score;
run;
/*
Answer: yes, there were 550 record pairs where birthdates did not match, but the match score
was 50 or higher.
(I expect around 30,000-60,000 matches, so this is about 1%.)
*/
/*
what about SSN?
*/
proc freq data=dihd.link2012;
   where ssnL4 ne c_ssnL4;
   tables score;
run;
/*
There are more than 2,000 records with different SSNs and high match scores
*/
/*
what about sex?
*/
proc freq data=dihd.link2012;
   where sex ne c_sex;
   tables score;
run;
/*
There are only 35 records where sex doesn't match and the match score
is above 50.
*/
\end{lstlisting}

The files are too large to allow for linking in R if we do not block
on birthdate, but it seems that blocking on birthdate will cause us to
lose about 500 links. (Blocking on SSN loses about 2,000 links;
blocking on sex only loses about 30, but does little good.) I will try
this: I will link the entire file while blocking on birthdate. I will
also create files that contain the death records and the CHARS records
from all the pairs for which birthdate did not match, but the matching
score was 20 or more, and do the linking routine with them separately,
not blocking on birthdate. Then I will combine all the links into one
file.

\subsection{Prepare files for linking}

In a preliminary try at linking I saw a pair of records for a baby in
which the first and last names did not match (the last names differed
on two letters and it looked like one could be a misspelled version of
the other, and on the CHARS record the first and middle names were
``BABY G''). Race information was also missing on CHARS, so there was
liitle to indicate that these records should match each other. But I
looked at the original CHARS and death records and saw that the CHARS
record showed status 20 (deceased) with same date of death and
facility code as the death record. So I conlcuded that these records
do match. This example motivated me to make the following changes.

For CHARS records in which status is 20, I will assume the discharge
date is the date of death, and the facility code is the facility where
death occurred. These should match corresponding fields in the death
file. So I will include these fields in the files for linking. In the
CHARS linking file, these fields will be blank when status is not 20.

I will prepare switched name fields so that the matching algorithm can
compare the first names in the death file to the last names in the
CHARS file and vice versa (because I noticed that the names were
switched on some CHARS records). I will do this by copying the
first and last names in the death file into fields named {\tt
deathfirst} and {\tt deathlast} respectively, and copying the first
ane last names in the CHARS file into fields named {\tt charsfirst}
and {\tt charslast} respectively, and then ordering the fields so that
{\tt deathfirst} is compared to {\tt charslast} and {\tt deathlast} is
compared to {\tt charsfirst}.

Prepare files to write to R. I convert strings that indicate missing
values (such as `'''' for the race codes, and `9999' for SSN) to
blanks so that the linking routines won't think these represent
good information.

\begin{lstlisting}[language=sas,caption=write death and CHARS files to csv for R]
/*
the length statements are to ensure fields are in a consistent order
when I read them into R, and the fields are ordered for easiest use
during the classification of the training set.
*/
data dwnames2;
   length certno $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 cnty_res $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 deathfirst $ 20 deathlast $ 20;
   set dwnames;
   keep certno cnty_res dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date deathfirst deathlast suffix
        ;
   if firstname in ('B','BABY','BABYBOY','BABYGIRL','BOY','GIRL')
      then firstname = '';
   deathfirst = firstname;
   deathlast  = lastname;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 = '9999' then ssnL4 = '';
   format dth_date mmddyy10.;
run;
proc export data=dwnames2
   outfile = "c:\data\DIHD\death2012.txt"
   dbms = csv
   replace
   ;
run;

data clink2;
   length seq_no_enc $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 countyres $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 charslast $ 20 charsfirst $ 20;
   set clink1112;
   if status = '20' then do;
      facility = substr(hospital,1,3);
      dth_date = dis_date;
      end;
   else do;
      facility = '';
      dth_date = .;
      end;
   if firstname in ('B','BABY','BABYBOY','BABYGIRL',
      'BOY','GIRL','BB','BBABY','BABYA','BABYB','BABYBOY',
      'BABYG','BABYGIRL','BABYTWIN','BABYABOY','BABYBGIRL',
      'BABYBOY','BABYBOYA','BABYBOYB','BABYFEMAL','BABYFEMALE',
      'BABYGIRL','BABYGIRLA','BABYGIRLB','BABYMALE','BABYONE',
      'BABYTWO')
      then firstname = '';
   charsfirst = firstname;
   charslast = lastname;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 = '9999' then ssnL4 = '';
   keep seq_no_enc countyres dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date charsfirst charslast suffix;
   format dth_date mmddyy10.;
run;
proc export data=clink2
   outfile = "c:\data\DIHD\chars2011_2012.txt"
   dbms = csv
   replace
   ;
run;
\end{lstlisting}

\subsection{Perform linking}

Now read the files into R.

\bfs
\begin{verbatim}
%<<>>=
library(RecordLinkage)
death2012 <- read.csv("../../../data/DIHD/death2012.txt",colClasses=c(rep("character",18)),
                      col.names=c("certno","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "death.first","death.last"))
death2012$firstname.sdx <- soundex(death2012$firstname)
death2012$lastname.sdx  <- soundex(death2012$lastname)

chars1112 <- read.csv("../../../data/DIHD/chars2011_2012.txt",colClasses=c(rep("character",18)),
                      col.names=c("seq_no_enc","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "chars.last","chars.first"))
chars1112$firstname.sdx <- soundex(chars1112$firstname)
chars1112$lastname.sdx  <- soundex(chars1112$lastname)


#tdeath <- death2012[1:1000,]
#tchars <- chars1112[640000:680000,]

trylcomp <- compare.linkage(tdeath,tchars,blockfld=c(2),exclude=c(1,15,17,18))
trylcomp.sc <- compare.linkage(tdeath,tchars,blockfld=c(2),exclude=c(1,15,17,18),strcmp=c(3,5),
               strcmpfun=levenshteinSim)


# question: can I train a binary comparison dataset and use it to
#  classify a dataset with string metrics?

trylcomp.model <- trainSupv(trylcomp.fsWt.train,method='bagging')
trylcomp.sc.model <- trainSupv(trylcomp.sc.fsWt.train,method='bagging')

trylcomp.result.a <- classifySupv(trylcomp.model,newdata=trylcomp.fsWt)
trylcomp.result.b <- classifySupv(trylcomp.model,newdata=trylcomp.sc.fsWt)
trylcomp.sc.result <- classifySupv(trylcomp.model,newdata=trylcomp.sc.fsWt)

plot(density(trylcomp.result.a$Wdata[trylcomp.result.a$prediction=='N']),xlim=c(-50,130))
lines(density(trylcomp.result.a$Wdata[trylcomp.result.a$prediction=='L']),col=2,lwd=2)

plot(density(trylcomp.result.b$Wdata[trylcomp.result.b$prediction=='N']),xlim=c(-50,130))
lines(density(trylcomp.result.b$Wdata[trylcomp.result.b$prediction=='L']),col=2,lwd=2)

plot(density(trylcomp.sc.result$Wdata[trylcomp.sc.result$prediction=='N']),xlim=c(-50,130))
lines(density(trylcomp.sc.result$Wdata[trylcomp.sc.result$prediction=='L']),col=2,lwd=2)

table(trylcomp.result.a$prediction,trylcomp.result.b$prediction)
table(trylcomp.result.a$prediction,trylcomp.sc.result$prediction)

# result.a and sc.result make exactly the same predictions; result.b
#  gets 2 different, and both those 2 are false matches.


pairs1112 <- compare.linkage(death2012,chars1112,blockfld=c(2),exclude=c(1))

# calculate Fellegi-Sunter weights
pairs1112.fsWt <- fsWeights(pairs1112)

# get a training set
train1112.a <- getMinimalTrain(pairs1112.fsWt,nEx=3)

train1112.a <- editMatch(train1112.a)


plot(density(pairs1112.fsWt$Wdata,bw=4),col=4,lwd=4)
lines(density(train1112.a$Wdata[train1112.a$pairs$is_match==1]),col=2)
lines(density(train1112.a$Wdata[train1112.a$pairs$is_match==0]),col=1)

model1112.bag <- trainSupv(train1112.a,method='bagging')
result1112.bag <- classifySupv(model1112.bag,newdata=pairs1112.fsWt)

# save the old training set, model, and results
# (these are from before I normalized the names)
save(list=c('train1112.a.old','model1112.bag.old','result1112.bag.old'),file='OldClassifier')


%@
\end{verbatim}
\efs

A look at the predictive power of the fields suggests that {\tt
race.haw} and {\tt race.ami} have little predictive ability. The field
{\tt statecode} also doesn't add much.

Using a string similarity metric apparently increases the number of
pairs that need to be evaluated for the training set, so I will use it
only for first and last names, and not for SSN. After trying that, I
found that the number of pairs in the training set increased to a
number too high for me to classify (83,000 pairs). I also found that
in the small trial I ran, the model that used string comparators
classified all the records in the dataset in exactly the same way as
the model that did not use string comparators. So I won't use them.

Since I am not using string comparators, I will use all the fields,
including those that don't add much.

what I need to do:
1. remove all non-letter characters from first and last names
2. create fields to compare first to last names
3. re-run compare.linkage with string comparators, etc
4. classify the new training set
5. use it to classify the 2012 death records
6. manual review
7. classify the records which had a high score and non-matching
birthdate.
8 repeat steps 5-7 for other years.

\bfs
\begin{verbatim}
> table(cut(result1112.bag$Wdata[result1112.bag$prediction=='L'],breaks=c(-500,-100,-50,-20,0,20,30,40,50,100,500)))

(-500,-100]  (-100,-50]   (-50,-20]     (-20,0]      (0,20]     (20,30]     (30,40]     (40,50]    (50,100]   (100,500]
          0           0           4          40         275         324         494        1003       42896       44357
> table(cut(result1112.bag$Wdata[result1112.bag$prediction=='N'],breaks=c(-500,-100,-50,-20,0,20,30,40,50,100,500)))

(-500,-100]  (-100,-50]   (-50,-20]     (-20,0]      (0,20]     (20,30]     (30,40]     (40,50]    (50,100]   (100,500]
          0      207213     1642634      102195       12467        1414         161          65          11           0
>
\end{verbatim}
\efs

I will probably manually review the non-links with weight of 30 or
more, and links with weights of 30 or less.

To review links, I subset the RecLinkData like this:

\bfs
\begin{verbatim}
manualreview2012 <- result1112.bag[(result1112.bag$prediction=='L'&result1112.bag$Wdata<=30)|
                     (result1112.bag$prediction=='N'&result1112.bag$Wdata>=30)]

manualreview2012 <- editMatch(manualreview2012)

manualreview2012.b <- manualreview2012
for(i in 1:length(manualreview2012$prediction)) {
      manualreview2012.b$prediction[i] <- if(manualreview2012$pairs$is_match[i]==0) 'N' else 'L'
}

predictions.2012a <- result1112.bag$prediction
index.r <- as.numeric(row.names(manualreview2012.b$pairs))
predictions.2012b <- predictions.2012a
predictions.2012b[index.r] <- manualreview2012.b$prediction

# combine death and CHARS row numbers with the predictions
newresults <- cbind(result1112.bag$pairs[,c(1,2)],predictions.2012b)

# get death certificate numbers and CHARS seq number (seq_no_enc)
deathcerts <- result1112.bag$data1[newresults[,1],1]
charsseq <- result1112.bag$data2[newresults[,2],1]
newresults.b <- data.frame(deathcerts,charsseq,predictions.2012b)

\end{verbatim}
\efs

Now I get a file of the record pairs which had a high matching score
(30 or higher)
with non-matching birthdates, and export them to an Excel spreadsheet to conduct a manual
review on them. I chose 30 as the cutoff score for manual review
because that provides a reasonable number of records for review (about
2,400 for 2012), but I think it includes nearly all the records that have much
chance of being classified a true match.

\begin{lstlisting}[language=sas,caption=get non-matching birthdate high scorers for manual review]
libname dihd 'c:\data\dihd';
data review1;
   set dihd.link2012(where=(dob ne c_dob and score ge 30));
run;
proc sort data=review1;
   by score;
run;
data review2(keep=dcert cseq bd fname mi lname ssn sx hosp dd zip county hisp rw
                  rb ram ras rh sc);
   length dcert $ 10 cseq $ 10 bd 8 fname $ 20 mi $ 1 lname $ 20 ssn $ 4 sx $ 1
          hosp $ 3 dd 8 zip $ 5 county $ 2 hisp rw rb ram ras rh $ 1
          sc 8;
   set review1;
   format bd dd mmddyy10.;

   dcert = certno;
   cseq = seq_no_enc;
   bd = dob;
   fname = firstname;
   mi = miname;
   lname = lastname;
   ssn = ssnL4;
   sx = sex;
   hosp = facility;
   dd = dth_date;
   zip = zipcode;
   county = cnty_res;
   hisp = hispanic;
   rw = race_wht;
   rb = race_blk;
   ram = race_ami;
   ras = race_asi;
   rh = race_haw;
   sc = score;
   output;

   bd = c_dob;
   fname = c_firstname;
   mi = c_miname;
   lname = c_lastname;
   ssn = c_ssnL4;
   sx = c_sex;
   if status = 20 or dis_date ge dth_date then do;
      hosp = hospital;
      dd = dis_date;
      end;
   else do;
      hosp = '';
      dd = .;
      end;
   zip = c_zipcode;
   county = c_cnty_res;
   hisp = c_hispanic;
   rw = c_race_wht;
   rb = c_race_blk;
   ram = c_race_ami;
   ras = c_race_asi;
   rh = c_race_haw;
   sc = .;
   output;

   bd = .;
   fname = '';
   mi = '';
   lname = '';
   ssn = '';
   sx = '';
   hosp = '';
   dd = .;
   zip = '';
   county = '';
   hisp = '';
   rw = '';
   rb = '';
   ram = '';
   ras = '';
   rh = '';
   sc = .;
   output;
run;

proc export data=review2
   outfile = "c:\user\projects\Death-CHARSlink\manreview2012.xls"
   dbms = excel5
   replace
   ;
run;
/*
read the reviewed links
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2012_done.xls"
   dbms = excel5
   ;
run;


\end{lstlisting}

Notes for future years:
\begin{enumerate}
\item convert '9999' in ssn to missing so it doesn't add to the score
\item subtract from the score if the discharge date is more than one day
past the death date.
\item compare the elements (day, month, year) of the birth date and add
to the score if some of them are the same.
\end{enumerate}

Now I need to combine the links from three sources: the machine
learning results, the manual review of those results, and the manual
coding of the records on which birthdate didn't match. After combining
those links, I need to check whether there are any hospitalization
records linked to more than one death record, and if so, adjudicate
those links manually. Then I can create the final linked file.

\bfs
\begin{verbatim}
#create file containing only the linked pairs
links2012 <- newresults.b[newresults.b$predictions.2012b=='L',]

write.csv(links2012,file="c:/data/dihd/links2012.csv",row.names=F)

\end{verbatim}
\efs

\begin{lstlisting}[language=sas,caption=create final linked file for 2012]
libname dihd 'c:\data\dihd';

proc import out=links0
   file = "c:\data\dihd\links2012.csv"
   dbms = csv
   replace
   ;
run;
data links1(keep=certno seq_no_enc predict);
   length certno seq_no_enc $ 10 predict $ 1;
   set links0;
   certno = substr(deathcerts,1,10);
   seq_no_enc = substr(charsseq,1,10);
   predict = substr(predictions_2012b,1,1);
run;
/*
find the CHARS records that linked to more than one death certificate
(there are 7 CHARS records that each linked to 2 death certs, and 3
   that each linked to 3 death certs)
*/
proc freq data=links1 noprint;
   tables seq_no_enc/out=charslist;
run;
data mults1(drop=percent);
   set charslist(where=(count ge 2));
run;
proc sort data=links1;
   by seq_no_enc;
run;
data mults2;
   merge links1 mults1(in=inmult);
   by seq_no_enc;
   if inmult;
run;
/*
I'll guess that all these pairs are in the dataset with hig scores,
   and I will get the detailed information from there.
*/
proc sort data=dihd.link2012;
   by certno seq_no_enc;
run;
proc sort data=mults2;
   by certno seq_no_enc;
run;

data mults3;
   merge dihd.link2012 mults2(in=inmult);
   by certno seq_no_enc;
   if inmult;
run;
proc print data=mults3;
run;
/*
I code the pairs by hand and enter the data here
*/
data mults4;
   input @1 certno $char10. @12 seq_no_enc $char10. @23 link $char1.;
datalines;
2012010713 2012107470 N
2012010713 2012287081 N
2012010717 2012107470 N
2012010717 2012287081 N
2012056614 2012253552 N
2012056614 2012579510 N
2012056615 2012253552 N
2012056615 2012579510 N
2012058625 2012059910 L
2012058625 2012457731 N
2012058626 2012059910 N
2012058626 2012457731 L
2012063085 2012087235 N
2012063085 2012457771 N
2012063085 2012551638 N
2012063086 2012087235 N
2012063086 2012457771 N
2012063086 2012551638 N
2012063087 2012087235 N
2012063087 2012457771 N
2012063087 2012551638 N
2012090096 2011083190 L
2012091639 2011083190 L
;;
run;
/*
I found that death certificates 2012090096 and 2012091639 seem to be
   for the same person.
*/
proc sort data=links1;
   by certno seq_no_enc;
run;
data links2(keep=certno seq_no_enc);
   merge links1 mults4;
   by certno seq_no_enc;
   if link = '' then match = predict;
   else              match = link;
   if match = 'L' then output;
run;

/*
read in the reviewed links for pairs which had high scores but
   non-matching birthdates
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2012_done.xls"
   dbms = excel5
   ;
run;
data mlinks1(keep=certno seq_no_enc sc link);
   length certno seq_no_enc $ 10;
   retain i 0;
   set review3;
   certno = substr(dcert,1,10);
   seq_no_enc = substr(cseq,1,10);
   i+1;
   if i = 1 then output;
   if i = 3 then i = 0;
run;
proc freq data=mlinks1;
   tables sc*link/norow nocol nopercent;
run;
/*
this table shows the strong relation between score and link status

            The SAS System                                                                         09:42 Monday, June 2, 2014  23

          The FREQ Procedure

         Table of SC by LINK

 SC(SC)     LINK(LINK)

 Frequency|       0|       1|  Total
 ---------+--------+--------+
       30 |     62 |     10 |     72
 ---------+--------+--------+
       31 |      5 |      0 |      5
 ---------+--------+--------+
       32 |    858 |     10 |    868
 ---------+--------+--------+
       33 |      0 |      2 |      2
 ---------+--------+--------+
       34 |    125 |      0 |    125
 ---------+--------+--------+
       35 |      4 |      9 |     13
 ---------+--------+--------+
       36 |      1 |      0 |      1
 ---------+--------+--------+
       37 |    197 |     34 |    231
 ---------+--------+--------+
       38 |      0 |      3 |      3
 ---------+--------+--------+
       39 |      0 |      7 |      7
 ---------+--------+--------+
       40 |      4 |      2 |      6
 ---------+--------+--------+
       41 |      0 |      3 |      3
 ---------+--------+--------+
       42 |     16 |     36 |     52
 ---------+--------+--------+
       43 |      0 |      1 |      1
 ---------+--------+--------+
       44 |      1 |      7 |      8
 ---------+--------+--------+
       45 |      0 |      3 |      3
 ---------+--------+--------+
       46 |      0 |      1 |      1
 ---------+--------+--------+
       47 |      1 |     68 |     69
 ---------+--------+--------+
       48 |      0 |      1 |      1
 ---------+--------+--------+
       49 |      0 |     30 |     30
 ---------+--------+--------+
       50 |      0 |      4 |      4
 ---------+--------+--------+
       52 |      1 |     84 |     85
 ---------+--------+--------+
       53 |      0 |      4 |      4
 ---------+--------+--------+
       54 |      0 |      3 |      3
 ---------+--------+--------+
       55 |      0 |     17 |     17
 ---------+--------+--------+
       57 |      0 |    102 |    102
 ---------+--------+--------+
       59 |      0 |     12 |     12
 ---------+--------+--------+
       60 |      0 |     30 |     30
 ---------+--------+--------+
       62 |      0 |    263 |    263
 ---------+--------+--------+
       64 |      0 |      3 |      3
 ---------+--------+--------+
       65 |      0 |      6 |      6
 ---------+--------+--------+
       67 |      0 |     61 |     61
 ---------+--------+--------+
       68 |      0 |      1 |      1
 ---------+--------+--------+
       70 |      0 |     33 |     33
 ---------+--------+--------+
       72 |      0 |    214 |    214
 ---------+--------+--------+
       74 |      0 |      3 |      3
 ---------+--------+--------+
       75 |      0 |      5 |      5
 ---------+--------+--------+
       77 |      0 |     27 |     27
 ---------+--------+--------+
       82 |      0 |     15 |     15
 ---------+--------+--------+
       85 |      0 |      5 |      5
 ---------+--------+--------+
       87 |      0 |     49 |     49
 ---------+--------+--------+
 Total        1275     1168     2443
*/
data mlinks2(keep=certno seq_no_enc);
   set mlinks1(where=(link=1));
run;
data dihd.finallink2012;
   set links2 mlinks2;
run;

proc freq data=dihd.finallink2012 noprint;
   tables certno/out=dcertlist;
run;
/*
I found that 35,993 death certificates (subtracting one copy of the
   duplicate I found) linked to 90,554 hospital records.
*/
\end{lstlisting}


\subsection{DIHD file for 2011}

\begin{lstlisting}[language=sas,caption=create death file for linking]
Steps:
1. read the death file with names
2. merge with standard death file to add dob, age, sex, race,
*/
/*
Step 1. read the death file with names
*/
data names;
   infile "c:\data\death\deathnames\deathnamesv3.2011" lrecl=241;
   input
      @1   certno     $char10.
      @11  lastname   $char50.
      @61  firstname  $char30.
      @91  middlename $char40.
      @131 suffix     $char4.
      @158 ssnL4      $char4.
      @162 street     $char35.
      @197 city       $char30.
      @236 statecode  $char2.
      ;
run;
/*
Step 2. merge with standard death file
*/
proc sort data=names;
   by certno;
run;
proc sort data=death.dea2011
      out=stats(keep=certno age dob sex cnty_res zipcode dth_date race_wht race_blk
      race_ami race_asi race_chi race_fil race_gua race_haw race_jap race_kor
      race_opi race_oas race_oth race_sam race_vie hisp zipcode facility fac_type);
   by certno;
run;
/*
combine statistical and name files, and recode race fields to match the reduced
set in the CHARS file (which has only white, black, american indian or alaska
native, asian, hawaiian or other Pacific Islander)
*/
data dwnames(drop=sum_race_asi sum_race_haw race_temp1 race_temp2 race_chi race_fil
          race_gua race_jap race_kor race_opi race_oas race_oth race_sam
          race_vie firsttemp lasttemp middlename hisp firsttemp2 lasttemp2);
   length firstname lastname $ 20 miname hispanic $ 1 lastname_sdx firstname_sdx $ 4
          firsttemp2 lasttemp2 $ 25;
   merge stats(rename=(race_asi=race_temp1 race_haw=race_temp2))
         names(rename=(firstname=firsttemp lastname=lasttemp));
   by certno;
   firsttemp2 = compress(firsttemp," '`-_,.&");
   lasttemp2  = compress(lasttemp," '`-_,.&");
   firstname = substr(firsttemp2,1,20);
   lastname  = substr(lasttemp2,1,20);
   miname    = substr(middlename,1,1);
   sum_race_asi = min(1,(race_chi='Y')+(race_fil='Y')+(race_jap='Y')+(race_kor='Y')+
                    (race_oas='Y')+(race_vie='Y')+(race_temp1='Y'));
   sum_race_haw = min(1,(race_gua='Y')+(race_opi='Y')+(race_sam='Y')+(race_temp2='Y'));

   if sum_race_asi = 0 then race_asi = 'N';
   else                     race_asi = 'Y';
   if sum_race_haw = 0 then race_haw = 'N';
   else                     race_haw = 'Y';
   if race_ami in ('') then race_ami = 'U';
   if race_asi in ('') then race_asi = 'U';
   if race_blk in ('') then race_blk = 'U';
   if race_haw in ('') then race_haw = 'U';
   if race_wht in ('') then race_wht = 'U';
   select(hisp);
      when('0')                 hispanic = 'N';
      when('1','2','3','4','5') hispanic = 'Y';
      when('','9')              hispanic = 'U';
      end;
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);

   format dob mmddyy10.;
run;
\end{lstlisting}

\begin{lstlisting}[language=sas,caption=Create CHARS file for linking]
proc format;
   value $stateres
     'AL' = '01'
     'AK' = '02'
     'AZ' = '03'
     'AR' = '04'
     'CA' = '05'
     'CO' = '06'
     'CT' = '07'
     'DE' = '08'
     'DC' = '09'
     'FL' = '10'
     'GA' = '11'
     'HI' = '12'
     'ID' = '13'
     'IL' = '14'
     'IN' = '15'
     'IA' = '16'
     'KS' = '17'
     'KY' = '18'
     'LA' = '19'
     'ME' = '20'
     'MD' = '21'
     'MA' = '22'
     'MI' = '23'
     'MN' = '24'
     'MS' = '25'
     'MO' = '26'
     'MT' = '27'
     'NE' = '28'
     'NV' = '29'
     'NH' = '30'
     'NJ' = '31'
     'NM' = '32'
     'NY' = '33'
     'NC' = '34'
     'ND' = '35'
     'OH' = '36'
     'OK' = '37'
     'OR' = '38'
     'PA' = '39'
     'RI' = '40'
     'SC' = '41'
     'SD' = '42'
     'TN' = '43'
     'TX' = '44'
     'UT' = '45'
     'VT' = '46'
     'VA' = '47'
     'WA' = '48'
     'WV' = '49'
     'WI' = '50'
     'WY' = '51'
     'PR' = '52'
     'VI' = '53'
     'GU' = '54'
     'AS' = '60'
     'MP' = '69'
      ;
run;
data clink1011(keep=seq_no_enc adm_date age country countyres dis_date dob firstname
                ssnL4 hispanic hospital lastname miname race_ami race_asi race_blk
                race_haw race_wht sex statecode status zipcode zipplus4
                lastname_sdx firstname_sdx suffix);
   length firstname lastname $ 20 suffix $ 4 lastname_sdx firstname_sdx $ 4 statecode $ 2;
   set chars.chr_r2010(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp))
       chars.chr_r2011(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp));
   if race_ami in ('','R') then race_ami = 'U';
   if race_asi in ('','R') then race_asi = 'U';
   if race_blk in ('','R') then race_blk = 'U';
   if race_haw in ('','R') then race_haw = 'U';
   if race_wht in ('','R') then race_wht = 'U';
   if hispanic in ('','R') then hispanic = 'U';
/*
remove the suffixes II, III, IV, V, VI, VII, VIII, ESQ, JR, and SR
from lastnames and place them in a separate suffix field.
Used with UB04 data.
*/
   if _N_ = 1 then do;
   	retain __re __reIII;
   	pattern = "/( II| III| IV| V| VI| VII| VIII| ESQ|.JR|.SR)$/i";
   	__re = prxparse(pattern);
   	__reIII = prxparse('/III$/');
   end;
   lasttemp = translate(lasttemp,' ','.,');
   call prxsubstr(__re, TRIM(lasttemp), position, length);
   if position ^= 0 then do;
   	suffix    = substr(lasttemp, position + 1, length - 1);
   	lasttemp2 = substr(lasttemp, 1, position - 1);
   end;
   else lasttemp2 = lasttemp;

   firstname = compress(firsttemp," '`-_,.&");
   lastname  = compress(lasttemp2," '`-_,.&");
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);
*   statecode = put(stateres,$stateres.);
   statecode = stateres;
*   if not ('01' le statecode le '69') then statecode = '99';
   if statecode = 'XX' then statecode = '';
run;
\end{lstlisting}


\begin{lstlisting}[language=sas,caption=compute test link scores]
libname dihd 'c:\data\dihd';

/*
For each record, I will evaluate its similarity with each of the other records
by computing a score using the points described above. In the output dataset,
I will keep records that have a score of at least 0.
Maximum score is 112.
*/
data dihd.link2011;
   set clink1011(rename=(
     age           = c_age
     countyres     = c_cnty_res
     dob           = c_dob
     firstname     = c_firstname
     hispanic      = c_hispanic
     lastname      = c_lastname
     miname        = c_miname
     race_ami      = c_race_ami
     race_asi      = c_race_asi
     race_blk      = c_race_blk
     race_haw      = c_race_haw
     race_wht      = c_race_wht
     sex           = c_sex
     zipcode       = c_zipcode
     firstname_sdx = c_firstname_sdx
     lastname_sdx  = c_lastname_sdx
     ssnl4         = c_ssnl4
     statecode     = c_statecode
     ));
   do i = 1 to 50589;
      set dwnames point=i;
      score =
      (age           = c_age           and age          ne .)*5  +
      (age           ne c_age          )*(-5) +
      (cnty_res      = c_cnty_res      and cnty_res     ne '')*3  +
      (cnty_res      ne c_cnty_res     )*(-5) +
      (dob           = c_dob           and dob          ne .)*20  +
      (dob           ne c_dob          )*(-20) +
      (firstname     = c_firstname     and firstname    ne '')*10  +
      (firstname     ne c_firstname    )*(-10) +
      (hispanic      = c_hispanic      and hispanic     ne '')*5  +
      (hispanic      ne c_hispanic     )*(-5) +
      (lastname      = c_lastname      and lastname     ne '')*15  +
      (lastname      ne c_lastname     )*(-15) +
      (miname        = c_miname        and miname       ne '')*2  +
      (miname        ne c_miname       )*(-3) +
      (race_ami      = c_race_ami      and race_ami     ne '')*5  +
      (race_ami      ne c_race_ami     )*(-5) +
      (race_asi      = c_race_asi      and race_asi     ne '')*5  +
      (race_asi      ne c_race_asi     )*(-5) +
      (race_blk      = c_race_blk      and race_blk     ne '')*5  +
      (race_blk      ne c_race_blk     )*(-5) +
      (race_haw      = c_race_haw      and race_haw     ne '')*5  +
      (race_haw      ne c_race_haw     )*(-5) +
      (race_wht      = c_race_wht      and race_wht     ne '')*5  +
      (race_wht      ne c_race_wht     )*(-5) +
      (sex           = c_sex           and sex          ne '')*2  +
      (sex           ne c_sex          )*(-20) +
      (zipcode       = c_zipcode       and zipcode      ne '')*3  +
      (zipcode       ne c_zipcode      )*(-2) +
      (firstname_sdx = c_firstname_sdx and firstname_sdx ne '')*2  +
      (firstname_sdx ne c_firstname_sdx)*(-10) +
      (lastname_sdx  = c_lastname_sdx  and lastname_sdx ne '')*4  +
      (lastname_sdx  ne c_lastname_sdx )*(-10) +
      (ssnl4         = c_ssnl4         and ssnl4        ne '')*15  +
      (ssnl4         ne c_ssnl4        )*(-10) +
      (statecode     = c_statecode     and statecode       ne '')*1  +
      (statecode     ne c_statecode    )*(-5) +
      (status = '20' and dth_date = dis_date)*10 +
      (status = '20' and dth_date ne dis_date)*(-10) +
      (status = '20' and facility = substr(hospital,1,3))*5 +
      (status = '20' and facility ne substr(hospital,1,3))*(-10)
      ;

      if score ge 0 then output;
      *output;

      end;
run;

proc print data=dihd.link2011(obs= );
   var score certno firstname c_firstname lastname c_lastname miname c_miname dob c_dob
       ssnL4 c_ssnL4 age c_age sex c_sex cnty_res c_cnty_res statecode c_statecode
       race_ami c_race_ami race_asi c_race_asi race_blk c_race_blk race_haw c_race_haw
       race_wht c_race_wht hispanic c_hispanic;
run;
/*
did any pairs have a high score without birthdate matching?
*/
proc freq data=dihd.link2011;
   where dob ne c_dob;
   tables score;
run;

\end{lstlisting}


\begin{lstlisting}[language=sas,caption=write death and CHARS files to csv for R]
/*
the length statements are to ensure fields are in a consistent order
when I read them into R, and the fields are ordered for easiest use
during the classification of the training set.
I delete the records that have no names or SSN (typically these are
deaths that occurred out-of-state).
*/
data dwnames2;
   length certno $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 cnty_res $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 deathfirst $ 20 deathlast $ 20;
   set dwnames;
   keep certno cnty_res dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date deathfirst deathlast suffix
        ;
   if firstname in ('B','BABY','BABYBOY','BABYGIRL','BOY','GIRL')
      then firstname = '';
   deathfirst = firstname;
   deathlast  = lastname;
   if firstname = '' and lastname = '' then delete;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 = '9999' then ssnL4 = '';
   format dth_date mmddyy10.;
run;
proc export data=dwnames2
   outfile = "c:\data\DIHD\death2011.txt"
   dbms = csv
   replace
   ;
run;

data clink2;
   length seq_no_enc $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 countyres $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 charslast $ 20 charsfirst $ 20;
   set clink1011;
   if status = '20' then do;
      facility = substr(hospital,1,3);
      dth_date = dis_date;
      end;
   else do;
      facility = '';
      dth_date = .;
      end;
   if firstname in ('B','BABY','BABYBOY','BABYGIRL',
      'BOY','GIRL','BB','BBABY','BABYA','BABYB','BABYBOY',
      'BABYG','BABYGIRL','BABYTWIN','BABYABOY','BABYBGIRL',
      'BABYBOY','BABYBOYA','BABYBOYB','BABYFEMAL','BABYFEMALE',
      'BABYGIRL','BABYGIRLA','BABYGIRLB','BABYMALE','BABYONE',
      'BABYTWO')
      then firstname = '';
   charsfirst = firstname;
   charslast = lastname;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 = '9999' then ssnL4 = '';
   keep seq_no_enc countyres dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date charsfirst charslast suffix;
   format dth_date mmddyy10.;
run;
proc export data=clink2
   outfile = "c:\data\DIHD\chars2010_2011.txt"
   dbms = csv
   replace
   ;
run;
\end{lstlisting}


\bfs
\begin{verbatim}
%<<>>=
library(RecordLinkage)

# save the previous training set, model, and results
save(list=c('pairs1112.fsWt','train1112.a','model1112.bag','result1112.bag',
        'manualreview2012.b'),file='Classifier2012')

death2011 <- read.csv("../../../data/DIHD/death2011.txt",colClasses=c(rep("character",18)),
                      col.names=c("certno","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "death.first","death.last"))
death2011$firstname.sdx <- soundex(death2011$firstname)
death2011$lastname.sdx  <- soundex(death2011$lastname)

chars1011 <- read.csv("../../../data/DIHD/chars2010_2011.txt",colClasses=c(rep("character",18)),
                      col.names=c("seq_no_enc","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "chars.last","chars.first"))
chars1011$firstname.sdx <- soundex(chars1011$firstname)
chars1011$lastname.sdx  <- soundex(chars1011$lastname)

pairs2011 <- compare.linkage(death2011,chars1011,blockfld=c(2),exclude=c(1))

# calculate Fellegi-Sunter weights
pairs2011.fsWt <- fsWeights(pairs2011)

# get a training set
train2011.a <- getMinimalTrain(pairs2011.fsWt,nEx=3)

train2011.a <- editMatch(train2011.a)

model2011.bag <- trainSupv(train2011.a,method='bagging')
result2011.bag <- classifySupv(model2011.bag,newdata=pairs2011.fsWt)

manualreview2011 <- result2011.bag[(result2011.bag$prediction=='L'&result2011.bag$Wdata<=35)|
                     (result2011.bag$prediction=='N'&result2011.bag$Wdata>=20)]

manualreview2011 <- editMatch(manualreview2011)

%@
\end{verbatim}
\efs

This shows the relationships between the weight, the machine
prediction, and the manual classification on the records that I
manually reviewed:

\bvm
> with(manualreview2011[manualreview2011$Wdata<0],table(pairs$is_match,prediction))
   prediction
     N  P  L
  0  0  0  4
  1  0  0 33
> with(manualreview2011[manualreview2011$Wdata>=0&manualreview2011$Wdata<10],table(pairs$is_match,prediction))
   prediction
     N  P  L
  0  0  0 19
  1  0  0 91
> with(manualreview2011[manualreview2011$Wdata>=10&manualreview2011$Wdata<20],table(pairs$is_match,prediction))
   prediction
      N   P   L
  0   0   0  36
  1   0   0 169
> with(manualreview2011[manualreview2011$Wdata>=20&manualreview2011$Wdata<30],table(pairs$is_match,prediction))
   prediction
       N    P    L
  0 1199    0   19
  1   27    0  331
> with(manualreview2011[manualreview2011$Wdata>=30&manualreview2011$Wdata<40],table(pairs$is_match,prediction))
   prediction
      N   P   L
  0 114   0   0
  1  17   0 220
> with(manualreview2011[manualreview2011$Wdata>=40&manualreview2011$Wdata<50],table(pairs$is_match,prediction))
   prediction
     N  P  L
  0 35  0  0
  1 27  0  0
> with(manualreview2011[manualreview2011$Wdata>=50&manualreview2011$Wdata<60],table(pairs$is_match,prediction))
   prediction
     N  P  L
  1 29  0  0
> with(manualreview2011[manualreview2011$Wdata>=60],table(pairs$is_match,prediction))
   prediction
    N P L
  1 5 0 0
\end{verbatim}

In tabular form:

When the machine predicted a link (I manually reviewed all pairs where
the weight was 35 or less and the machine predicted a link):

\begin{tabular}{rrrr}
weight & match & not & \% not match \\ \hline
$< 0$  & 33 & 4  & 11 \\
0--10  & 91 & 19 & 17 \\
10--20 &169 & 36 & 18 \\
20--30 &331 & 19 &  5 \\
30--35 &220 &  0 &  0 \\
\end{tabular}

When the machine predicted a pair was not a link (I manually reviewed
all pairs where the weight was 20 or more and the machine predicted
the pair was not a link):

\begin{tabular}{rrrr}
weight & match & not & \% match \\ \hline
20--30 & 27 & 1199 &  2 \\
30--40 & 17 &  114 & 13 \\
40--50 & 27 &   35 & 44 \\
50--60 & 29 &    0 &100 \\
60 +   &  5 &    0 &100 \\
\end{tabular}

So it looks like I should continue to manually review pairs that
satisfy one of these two conditions:
\begin{itemize}
\item weight is 30 or lower and the machine predicts a link
\item weight is 30 or higher and the machine predicts not a link
\end{itemize}

For 2011, following these guidelines would have meant doing manual
review on 929 pairs, and changing the classification of 156 of them (17\%).


\bfs
\begin{verbatim}
%<<>>=
library(RecordLinkage)

manualreview2011.b <- manualreview2011
for(i in 1:length(manualreview2011$prediction)) {
      manualreview2011.b$prediction[i] <- if(manualreview2011$pairs$is_match[i]==0) 'N' else 'L'
}

predictions.2011a <- result2011.bag$prediction
index.r <- as.numeric(row.names(manualreview2011.b$pairs))
predictions.2011b <- predictions.2011a
predictions.2011b[index.r] <- manualreview2011.b$prediction

# combine death and CHARS row numbers with the predictions
newresults2011 <- cbind(result2011.bag$pairs[,c(1,2)],predictions.2011b)

# get death certificate numbers and CHARS seq number (seq_no_enc)
deathcerts <- result2011.bag$data1[newresults2011[,1],1]
charsseq <- result2011.bag$data2[newresults2011[,2],1]
newresults2011.b <- data.frame(deathcerts,charsseq,predictions.2011b)

%@
\end{verbatim}
\efs

\subsubsection{Manual review of records with non-matching birthdates}

Now I get a file of the record pairs which had a high matching score
(30 or higher)
with non-matching birthdates, and export them to an Excel spreadsheet to conduct a manual
review on them. I chose 30 as the cutoff score for manual review
because that provides a reasonable number of records for review (about
2,400 for 2011), but I think it includes nearly all the records that have much
chance of being classified a true match.

\begin{lstlisting}[language=sas,caption=get non-matching birthdate high scorers for manual review]
libname dihd 'c:\data\dihd';
data review1;
   set dihd.link2011(where=(dob ne c_dob and score ge 30));
run;
proc sort data=review1;
   by score;
run;
data review2(keep=dcert cseq bd fname mi lname ssn sx hosp dd zip county hisp rw
                  rb ram ras rh sc);
   length dcert $ 10 cseq $ 10 bd 8 fname $ 20 mi $ 1 lname $ 20 ssn $ 4 sx $ 1
          hosp $ 3 dd 8 zip $ 5 county $ 2 hisp rw rb ram ras rh $ 1
          sc 8;
   set review1;
   format bd dd mmddyy10.;

   dcert = certno;
   cseq = seq_no_enc;
   bd = dob;
   fname = firstname;
   mi = miname;
   lname = lastname;
   ssn = ssnL4;
   sx = sex;
   hosp = facility;
   dd = dth_date;
   zip = zipcode;
   county = cnty_res;
   hisp = hispanic;
   rw = race_wht;
   rb = race_blk;
   ram = race_ami;
   ras = race_asi;
   rh = race_haw;
   sc = score;
   output;

   bd = c_dob;
   fname = c_firstname;
   mi = c_miname;
   lname = c_lastname;
   ssn = c_ssnL4;
   sx = c_sex;
   if status = 20 or dis_date ge dth_date then do;
      hosp = hospital;
      dd = dis_date;
      end;
   else do;
      hosp = '';
      dd = .;
      end;
   zip = c_zipcode;
   county = c_cnty_res;
   hisp = c_hispanic;
   rw = c_race_wht;
   rb = c_race_blk;
   ram = c_race_ami;
   ras = c_race_asi;
   rh = c_race_haw;
   sc = .;
   output;

   bd = .;
   fname = '';
   mi = '';
   lname = '';
   ssn = '';
   sx = '';
   hosp = '';
   dd = .;
   zip = '';
   county = '';
   hisp = '';
   rw = '';
   rb = '';
   ram = '';
   ras = '';
   rh = '';
   sc = .;
   output;
run;

proc export data=review2
   outfile = "c:\user\projects\Death-CHARSlink\manreview2011.xls"
   dbms = excel5
   replace
   ;
run;
/*
read the reviewed links
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2011_done.xls"
   dbms = excel5
   ;
run;
\end{lstlisting}

Now I need to combine the links from three sources: the machine
learning results, the manual review of those results, and the manual
coding of the records on which birthdate didn't match. After combining
those links, I need to check whether there are any hospitalization
records linked to more than one death record, and if so, adjudicate
those links manually. Then I can create the final linked file.

\bfs
\begin{verbatim}
#create file containing only the linked pairs
links2011 <- newresults2011.b[newresults2011.b$predictions.2011b=='L',]

write.csv(links2011,file="c:/data/dihd/links2011.csv",row.names=F)

\end{verbatim}
\efs

\begin{lstlisting}[language=sas,caption=create final linked file for 2011]
libname dihd 'c:\data\dihd';

proc import out=links0
   file = "c:\data\dihd\links2011.csv"
   dbms = csv
   replace
   ;
run;
data links1(keep=certno seq_no_enc predict);
   length certno seq_no_enc $ 10 predict $ 1;
   set links0;
   certno = substr(deathcerts,1,10);
   seq_no_enc = substr(charsseq,1,10);
   predict = substr(predictions_2011b,1,1);
run;
/*
find the CHARS records that linked to more than one death certificate
(there are 7 CHARS records that each linked to 2 death certs)
*/
proc freq data=links1 noprint;
   tables seq_no_enc/out=charslist;
run;
data mults1(drop=percent);
   set charslist(where=(count ge 2));
run;
proc sort data=links1;
   by seq_no_enc;
run;
data mults2;
   merge links1 mults1(in=inmult);
   by seq_no_enc;
   if inmult;
run;
/*
I'll guess that all these pairs are in the dataset with high scores,
   and I will get the detailed information from there.
*/
proc sort data=dihd.link2011;
   by certno seq_no_enc;
run;
proc sort data=mults2;
   by certno seq_no_enc;
run;

data mults3;
   merge dihd.link2011 mults2(in=inmult);
   by certno seq_no_enc;
   if inmult;
run;
proc print data=mults3;
run;
/*
I code the pairs by hand and enter the data here
*/
data mults4;
   input @1 certno $char10. @12 seq_no_enc $char10. @23 link $char1.;
datalines;
2011050070 2010130586 N
2011050070 2011112553 N
2011050070 2011212287 N
2011050070 2011385211 N
2011050070 2011445277 N
2011050070 2011547660 N
2011050070 2011612676 N
2011057314 2010130586 L
2011057314 2011112553 L
2011057314 2011212287 L
2011057314 2011385211 L
2011057314 2011445277 L
2011057314 2011547660 L
2011057314 2011612676 L
;;
run;
proc sort data=links1;
   by certno seq_no_enc;
run;
data links2(keep=certno seq_no_enc);
   merge links1 mults4;
   by certno seq_no_enc;
   if link = '' then match = predict;
   else              match = link;
   if match = 'L' then output;
run;

/*
read in the reviewed links for pairs which had high scores but
   non-matching birthdates
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2011_done.xls"
   dbms = excel5
   ;
run;
data mlinks1(keep=certno seq_no_enc sc link);
   length certno seq_no_enc $ 10;
   retain i 0;
   set review3;
   certno = substr(dcert,1,10);
   seq_no_enc = substr(cseq,1,10);
   i+1;
   if i = 1 then output;
   if i = 3 then i = 0;
run;
proc freq data=mlinks1;
   tables sc*link/norow nocol nopercent;
run;
/*
this table shows the strong relation between score and link status
      The SAS System                    12:04 Friday, July 11, 2014 122

           The FREQ Procedure

          Table of SC by LINK

  SC(SC)     LINK(LINK)

  Frequency|       0|       1|  Total
  ---------+--------+--------+
        30 |     36 |     14 |     50
  ---------+--------+--------+
        32 |    803 |     13 |    816
  ---------+--------+--------+
        33 |      1 |      1 |      2
  ---------+--------+--------+
        34 |     99 |      4 |    103
  ---------+--------+--------+
        35 |      5 |      6 |     11
  ---------+--------+--------+
        37 |    178 |     20 |    198
  ---------+--------+--------+
        38 |      1 |      0 |      1
  ---------+--------+--------+
        39 |      0 |      6 |      6
  ---------+--------+--------+
        40 |      0 |      4 |      4
  ---------+--------+--------+
        42 |     11 |     38 |     49
  ---------+--------+--------+
        43 |      0 |      6 |      6
  ---------+--------+--------+
        44 |      6 |      7 |     13
  ---------+--------+--------+
        45 |      0 |      7 |      7
  ---------+--------+--------+
        47 |      3 |     40 |     43
  ---------+--------+--------+
        48 |      0 |      1 |      1
  ---------+--------+--------+
        49 |      4 |     25 |     29
  ---------+--------+--------+
        50 |      0 |     18 |     18
  ---------+--------+--------+
        52 |      1 |     92 |     93
  ---------+--------+--------+
        53 |      0 |      6 |      6
  ---------+--------+--------+
        54 |      0 |      3 |      3
  ---------+--------+--------+
        55 |      0 |      4 |      4
  ---------+--------+--------+
        57 |      0 |    135 |    135
  ---------+--------+--------+
        59 |      0 |     14 |     14
  ---------+--------+--------+
        60 |      0 |     12 |     12
  ---------+--------+--------+
        62 |      0 |    271 |    271
  ---------+--------+--------+
        64 |      0 |      1 |      1
  ---------+--------+--------+
        65 |      0 |     13 |     13
  ---------+--------+--------+
        67 |      0 |     95 |     95
  ---------+--------+--------+
        68 |      0 |      3 |      3
  ---------+--------+--------+
        69 |      0 |      1 |      1
  ---------+--------+--------+
        70 |      0 |     13 |     13
  ---------+--------+--------+
        72 |      0 |    265 |    265
  ---------+--------+--------+
        74 |      0 |      1 |      1
  ---------+--------+--------+
        75 |      0 |      3 |      3
  ---------+--------+--------+
        77 |      0 |     32 |     32
  ---------+--------+--------+
        80 |      0 |      1 |      1
  ---------+--------+--------+
        82 |      0 |     21 |     21
  ---------+--------+--------+
        85 |      0 |      4 |      4
  ---------+--------+--------+
        87 |      0 |     49 |     49
  ---------+--------+--------+
  Total        1148     1249     2397
*/
data mlinks2(keep=certno seq_no_enc);
   set mlinks1(where=(link=1));
run;
data dihd.finallink2011;
   set links2 mlinks2;
run;

proc freq data=dihd.finallink2011 noprint;
   tables certno/out=dcertlist;
run;
/*
I found that 35,736 death certificates linked to 90,371
hospital records.
*/
\end{lstlisting}

\subsection{DIHD file for 2010}


\begin{lstlisting}[language=sas,caption=create death file for linking]
/*
Step 1. read the death file with names
*/
libname death 'c:\data\death';
libname chars 'c:\data\chars';

data names;
   infile "c:\data\death\deathnames\deathnamesv3.2010" lrecl=241;
   input
      @1   certno     $char10.
      @11  lastname   $char50.
      @61  firstname  $char30.
      @91  middlename $char40.
      @131 suffix     $char4.
      @158 ssnL4      $char4.
      @162 street     $char35.
      @197 city       $char30.
      @236 statecode  $char2.
      ;
run;
/*
Step 2. merge with standard death file
*/
proc sort data=names;
   by certno;
run;
proc sort data=death.dea2010
      out=stats(keep=certno age dob sex cnty_res zipcode dth_date race_wht race_blk
      race_ami race_asi race_chi race_fil race_gua race_haw race_jap race_kor
      race_opi race_oas race_oth race_sam race_vie hisp zipcode facility fac_type);
   by certno;
run;
/*
combine statistical and name files, and recode race fields to match the reduced
set in the CHARS file (which has only white, black, american indian or alaska
native, asian, hawaiian or other Pacific Islander)
*/
data dwnames(drop=sum_race_asi sum_race_haw race_temp1 race_temp2 race_chi race_fil
          race_gua race_jap race_kor race_opi race_oas race_oth race_sam
          race_vie firsttemp lasttemp middlename hisp firsttemp2 lasttemp2);
   length firstname lastname $ 20 miname hispanic $ 1 lastname_sdx firstname_sdx $ 4
          firsttemp2 lasttemp2 $ 25;
   merge stats(rename=(race_asi=race_temp1 race_haw=race_temp2))
         names(rename=(firstname=firsttemp lastname=lasttemp));
   by certno;
   firsttemp2 = compress(firsttemp," '`-_,.&");
   lasttemp2  = compress(lasttemp," '`-_,.&");
   firstname = substr(firsttemp2,1,20);
   lastname  = substr(lasttemp2,1,20);
   miname    = substr(middlename,1,1);
   sum_race_asi = min(1,(race_chi='Y')+(race_fil='Y')+(race_jap='Y')+(race_kor='Y')+
                    (race_oas='Y')+(race_vie='Y')+(race_temp1='Y'));
   sum_race_haw = min(1,(race_gua='Y')+(race_opi='Y')+(race_sam='Y')+(race_temp2='Y'));

   if sum_race_asi = 0 then race_asi = 'N';
   else                     race_asi = 'Y';
   if sum_race_haw = 0 then race_haw = 'N';
   else                     race_haw = 'Y';
   if race_ami in ('') then race_ami = 'U';
   if race_asi in ('') then race_asi = 'U';
   if race_blk in ('') then race_blk = 'U';
   if race_haw in ('') then race_haw = 'U';
   if race_wht in ('') then race_wht = 'U';
   if ssnL4 = '9999'      then ssnL4 = '';
   select(hisp);
      when('0')                 hispanic = 'N';
      when('1','2','3','4','5') hispanic = 'Y';
      when('','9')              hispanic = 'U';
      end;
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);

   format dob mmddyy10.;
run;
\end{lstlisting}

\begin{lstlisting}[language=sas,caption=Create CHARS file for linking]
data clink0910(keep=seq_no_enc adm_date age country countyres dis_date dob firstname
                ssnL4 hispanic hospital lastname miname race_ami race_asi race_blk
                race_haw race_wht sex statecode status zipcode zipplus4
                lastname_sdx firstname_sdx suffix);
   length firstname lastname $ 20 suffix $ 4 lastname_sdx firstname_sdx $ 4 statecode $ 2;
   set chars.chr_r2009(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp))
       chars.chr_r2010(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp));
   if race_ami in ('','R') then race_ami = 'U';
   if race_asi in ('','R') then race_asi = 'U';
   if race_blk in ('','R') then race_blk = 'U';
   if race_haw in ('','R') then race_haw = 'U';
   if race_wht in ('','R') then race_wht = 'U';
   if hispanic in ('','R') then hispanic = 'U';
   if ssnL4 = '9999'      then ssnL4 = '';
/*
remove the suffixes II, III, IV, V, VI, VII, VIII, ESQ, JR, and SR
from lastnames and place them in a separate suffix field.
Used with UB04 data.
*/
   if _N_ = 1 then do;
   	retain __re __reIII;
   	pattern = "/( II| III| IV| V| VI| VII| VIII| ESQ|.JR|.SR)$/i";
   	__re = prxparse(pattern);
   	__reIII = prxparse('/III$/');
   end;
   lasttemp = translate(lasttemp,' ','.,');
   call prxsubstr(__re, TRIM(lasttemp), position, length);
   if position ^= 0 then do;
   	suffix    = substr(lasttemp, position + 1, length - 1);
   	lasttemp2 = substr(lasttemp, 1, position - 1);
   end;
   else lasttemp2 = lasttemp;

   firstname = compress(firsttemp," '`-_,.&");
   lastname  = compress(lasttemp2," '`-_,.&");
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);
*   statecode = put(stateres,$stateres.);
   statecode = stateres;
*   if not ('01' le statecode le '69') then statecode = '99';
   if statecode = 'XX' then statecode = '';
run;
\end{lstlisting}


\begin{lstlisting}[language=sas,caption=compute test link scores]
libname dihd 'c:\data\dihd';

/*
For each record, I will evaluate its similarity with each of the other records
by computing a score using the points described above. In the output dataset,
I will keep records that have a score of at least 0.
Maximum score is 112.
*/
data dihd.link2010;
   set clink0910(rename=(
     age           = c_age
     countyres     = c_cnty_res
     dob           = c_dob
     firstname     = c_firstname
     hispanic      = c_hispanic
     lastname      = c_lastname
     miname        = c_miname
     race_ami      = c_race_ami
     race_asi      = c_race_asi
     race_blk      = c_race_blk
     race_haw      = c_race_haw
     race_wht      = c_race_wht
     sex           = c_sex
     zipcode       = c_zipcode
     firstname_sdx = c_firstname_sdx
     lastname_sdx  = c_lastname_sdx
     ssnl4         = c_ssnl4
     statecode     = c_statecode
     ));
   do i = 1 to 49190;
      set dwnames point=i;
      score =
      (age           = c_age           and age          ne .)*5  +
      (age           ne c_age          )*(-5) +
      (cnty_res      = c_cnty_res      and cnty_res     ne '')*3  +
      (cnty_res      ne c_cnty_res     )*(-5) +
      (dob           = c_dob           and dob          ne .)*20  +
      (dob           ne c_dob          )*(-20) +
      (month(dob)    = month(c_dob)    and dob          ne .)*3   +
      (month(dob)    ne month(c_dob)   )*(-5)  +
      (day(dob)      = day(c_dob)      and dob          ne .)*4   +
      (day(dob)      ne day(c_dob)     )*(-4)   +
      (year(dob)     = year(c_dob)     and dob          ne .)*4   +
      (year(dob)     ne year(c_dob)    )*(-4)   +
      (firstname     = c_firstname     and firstname    ne '')*10 +
      (firstname     ne c_firstname    )*(-10) +
      (hispanic      = c_hispanic      and hispanic     ne '')*5  +
      (hispanic      ne c_hispanic     )*(-5) +
      (lastname      = c_lastname      and lastname     ne '')*15  +
      (lastname      ne c_lastname     )*(-15) +
      (miname        = c_miname        and miname       ne '')*2  +
      (miname        ne c_miname       )*(-3) +
      (race_ami      = c_race_ami      and race_ami     ne '')*5  +
      (race_ami      ne c_race_ami     )*(-5) +
      (race_asi      = c_race_asi      and race_asi     ne '')*5  +
      (race_asi      ne c_race_asi     )*(-5) +
      (race_blk      = c_race_blk      and race_blk     ne '')*5  +
      (race_blk      ne c_race_blk     )*(-5) +
      (race_haw      = c_race_haw      and race_haw     ne '')*5  +
      (race_haw      ne c_race_haw     )*(-5) +
      (race_wht      = c_race_wht      and race_wht     ne '')*5  +
      (race_wht      ne c_race_wht     )*(-5) +
      (sex           = c_sex           and sex          ne '')*2  +
      (sex           ne c_sex          )*(-20) +
      (zipcode       = c_zipcode       and zipcode      ne '')*3  +
      (zipcode       ne c_zipcode      )*(-2) +
      (firstname_sdx = c_firstname_sdx and firstname_sdx ne '')*2  +
      (firstname_sdx ne c_firstname_sdx)*(-10) +
      (lastname_sdx  = c_lastname_sdx  and lastname_sdx ne '')*4  +
      (lastname_sdx  ne c_lastname_sdx )*(-10) +
      (ssnl4         = c_ssnl4         and ssnl4        ne '')*15  +
      (ssnl4         ne c_ssnl4        )*(-10) +
      (statecode     = c_statecode     and statecode       ne '')*1  +
      (statecode     ne c_statecode    )*(-5) +
      (status = '20' and dth_date = dis_date)*10 +
      (status = '20' and dth_date ne dis_date)*(-10) +
      (status = '20' and facility = substr(hospital,1,3))*5 +
      (status = '20' and facility ne substr(hospital,1,3))*(-10) +
      (dis_date ge dth_date + 2)*(-20)
      ;

      if score ge 0 then output;
      *output;

      end;
run;
proc print data=dihd.link2010(obs=21 );
   var score certno firstname c_firstname lastname c_lastname miname c_miname dob c_dob
       ssnL4 c_ssnL4 age c_age sex c_sex cnty_res c_cnty_res statecode c_statecode
       race_ami c_race_ami race_asi c_race_asi race_blk c_race_blk race_haw c_race_haw
       race_wht c_race_wht hispanic c_hispanic;
run;
/*
did any pairs have a high score without birthdate matching?
*/
proc freq data=dihd.link2010;
   where dob ne c_dob;
   tables score;
run;
\end{lstlisting}

\begin{lstlisting}[language=sas,caption=write death and CHARS files to csv for R]
/*
the length statements are to ensure fields are in a consistent order
when I read them into R, and the fields are ordered for easiest use
during the classification of the training set.
I delete the records that have no names or SSN (typically these are
deaths that occurred out-of-state).
*/
data dwnames2;
   length certno $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 cnty_res $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 deathfirst $ 20 deathlast $ 20;
   set dwnames;
   keep certno cnty_res dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date deathfirst deathlast suffix
        ;
   if firstname in ('B','BABY','BABYBOY','BABYGIRL','BOY','GIRL')
      then firstname = '';
   deathfirst = firstname;
   deathlast  = lastname;
   if firstname = '' and lastname = '' then delete;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 = '9999' then ssnL4 = '';
   format dth_date mmddyy10.;
run;
proc export data=dwnames2
   outfile = "c:\data\DIHD\death2010.txt"
   dbms = csv
   replace
   ;
run;

data clink2;
   length seq_no_enc $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 countyres $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 charslast $ 20 charsfirst $ 20;
   set clink0910;
   if status = '20' then do;
      facility = substr(hospital,1,3);
      dth_date = dis_date;
      end;
   else do;
      facility = '';
      dth_date = .;
      end;
   if firstname in ('B','BABY','BABYBOY','BABYGIRL',
      'BOY','GIRL','BB','BBABY','BABYA','BABYB','BABYBOY',
      'BABYG','BABYGIRL','BABYTWIN','BABYABOY','BABYBGIRL',
      'BABYBOY','BABYBOYA','BABYBOYB','BABYFEMAL','BABYFEMALE',
      'BABYGIRL','BABYGIRLA','BABYGIRLB','BABYMALE','BABYONE',
      'BABYTWO')
      then firstname = '';
   charsfirst = firstname;
   charslast = lastname;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 = '9999' then ssnL4 = '';
   keep seq_no_enc countyres dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date charsfirst charslast suffix;
   format dth_date mmddyy10.;
run;
proc export data=clink2
   outfile = "c:\data\DIHD\chars2009_2010.txt"
   dbms = csv
   replace
   ;
run;
\end{lstlisting}


\bfs
\begin{verbatim}
%<<>>=
library(RecordLinkage)

# save the previous training set, model, and results
save(list=c('pairs2011.fsWt','train2011.a','model2011.bag','result2011.bag',
        'manualreview2011.b','predictions.2011b','links2011'),file='Classifier2011')

death2010 <- read.csv("../../../data/DIHD/death2010.txt",colClasses=c(rep("character",18)),
                      col.names=c("certno","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "death.first","death.last"))
death2010$firstname.sdx <- soundex(death2010$firstname)
death2010$lastname.sdx  <- soundex(death2010$lastname)

chars0910 <- read.csv("../../../data/DIHD/chars2009_2010.txt",colClasses=c(rep("character",18)),
                      col.names=c("seq_no_enc","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "chars.last","chars.first"))
chars0910$firstname.sdx <- soundex(chars0910$firstname)
chars0910$lastname.sdx  <- soundex(chars0910$lastname)

pairs2010 <- compare.linkage(death2010,chars0910,blockfld=c(2),exclude=c(1))

# calculate Fellegi-Sunter weights
pairs2010.fsWt <- fsWeights(pairs2010)

# use the model that was trained on the 2011 data.
result2010.bag <- classifySupv(model2011.bag,newdata=pairs2010.fsWt)

manualreview2010 <- result2010.bag[(result2010.bag$prediction=='L'&result2010.bag$Wdata<=30)|
                     (result2010.bag$prediction=='N'&result2010.bag$Wdata>=30)]

manualreview2010 <- editMatch(manualreview2010)

%@
\end{verbatim}
\efs

This shows the relationships between the weight, the machine
prediction, and the manual classification on the records that I
manually reviewed:

\bvm
> with(manualreview2010[manualreview2010$Wdata<0],table(pairs$is_match,prediction))
   prediction
     N  P  L
  0  0  0  7
  1  0  0 45
> with(manualreview2010[manualreview2010$Wdata>=0&manualreview2010$Wdata<10],table(pairs$is_match,prediction))
   prediction
     N  P  L
  0  0  0 17
  1  0  0 80
> with(manualreview2010[manualreview2010$Wdata>=10&manualreview2010$Wdata<20],table(pairs$is_match,prediction))
   prediction
      N   P   L
  0   0   0  20
  1   0   0 182
> with(manualreview2010[manualreview2010$Wdata>=20&manualreview2010$Wdata<30],table(pairs$is_match,prediction))
   prediction
      N    P    L
  0   0    0    9
  1   0    0  430
> with(manualreview2010[manualreview2010$Wdata>=30&manualreview2010$Wdata<40],table(pairs$is_match,prediction))
   prediction
      N   P  L
  0  75   0  0
  1  15   0  0
> with(manualreview2010[manualreview2010$Wdata>=40&manualreview2010$Wdata<50],table(pairs$is_match,prediction))
   prediction
     N  P  L
  0 28  0  0
  1 31  0  0
> with(manualreview2010[manualreview2010$Wdata>=50&manualreview2010$Wdata<60],table(pairs$is_match,prediction))
   prediction
     N  P  L
  1 19  0  0
> with(manualreview2010[manualreview2010$Wdata>=60],table(pairs$is_match,prediction))
   prediction
    N P L
  1 2 0 0
\end{verbatim}

In tabular form:

When the machine predicted a link (I manually reviewed all pairs where
the weight was 30 or less and the machine predicted a link):

\begin{tabular}{rrrr}
weight & match & not & \% not match \\ \hline
$< 0$  & 45 & 7  & 13 \\
0--10  & 80 & 17 & 18 \\
10--20 &182 & 20 & 10 \\
20--30 &430 &  9 &  2 \\
\end{tabular}

When the machine predicted a pair was not a link (I manually reviewed
all pairs where the weight was 30 or more and the machine predicted
the pair was not a link):

\begin{tabular}{rrrr}
weight & match & not & \% match \\ \hline
30--40 & 15 &   75 & 17 \\
40--50 & 31 &   28 & 53 \\
50--60 & 19 &    0 &100 \\
60 +   &  2 &    0 &100 \\
\end{tabular}

\bfs
\begin{verbatim}
%<<>>=
library(RecordLinkage)

manualreview2010.b <- manualreview2010
for(i in 1:length(manualreview2010$prediction)) {
      manualreview2010.b$prediction[i] <- if(manualreview2010$pairs$is_match[i]==0) 'N' else 'L'
}

predictions.2010a <- result2010.bag$prediction
index.r <- as.numeric(row.names(manualreview2010.b$pairs))
predictions.2010b <- predictions.2010a
predictions.2010b[index.r] <- manualreview2010.b$prediction

# combine death and CHARS row numbers with the predictions
newresults2010 <- cbind(result2010.bag$pairs[,c(1,2)],predictions.2010b)

# get death certificate numbers and CHARS seq number (seq_no_enc)
deathcerts <- result2010.bag$data1[newresults2010[,1],1]
charsseq <- result2010.bag$data2[newresults2010[,2],1]
newresults2010.b <- data.frame(deathcerts,charsseq,predictions.2010b)

%@
\end{verbatim}
\efs

\subsubsection{Manual review of records with non-matching birthdates}

Now I get a file of the record pairs which had a high matching score
(20 or higher)
with non-matching birthdates, and export them to an Excel spreadsheet to conduct a manual
review on them. I chose 20 as the cutoff score for manual review
because that provides a reasonable number of records for review (about
2,400 for 2010), but I think it includes nearly all the records that have much
chance of being classified a true match.

\begin{lstlisting}[language=sas,caption=get non-matching birthdate high scorers for manual review]
libname dihd 'c:\data\dihd';
data review1;
   set dihd.link2010(where=(dob ne c_dob and score ge 20));
run;
proc sort data=review1;
   by score;
run;
data review2(keep=dcert cseq bd fname mi lname ssn sx hosp dd zip county hisp rw
                  rb ram ras rh sc);
   length dcert $ 10 cseq $ 10 bd 8 fname $ 20 mi $ 1 lname $ 20 ssn $ 4 sx $ 1
          hosp $ 3 dd 8 zip $ 5 county $ 2 hisp rw rb ram ras rh $ 1
          sc 8;
   set review1;
   format bd dd mmddyy10.;

   dcert = certno;
   cseq = seq_no_enc;
   bd = dob;
   fname = firstname;
   mi = miname;
   lname = lastname;
   ssn = ssnL4;
   sx = sex;
   hosp = facility;
   dd = dth_date;
   zip = zipcode;
   county = cnty_res;
   hisp = hispanic;
   rw = race_wht;
   rb = race_blk;
   ram = race_ami;
   ras = race_asi;
   rh = race_haw;
   sc = score;
   output;

   bd = c_dob;
   fname = c_firstname;
   mi = c_miname;
   lname = c_lastname;
   ssn = c_ssnL4;
   sx = c_sex;
   if status = 20 or dis_date ge dth_date then do;
      hosp = hospital;
      dd = dis_date;
      end;
   else do;
      hosp = '';
      dd = .;
      end;
   zip = c_zipcode;
   county = c_cnty_res;
   hisp = c_hispanic;
   rw = c_race_wht;
   rb = c_race_blk;
   ram = c_race_ami;
   ras = c_race_asi;
   rh = c_race_haw;
   sc = .;
   output;

   bd = .;
   fname = '';
   mi = '';
   lname = '';
   ssn = '';
   sx = '';
   hosp = '';
   dd = .;
   zip = '';
   county = '';
   hisp = '';
   rw = '';
   rb = '';
   ram = '';
   ras = '';
   rh = '';
   sc = .;
   output;
run;

proc export data=review2
   outfile = "c:\user\projects\Death-CHARSlink\manreview2010.xls"
   dbms = excel5
   replace
   ;
run;
/*
read the reviewed links
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2010_done.xls"
   dbms = excel5
   ;
run;
\end{lstlisting}

Now I need to combine the links from three sources: the machine
learning results, the manual review of those results, and the manual
coding of the records on which birthdate didn't match. After combining
those links, I need to check whether there are any hospitalization
records linked to more than one death record, and if so, adjudicate
those links manually. Then I can create the final linked file.

\bfs
\begin{verbatim}
#create file containing only the linked pairs
links2010 <- newresults2010.b[newresults2010.b$predictions.2010b=='L',]

write.csv(links2010,file="c:/data/dihd/links2010.csv",row.names=F)

\end{verbatim}
\efs

\begin{lstlisting}[language=sas,caption=create final linked file for 2010]
libname dihd 'c:\data\dihd';

proc import out=links0
   file = "c:\data\dihd\links2010.csv"
   dbms = csv
   replace
   ;
run;
data links1(keep=certno seq_no_enc predict);
   length certno seq_no_enc $ 10 predict $ 1;
   set links0;
   certno = substr(deathcerts,1,10);
   seq_no_enc = substr(charsseq,1,10);
   predict = substr(predictions_2010b,1,1);
run;
/*
find the CHARS records that linked to more than one death certificate
(there are 4 CHARS records that each linked to 2 death certs)
*/
proc freq data=links1 noprint;
   tables seq_no_enc/out=charslist;
run;
data mults1(drop=percent);
   set charslist(where=(count ge 2));
run;
proc sort data=links1;
   by seq_no_enc;
run;
data mults2;
   merge links1 mults1(in=inmult);
   by seq_no_enc;
   if inmult;
run;
/*
I'll guess that all these pairs are in the dataset with high scores,
   and I will get the detailed information from there.
*/
proc sort data=dihd.link2010;
   by certno seq_no_enc;
run;
proc sort data=mults2;
   by certno seq_no_enc;
run;

data mults3;
   merge dihd.link2010 mults2(in=inmult);
   by certno seq_no_enc;
   if inmult;
run;
proc print data=mults3;
run;
/*
I code the pairs by hand and enter the data here
*/
data mults4;
   input @1 certno $char10. @12 seq_no_enc $char10. @23 link $char1.;
datalines;
2010005523 2010406851 N
2010005523 2010603970 L
2010005524 2010406851 L
2010005524 2010603970 N
2010008255 2010059679 N
2010008255 2010611929 L
2010008286 2010059679 L
2010008286 2010611929 N
;;
run;
proc sort data=links1;
   by certno seq_no_enc;
run;
data links2(keep=certno seq_no_enc);
   merge links1 mults4;
   by certno seq_no_enc;
   if link = '' then match = predict;
   else              match = link;
   if match = 'L' then output;
run;

/*
read in the reviewed links for pairs which had high scores but
   non-matching birthdates
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2010_done.xls"
   dbms = excel5
   replace
   ;
run;
data mlinks1(keep=certno seq_no_enc sc link);
   length certno seq_no_enc $ 10;
   retain i 0;
   set review3;
   certno = substr(dcert,1,10);
   seq_no_enc = substr(cseq,1,10);
   i+1;
   if i = 1 then output;
   if i = 3 then i = 0;
run;
proc freq data=mlinks1;
   tables sc*link/norow nocol nopercent;
run;
/*
this table shows the strong relation between score and link status
              The SAS System                                                                    11:35 Wednesday, July 16, 2014 2012

            The FREQ Procedure

           Table of SC by LINK

   SC(SC)     LINK(LINK)

   Frequency|       0|       1|  Total
   ---------+--------+--------+
         20 |     11 |      6 |     17
   ---------+--------+--------+
         21 |     63 |      6 |     69
   ---------+--------+--------+
         22 |    572 |      3 |    575
   ---------+--------+--------+
         23 |      3 |      5 |      8
   ---------+--------+--------+
         24 |    330 |      0 |    330
   ---------+--------+--------+
         25 |      5 |     13 |     18
   ---------+--------+--------+
         26 |     10 |      2 |     12
   ---------+--------+--------+
         27 |    100 |      0 |    100
   ---------+--------+--------+
         28 |      0 |      9 |      9
   ---------+--------+--------+
         29 |     31 |      0 |     31
   ---------+--------+--------+
         30 |     32 |      9 |     41
   ---------+--------+--------+
         31 |      7 |      5 |     12
   ---------+--------+--------+
         32 |     68 |      2 |     70
   ---------+--------+--------+
         33 |      0 |      8 |      8
   ---------+--------+--------+
         34 |      2 |      1 |      3
   ---------+--------+--------+
         35 |      7 |     15 |     22
   ---------+--------+--------+
         36 |      0 |      3 |      3
   ---------+--------+--------+
         37 |      1 |      2 |      3
   ---------+--------+--------+
         38 |      1 |     29 |     30
   ---------+--------+--------+
         39 |      6 |      1 |      7
   ---------+--------+--------+
         40 |      3 |     35 |     38
   ---------+--------+--------+
         41 |      0 |      1 |      1
   ---------+--------+--------+
         42 |      1 |      7 |      8
   ---------+--------+--------+
         43 |      0 |     14 |     14
   ---------+--------+--------+
         44 |      0 |      7 |      7
   ---------+--------+--------+
         45 |      1 |     52 |     53
   ---------+--------+--------+
         46 |      0 |      2 |      2
   ---------+--------+--------+
         47 |      0 |      5 |      5
   ---------+--------+--------+
         48 |      0 |      3 |      3
   ---------+--------+--------+
         49 |      0 |      5 |      5
   ---------+--------+--------+
         50 |      1 |     43 |     44
   ---------+--------+--------+
         51 |      0 |      1 |      1
   ---------+--------+--------+
         52 |      0 |     21 |     21
   ---------+--------+--------+
         53 |      0 |      9 |      9
   ---------+--------+--------+
         55 |      0 |     86 |     86
   ---------+--------+--------+
         56 |      0 |      2 |      2
   ---------+--------+--------+
         57 |      0 |     14 |     14
   ---------+--------+--------+
         58 |      0 |      4 |      4
   ---------+--------+--------+
         60 |      0 |    126 |    126
   ---------+--------+--------+
         61 |      0 |      1 |      1
   ---------+--------+--------+
         62 |      0 |      6 |      6
   ---------+--------+--------+
         63 |      0 |     19 |     19
   ---------+--------+--------+
         64 |      0 |      1 |      1
   ---------+--------+--------+
         65 |      0 |    222 |    222
   ---------+--------+--------+
         67 |      0 |     12 |     12
   ---------+--------+--------+
         68 |      0 |      7 |      7
   ---------+--------+--------+
         70 |      0 |     65 |     65
   ---------+--------+--------+
         71 |      0 |      1 |      1
   ---------+--------+--------+
         72 |      0 |      1 |      1
   ---------+--------+--------+
         73 |      0 |     17 |     17
   ---------+--------+--------+
         75 |      0 |    156 |    156
   ---------+--------+--------+
         77 |      0 |      1 |      1
   ---------+--------+--------+
         78 |      0 |      3 |      3
   ---------+--------+--------+
         80 |      0 |     28 |     28
   ---------+--------+--------+
         82 |      0 |      3 |      3
   ---------+--------+--------+
         85 |      0 |      9 |      9
   ---------+--------+--------+
         88 |      0 |      6 |      6
   ---------+--------+--------+
         90 |      0 |     35 |     35
   ---------+--------+--------+
   Total        1255     1149     2404
*/
data mlinks2(keep=certno seq_no_enc);
   set mlinks1(where=(link=1));
run;
data dihd.finallink2010;
   set links2 mlinks2;
run;

proc freq data=dihd.finallink2010 noprint;
   tables certno/out=dcertlist;
run;
/*
I found that 34,571 death certificates linked to 87,536
hospital records.
*/
\end{lstlisting}


\subsection{Expanded files}

To create the expanded files I need to link the 2012 deaths to the
2009 and 2010 CHARS records, and the 2011 deaths to the 2009 CHARS
records.

\subsubsection{2012}

First, do 2012 deaths---2009 and 2010 CHARS:

\begin{lstlisting}[language=sas,caption=create death file for linking]
/*
Step 1. read the death file with names
*/
libname death 'c:\data\death';
libname chars 'c:\data\chars';

data names;
   infile "c:\data\death\deathnames\deathnamesv3.2012" lrecl=241;
   input
      @1   certno     $char10.
      @11  lastname   $char50.
      @61  firstname  $char30.
      @91  middlename $char40.
      @131 suffix     $char4.
      @142 ssnL4      $char4.
      @146 street     $char35.
      @181 city       $char30.
      @213 statecode  $char2.
      ;
run;
/*
Step 2. merge with standard death file
*/
proc sort data=names;
   by certno;
run;
proc sort data=death.dea2012
      out=stats(keep=certno age dob sex cnty_res zipcode dth_date race_wht race_blk
      race_ami race_asi race_chi race_fil race_gua race_haw race_jap race_kor
      race_opi race_oas race_oth race_sam race_vie hisp zipcode facility fac_type);
   by certno;
run;
/*
combine statistical and name files, and recode race fields to match the reduced
set in the CHARS file (which has only white, black, american indian or alaska
native, asian, hawaiian or other Pacific Islander)
*/
proc format;
   value $stateres
     '01' = 'AL'
     '02' = 'AK'
     '03' = 'AZ'
     '04' = 'AR'
     '05' = 'CA'
     '06' = 'CO'
     '07' = 'CT'
     '08' = 'DE'
     '09' = 'DC'
     '10' = 'FL'
     '11' = 'GA'
     '12' = 'HI'
     '13' = 'ID'
     '14' = 'IL'
     '15' = 'IN'
     '16' = 'IA'
     '17' = 'KS'
     '18' = 'KY'
     '19' = 'LA'
     '20' = 'ME'
     '21' = 'MD'
     '22' = 'MA'
     '23' = 'MI'
     '24' = 'MN'
     '25' = 'MS'
     '26' = 'MO'
     '27' = 'MT'
     '28' = 'NE'
     '29' = 'NV'
     '30' = 'NH'
     '31' = 'NJ'
     '32' = 'NM'
     '33' = 'NY'
     '34' = 'NC'
     '35' = 'ND'
     '36' = 'OH'
     '37' = 'OK'
     '38' = 'OR'
     '39' = 'PA'
     '40' = 'RI'
     '41' = 'SC'
     '42' = 'SD'
     '43' = 'TN'
     '44' = 'TX'
     '45' = 'UT'
     '46' = 'VT'
     '47' = 'VA'
     '48' = 'WA'
     '49' = 'WV'
     '50' = 'WI'
     '51' = 'WY'
     '52' = 'PR'
     '53' = 'VI'
     '54' = 'GU'
     '55' = 'XX'
     '57' = 'XX'
     '59' = 'XX'
     '99' = 'XX'
     '60' = 'AS'
     '69' = 'MP'
      ;
run;
data dwnames(drop=sum_race_asi sum_race_haw race_temp1 race_temp2 race_chi race_fil
          race_gua race_jap race_kor race_opi race_oas race_oth race_sam
          race_vie firsttemp lasttemp middlename hisp firsttemp2
          lasttemp2 statetemp);
   length firstname lastname $ 20 miname hispanic $ 1 lastname_sdx firstname_sdx $ 4
          firsttemp2 lasttemp2 $ 25 statecode $ 2;
   merge stats(rename=(race_asi=race_temp1 race_haw=race_temp2))
         names(rename=(firstname=firsttemp lastname=lasttemp statecode=statetemp));
   by certno;
   firsttemp2 = compress(firsttemp," '`-_,.&");
   lasttemp2  = compress(lasttemp," '`-_,.&");
   firstname = substr(firsttemp2,1,20);
   lastname  = substr(lasttemp2,1,20);
   miname    = substr(middlename,1,1);
   sum_race_asi = min(1,(race_chi='Y')+(race_fil='Y')+(race_jap='Y')+(race_kor='Y')+
                    (race_oas='Y')+(race_vie='Y')+(race_temp1='Y'));
   sum_race_haw = min(1,(race_gua='Y')+(race_opi='Y')+(race_sam='Y')+(race_temp2='Y'));

   if sum_race_asi = 0 then race_asi = 'N';
   else                     race_asi = 'Y';
   if sum_race_haw = 0 then race_haw = 'N';
   else                     race_haw = 'Y';
   if race_ami in ('') then race_ami = 'U';
   if race_asi in ('') then race_asi = 'U';
   if race_blk in ('') then race_blk = 'U';
   if race_haw in ('') then race_haw = 'U';
   if race_wht in ('') then race_wht = 'U';
   if ssnL4 = '9999'      then ssnL4 = '';
   select(hisp);
      when('0')                 hispanic = 'N';
      when('1','2','3','4','5') hispanic = 'Y';
      when('','9')              hispanic = 'U';
      end;
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);
   statecode = put(statetemp,$stateres.);
   if statecode = 'XX' then statecode = '';
   format dob mmddyy10.;
run;
\end{lstlisting}

\begin{lstlisting}[language=sas,caption=Create CHARS file for linking]
data clink0910(keep=seq_no_enc adm_date age country countyres dis_date dob firstname
                ssnL4 hispanic hospital lastname miname race_ami race_asi race_blk
                race_haw race_wht sex statecode status zipcode zipplus4
                lastname_sdx firstname_sdx suffix);
   length firstname lastname $ 20 suffix $ 4 lastname_sdx firstname_sdx $ 4 statecode $ 2;
   set chars.chr_r2009(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp))
       chars.chr_r2010(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp));
   if race_ami in ('','R') then race_ami = 'U';
   if race_asi in ('','R') then race_asi = 'U';
   if race_blk in ('','R') then race_blk = 'U';
   if race_haw in ('','R') then race_haw = 'U';
   if race_wht in ('','R') then race_wht = 'U';
   if hispanic in ('','R') then hispanic = 'U';
   if ssnL4 = '9999'      then ssnL4 = '';
/*
remove the suffixes II, III, IV, V, VI, VII, VIII, ESQ, JR, and SR
from lastnames and place them in a separate suffix field.
Used with UB04 data.
*/
   if _N_ = 1 then do;
   	retain __re __reIII;
   	pattern = "/( II| III| IV| V| VI| VII| VIII| ESQ|.JR|.SR)$/i";
   	__re = prxparse(pattern);
   	__reIII = prxparse('/III$/');
   end;
   lasttemp = translate(lasttemp,' ','.,');
   call prxsubstr(__re, TRIM(lasttemp), position, length);
   if position ^= 0 then do;
   	suffix    = substr(lasttemp, position + 1, length - 1);
   	lasttemp2 = substr(lasttemp, 1, position - 1);
   end;
   else lasttemp2 = lasttemp;

   firstname = compress(firsttemp," '`-_,.&");
   lastname  = compress(lasttemp2," '`-_,.&");
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);
   statecode = stateres;
   if statecode = 'XX' then statecode = '';
run;
\end{lstlisting}


\begin{lstlisting}[language=sas,caption=compute test link scores]
libname dihd 'c:\data\dihd';

/*
For each record, I will evaluate its similarity with each of the other records
by computing a score using the points described above. In the output dataset,
I will keep records that have a score of at least 0.
Maximum score is 112.
*/
data dihd.link2012plus;
   set clink0910(rename=(
     age           = c_age
     countyres     = c_cnty_res
     dob           = c_dob
     firstname     = c_firstname
     hispanic      = c_hispanic
     lastname      = c_lastname
     miname        = c_miname
     race_ami      = c_race_ami
     race_asi      = c_race_asi
     race_blk      = c_race_blk
     race_haw      = c_race_haw
     race_wht      = c_race_wht
     sex           = c_sex
     zipcode       = c_zipcode
     firstname_sdx = c_firstname_sdx
     lastname_sdx  = c_lastname_sdx
     ssnl4         = c_ssnl4
     statecode     = c_statecode
     ));
   do i = 1 to 51241;
      set dwnames point=i;
      score =
      (age           = c_age           and age          ne .)*5  +
      (age           ne c_age          )*(-5) +
      (cnty_res      = c_cnty_res      and cnty_res     ne '')*3  +
      (cnty_res      ne c_cnty_res     )*(-5) +
      (dob           = c_dob           and dob          ne .)*20  +
      (dob           ne c_dob          )*(-20) +
      (month(dob)    = month(c_dob)    and dob          ne .)*3   +
      (month(dob)    ne month(c_dob)   )*(-5)  +
      (day(dob)      = day(c_dob)      and dob          ne .)*4   +
      (day(dob)      ne day(c_dob)     )*(-4)   +
      (year(dob)     = year(c_dob)     and dob          ne .)*4   +
      (year(dob)     ne year(c_dob)    )*(-4)   +
      (firstname     = c_firstname     and firstname    ne '')*10 +
      (firstname     ne c_firstname    )*(-10) +
      (hispanic      = c_hispanic      and hispanic     ne '')*5  +
      (hispanic      ne c_hispanic     )*(-5) +
      (lastname      = c_lastname      and lastname     ne '')*15  +
      (lastname      ne c_lastname     )*(-15) +
      (miname        = c_miname        and miname       ne '')*2  +
      (miname        ne c_miname       )*(-3) +
      (race_ami      = c_race_ami      and race_ami     ne '')*3  +
      (race_ami      ne c_race_ami     )*(-2) +
      (race_asi      = c_race_asi      and race_asi     ne '')*3  +
      (race_asi      ne c_race_asi     )*(-2) +
      (race_blk      = c_race_blk      and race_blk     ne '')*3  +
      (race_blk      ne c_race_blk     )*(-2) +
      (race_haw      = c_race_haw      and race_haw     ne '')*3  +
      (race_haw      ne c_race_haw     )*(-2) +
      (race_wht      = c_race_wht      and race_wht     ne '')*3  +
      (race_wht      ne c_race_wht     )*(-2) +
      (sex           = c_sex           and sex          ne '')*2  +
      (sex           ne c_sex          )*(-20) +
      (zipcode       = c_zipcode       and zipcode      ne '')*3  +
      (zipcode       ne c_zipcode      )*(-2) +
      (firstname_sdx = c_firstname_sdx and firstname_sdx ne '')*2  +
      (firstname_sdx ne c_firstname_sdx)*(-10) +
      (lastname_sdx  = c_lastname_sdx  and lastname_sdx ne '')*4  +
      (lastname_sdx  ne c_lastname_sdx )*(-10) +
      (ssnl4         = c_ssnl4         and ssnl4        ne '')*15  +
      (ssnl4         ne c_ssnl4        )*(-10) +
      (statecode     = c_statecode     and statecode       ne '')*1  +
      (statecode     ne c_statecode    )*(-5) +
      (status = '20' and dth_date = dis_date)*10 +
      (status = '20' and dth_date ne dis_date)*(-10) +
      (status = '20' and facility = substr(hospital,1,3))*5 +
      (status = '20' and facility ne substr(hospital,1,3))*(-10) +
      (dis_date ge dth_date + 2)*(-20)
      ;

      if score ge 0 then output;
      *output;

      end;
run;
proc print data=dihd.link2012plus(obs=21 );
   var score certno firstname c_firstname lastname c_lastname miname c_miname dob c_dob
       ssnL4 c_ssnL4 age c_age sex c_sex cnty_res c_cnty_res statecode c_statecode
       race_ami c_race_ami race_asi c_race_asi race_blk c_race_blk race_haw c_race_haw
       race_wht c_race_wht hispanic c_hispanic;
run;
/*
did any pairs have a high score without birthdate matching?
*/
proc freq data=dihd.link2012plus;
   where dob ne c_dob;
   tables score;
run;
\end{lstlisting}

\begin{lstlisting}[language=sas,caption=write death and CHARS files to csv for R]
/*
the length statements are to ensure fields are in a consistent order
when I read them into R, and the fields are ordered for easiest use
during the classification of the training set.
I delete the records that have no names or SSN (typically these are
deaths that occurred out-of-state).
*/
data dwnames2;
   length certno $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 cnty_res $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 deathfirst $ 20 deathlast $ 20;
   set dwnames;
   keep certno cnty_res dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date deathfirst deathlast suffix
        ;
   if firstname in ('B','BABY','BABYBOY','BABYGIRL','BOY','GIRL')
      then firstname = '';
   deathfirst = firstname;
   deathlast  = lastname;
   if firstname = '' and lastname = '' then delete;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 = '9999' then ssnL4 = '';
   format dth_date mmddyy10.;
run;
proc export data=dwnames2
   outfile = "c:\data\DIHD\death2012.txt"
   dbms = csv
   replace
   ;
run;

data clink2;
   length seq_no_enc $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 countyres $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 charslast $ 20 charsfirst $ 20;
   set clink0910;
   if status = '20' then do;
      facility = substr(hospital,1,3);
      dth_date = dis_date;
      end;
   else do;
      facility = '';
      dth_date = .;
      end;
   if firstname in ('B','BABY','BABYBOY','BABYGIRL',
      'BOY','GIRL','BB','BBABY','BABYA','BABYB','BABYBOY',
      'BABYG','BABYGIRL','BABYTWIN','BABYABOY','BABYBGIRL',
      'BABYBOY','BABYBOYA','BABYBOYB','BABYFEMAL','BABYFEMALE',
      'BABYGIRL','BABYGIRLA','BABYGIRLB','BABYMALE','BABYONE',
      'BABYTWO')
      then firstname = '';
   charsfirst = firstname;
   charslast = lastname;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 = '9999' then ssnL4 = '';
   keep seq_no_enc countyres dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date charsfirst charslast suffix;
   format dth_date mmddyy10.;
run;
proc export data=clink2
   outfile = "c:\data\DIHD\chars2009_2010.txt"
   dbms = csv
   replace
   ;
run;
\end{lstlisting}


\bfs
\begin{verbatim}
%<<>>=
library(RecordLinkage)

death2012 <- read.csv("../../../data/DIHD/death2012.txt",colClasses=c(rep("character",18)),
                      col.names=c("certno","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "death.first","death.last"))
death2012$firstname.sdx <- soundex(death2012$firstname)
death2012$lastname.sdx  <- soundex(death2012$lastname)

chars0910 <- read.csv("../../../data/DIHD/chars2009_2010.txt",colClasses=c(rep("character",18)),
                      col.names=c("seq_no_enc","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "chars.last","chars.first"))
chars0910$firstname.sdx <- soundex(chars0910$firstname)
chars0910$lastname.sdx  <- soundex(chars0910$lastname)

pairs2012plus <- compare.linkage(death2012,chars0910,blockfld=c(2),exclude=c(1))

# calculate Fellegi-Sunter weights
pairs2012plus.fsWt <- fsWeights(pairs2012plus)

# use the model that was trained on the 2011 data.
result2012plus.bag <- classifySupv(model2011.bag,newdata=pairs2012plus.fsWt)

manualreview2012plus <- result2012plus.bag[(result2012plus.bag$prediction=='L'&
                          result2012plus.bag$Wdata<=30)|(result2012plus.bag$prediction=='N'&
                          result2012plus.bag$Wdata>=30)]

manualreview2012plus <- editMatch(manualreview2012plus)

%@
\end{verbatim}
\efs


\bfs
\begin{verbatim}
%<<>>=
library(RecordLinkage)

manualreview2012plus.b <- manualreview2012plus
for(i in 1:length(manualreview2012plus$prediction)) {
      manualreview2012plus.b$prediction[i] <- if(manualreview2012plus$pairs$is_match[i]==0) 'N' else 'L'
}

predictions.2012plusa <- result2012plus.bag$prediction
index.r <- as.numeric(row.names(manualreview2012plus.b$pairs))
predictions.2012plusb <- predictions.2012plusa
predictions.2012plusb[index.r] <- manualreview2012plus.b$prediction

# combine death and CHARS row numbers with the predictions
newresults2012plus <- cbind(result2012plus.bag$pairs[,c(1,2)],predictions.2012plusb)

# get death certificate numbers and CHARS seq number (seq_no_enc)
deathcerts <- result2012plus.bag$data1[newresults2012plus[,1],1]
charsseq <- result2012plus.bag$data2[newresults2012plus[,2],1]
newresults2012plus.b <- data.frame(deathcerts,charsseq,predictions.2012plusb)

%@
\end{verbatim}
\efs

\subsubsection{Manual review of records with non-matching birthdates}

Now I get a file of the record pairs which had a high matching score
(13 or higher)
with non-matching birthdates, and export them to an Excel spreadsheet to conduct a manual
review on them. I chose 10 as the cutoff score for manual review
because that provides a reasonable number of records for review (about
1,200 for 2010), but I think it includes nearly all the records that have much
chance of being classified a true match.

\begin{lstlisting}[language=sas,caption=get non-matching birthdate high scorers for manual review]
libname dihd 'c:\data\dihd';
data review1;
   set dihd.link2012plus(where=(dob ne c_dob and score ge 13));
run;
proc sort data=review1;
   by score;
run;
data review2(keep=dcert cseq bd fname mi lname ssn sx hosp dd zip county hisp rw
                  rb ram ras rh sc);
   length dcert $ 10 cseq $ 10 bd 8 fname $ 20 mi $ 1 lname $ 20 ssn $ 4 sx $ 1
          hosp $ 3 dd 8 zip $ 5 county $ 2 hisp rw rb ram ras rh $ 1
          sc 8;
   set review1;
   format bd dd mmddyy10.;

   dcert = certno;
   cseq = seq_no_enc;
   bd = dob;
   fname = firstname;
   mi = miname;
   lname = lastname;
   ssn = ssnL4;
   sx = sex;
   hosp = facility;
   dd = dth_date;
   zip = zipcode;
   county = cnty_res;
   hisp = hispanic;
   rw = race_wht;
   rb = race_blk;
   ram = race_ami;
   ras = race_asi;
   rh = race_haw;
   sc = score;
   output;

   bd = c_dob;
   fname = c_firstname;
   mi = c_miname;
   lname = c_lastname;
   ssn = c_ssnL4;
   sx = c_sex;
   if status = 20 or dis_date ge dth_date then do;
      hosp = hospital;
      dd = dis_date;
      end;
   else do;
      hosp = '';
      dd = .;
      end;
   zip = c_zipcode;
   county = c_cnty_res;
   hisp = c_hispanic;
   rw = c_race_wht;
   rb = c_race_blk;
   ram = c_race_ami;
   ras = c_race_asi;
   rh = c_race_haw;
   sc = .;
   output;

   bd = .;
   fname = '';
   mi = '';
   lname = '';
   ssn = '';
   sx = '';
   hosp = '';
   dd = .;
   zip = '';
   county = '';
   hisp = '';
   rw = '';
   rb = '';
   ram = '';
   ras = '';
   rh = '';
   sc = .;
   output;
run;

proc export data=review2
   outfile = "c:\user\projects\Death-CHARSlink\manreview2012plus.xls"
   dbms = excel5
   replace
   ;
run;
/*
read the reviewed links
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2012plus_done.xls"
   dbms = excel5
   ;
run;
\end{lstlisting}

Now I need to combine the links from three sources: the machine
learning results, the manual review of those results, and the manual
coding of the records on which birthdate didn't match. After combining
those links, I need to check whether there are any hospitalization
records linked to more than one death record, and if so, adjudicate
those links manually. Then I can create the final linked file.

\bfs
\begin{verbatim}
#create file containing only the linked pairs
links2012plus <- newresults2012plus.b[newresults2012plus.b$predictions.2012plusb=='L',]

write.csv(links2012plus,file="c:/data/dihd/links2012plus.csv",row.names=F)

\end{verbatim}
\efs

\begin{lstlisting}[language=sas,caption=create final expanded linked file for 2012]
libname dihd 'c:\data\dihd';

proc import out=links0
   file = "c:\data\dihd\links2012plus.csv"
   dbms = csv
   replace
   ;
run;
data links1(keep=certno seq_no_enc predict);
   length certno seq_no_enc $ 10 predict $ 1;
   set links0;
   certno = substr(deathcerts,1,10);
   seq_no_enc = substr(charsseq,1,10);
   predict = substr(predictions_2012plusb,1,1);
run;
/*
read in the reviewed links for pairs which had high scores but
   non-matching birthdates
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2012plus_done.xls"
   dbms = excel5
   replace
   ;
run;
data mlinks1(keep=certno seq_no_enc sc link);
   length certno seq_no_enc $ 10;
   retain i 0;
   set review3;
   certno = substr(dcert,1,10);
   seq_no_enc = substr(cseq,1,10);
   i+1;
   if i = 1 then output;
   if i = 3 then i = 0;
run;
proc freq data=mlinks1;
   tables sc*link/norow nocol nopercent;
run;
/*
this table shows the strong relation between score and link status
               The SAS System                                                                       12:19 Tuesday, July 22, 2014   3

             The FREQ Procedure

            Table of SC by LINK

    SC(SC)     LINK(LINK)

    Frequency|       0|       1|  Total
    ---------+--------+--------+
          13 |      0 |      5 |      5
    ---------+--------+--------+
          14 |    267 |      0 |    267
    ---------+--------+--------+
          15 |     11 |     19 |     30
    ---------+--------+--------+
          16 |     13 |      0 |     13
    ---------+--------+--------+
          17 |     96 |      4 |    100
    ---------+--------+--------+
          18 |      0 |      6 |      6
    ---------+--------+--------+
          19 |     25 |      0 |     25
    ---------+--------+--------+
          20 |     44 |     38 |     82
    ---------+--------+--------+
          21 |      3 |      0 |      3
    ---------+--------+--------+
          22 |     21 |      2 |     23
    ---------+--------+--------+
          23 |      1 |      2 |      3
    ---------+--------+--------+
          24 |      3 |      2 |      5
    ---------+--------+--------+
          25 |      7 |     33 |     40
    ---------+--------+--------+
          26 |      0 |      3 |      3
    ---------+--------+--------+
          27 |      1 |      0 |      1
    ---------+--------+--------+
          28 |      0 |      3 |      3
    ---------+--------+--------+
          29 |      0 |      4 |      4
    ---------+--------+--------+
          30 |      4 |     19 |     23
    ---------+--------+--------+
          31 |      0 |      1 |      1
    ---------+--------+--------+
          32 |      0 |      6 |      6
    ---------+--------+--------+
          34 |      0 |      2 |      2
    ---------+--------+--------+
          35 |      1 |      6 |      7
    ---------+--------+--------+
          36 |      0 |      3 |      3
    ---------+--------+--------+
          37 |      0 |      6 |      6
    ---------+--------+--------+
          38 |      0 |      2 |      2
    ---------+--------+--------+
          39 |      0 |      4 |      4
    ---------+--------+--------+
          40 |      0 |     51 |     51
    ---------+--------+--------+
          42 |      0 |     18 |     18
    ---------+--------+--------+
          43 |      0 |      4 |      4
    ---------+--------+--------+
          45 |      0 |     67 |     67
    ---------+--------+--------+
          47 |      0 |     12 |     12
    ---------+--------+--------+
          48 |      0 |     21 |     21
    ---------+--------+--------+
          50 |      0 |    106 |    106
    ---------+--------+--------+
          52 |      0 |      1 |      1
    ---------+--------+--------+
          53 |      0 |     18 |     18
    ---------+--------+--------+
          55 |      0 |    187 |    187
    ---------+--------+--------+
          60 |      0 |      2 |      2
    ---------+--------+--------+
          65 |      0 |      1 |      1
    ---------+--------+--------+
    Total         497      658     1155
*/
data mlinks2(keep=certno seq_no_enc);
   set mlinks1(where=(link=1));
run;
/*
combine links from the standard 2012 DIHD file, the new links from R,
and the new links from the mis-matched birth date records

Then check if any CHARS records linked to more than one death certificate
*/
data link2012plus;
   set dihd.finallink2012 links1(drop=predict) mlinks2;
run;
/*
check for CHARS records that linked to more than one death certificate
(there is one CHARS records that linked to 2 death certs, but it is
for the person who apparently has 2 death certs, so there is nothing I
can do.)
*/
proc freq data=link2012plus noprint;
   tables seq_no_enc/out=charslist;
run;
data mults1(drop=percent);
   set charslist(where=(count ge 2));
run;
proc sort data=link2012plus;
   by seq_no_enc;
run;
data mults2;
   merge link2012plus mults1(in=inmult);
   by seq_no_enc;
   if inmult;
run;
/*
This pairs are in the dataset with high scores,
   and I will get the detailed information from there.
*/
proc sort data=dihd.link2012;
   by certno seq_no_enc;
run;
proc sort data=mults2;
   by certno seq_no_enc;
run;
data mults3;
   merge dihd.link2012 mults2(in=inmult);
   by certno seq_no_enc;
   if inmult;
run;
proc print data=mults3;
run;
/*
create final linked file
*/
data dihd.finallink2012plus;
   set link2012plus;
run;

proc freq data=dihd.finallink2012plus noprint;
   tables certno/out=dcertlist;
run;
/*
I found that 40,007 death certificates from 2012 linked
to 132,204 hospital records from 2009-2012.
*/
\end{lstlisting}


\subsubsection{2011}

Now link the 2011 deaths to the 2009 CHARS file.

\begin{lstlisting}[language=sas,caption=create death file for linking]
Steps:
1. read the death file with names
2. merge with standard death file to add dob, age, sex, race,
*/
/*
Step 1. read the death file with names
*/
data names;
   infile "c:\data\death\deathnames\deathnamesv3.2011" lrecl=241;
   input
      @1   certno     $char10.
      @11  lastname   $char50.
      @61  firstname  $char30.
      @91  middlename $char40.
      @131 suffix     $char4.
      @158 ssnL4      $char4.
      @162 street     $char35.
      @197 city       $char30.
      @236 statecode  $char2.
      ;
run;
/*
Step 2. merge with standard death file
*/
proc sort data=names;
   by certno;
run;
proc sort data=death.dea2011
      out=stats(keep=certno age dob sex cnty_res zipcode dth_date race_wht race_blk
      race_ami race_asi race_chi race_fil race_gua race_haw race_jap race_kor
      race_opi race_oas race_oth race_sam race_vie hisp zipcode facility fac_type);
   by certno;
run;
/*
combine statistical and name files, and recode race fields to match the reduced
set in the CHARS file (which has only white, black, american indian or alaska
native, asian, hawaiian or other Pacific Islander)
*/
data dwnames(drop=sum_race_asi sum_race_haw race_temp1 race_temp2 race_chi race_fil
          race_gua race_jap race_kor race_opi race_oas race_oth race_sam
          race_vie firsttemp lasttemp middlename hisp firsttemp2 lasttemp2);
   length firstname lastname $ 20 miname hispanic $ 1 lastname_sdx firstname_sdx $ 4
          firsttemp2 lasttemp2 $ 25;
   merge stats(rename=(race_asi=race_temp1 race_haw=race_temp2))
         names(rename=(firstname=firsttemp lastname=lasttemp));
   by certno;
   firsttemp2 = compress(firsttemp," '`-_,.&");
   lasttemp2  = compress(lasttemp," '`-_,.&");
   firstname = substr(firsttemp2,1,20);
   lastname  = substr(lasttemp2,1,20);
   miname    = substr(middlename,1,1);
   sum_race_asi = min(1,(race_chi='Y')+(race_fil='Y')+(race_jap='Y')+(race_kor='Y')+
                    (race_oas='Y')+(race_vie='Y')+(race_temp1='Y'));
   sum_race_haw = min(1,(race_gua='Y')+(race_opi='Y')+(race_sam='Y')+(race_temp2='Y'));

   if sum_race_asi = 0 then race_asi = 'N';
   else                     race_asi = 'Y';
   if sum_race_haw = 0 then race_haw = 'N';
   else                     race_haw = 'Y';
   if race_ami in ('') then race_ami = 'U';
   if race_asi in ('') then race_asi = 'U';
   if race_blk in ('') then race_blk = 'U';
   if race_haw in ('') then race_haw = 'U';
   if race_wht in ('') then race_wht = 'U';
   if ssnL4 = '9999'      then ssnL4 = '';
   select(hisp);
      when('0')                 hispanic = 'N';
      when('1','2','3','4','5') hispanic = 'Y';
      when('','9')              hispanic = 'U';
      end;
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);

   format dob mmddyy10.;
run;
\end{lstlisting}

\begin{lstlisting}[language=sas,caption=Create CHARS file for linking]
data clink09(keep=seq_no_enc adm_date age country countyres dis_date dob firstname
                ssnL4 hispanic hospital lastname miname race_ami race_asi race_blk
                race_haw race_wht sex statecode status zipcode zipplus4
                lastname_sdx firstname_sdx suffix);
   length firstname lastname $ 20 suffix $ 4 lastname_sdx firstname_sdx $ 4 statecode $ 2;
   set chars.chr_r2009(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp));
   if race_ami in ('','R') then race_ami = 'U';
   if race_asi in ('','R') then race_asi = 'U';
   if race_blk in ('','R') then race_blk = 'U';
   if race_haw in ('','R') then race_haw = 'U';
   if race_wht in ('','R') then race_wht = 'U';
   if hispanic in ('','R') then hispanic = 'U';
   if ssnL4 = '9999'      then ssnL4 = '';
/*
remove the suffixes II, III, IV, V, VI, VII, VIII, ESQ, JR, and SR
from lastnames and place them in a separate suffix field.
Used with UB04 data.
*/
   if _N_ = 1 then do;
   	retain __re __reIII;
   	pattern = "/( II| III| IV| V| VI| VII| VIII| ESQ|.JR|.SR)$/i";
   	__re = prxparse(pattern);
   	__reIII = prxparse('/III$/');
   end;
   lasttemp = translate(lasttemp,' ','.,');
   call prxsubstr(__re, TRIM(lasttemp), position, length);
   if position ^= 0 then do;
   	suffix    = substr(lasttemp, position + 1, length - 1);
   	lasttemp2 = substr(lasttemp, 1, position - 1);
   end;
   else lasttemp2 = lasttemp;

   firstname = compress(firsttemp," '`-_,.&");
   lastname  = compress(lasttemp2," '`-_,.&");
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);
   statecode = stateres;
   if statecode = 'XX' then statecode = '';
run;
\end{lstlisting}

\begin{lstlisting}[language=sas,caption=compute test link scores]
libname dihd 'c:\data\dihd';

/*
For each record, I will evaluate its similarity with each of the other records
by computing a score using the points described above. In the output dataset,
I will keep records that have a score of at least 0.
Maximum score is ?.
*/
data dihd.link2011plus;
   set clink09(rename=(
     age           = c_age
     countyres     = c_cnty_res
     dob           = c_dob
     firstname     = c_firstname
     hispanic      = c_hispanic
     lastname      = c_lastname
     miname        = c_miname
     race_ami      = c_race_ami
     race_asi      = c_race_asi
     race_blk      = c_race_blk
     race_haw      = c_race_haw
     race_wht      = c_race_wht
     sex           = c_sex
     zipcode       = c_zipcode
     firstname_sdx = c_firstname_sdx
     lastname_sdx  = c_lastname_sdx
     ssnl4         = c_ssnl4
     statecode     = c_statecode
     ));
   do i = 1 to 50589;
      set dwnames point=i;
      score =
      (age           = c_age           and age          ne .)*5  +
      (age           ne c_age          )*(-5) +
      (cnty_res      = c_cnty_res      and cnty_res     ne '')*3  +
      (cnty_res      ne c_cnty_res     )*(-5) +
      (dob           = c_dob           and dob          ne .)*20  +
      (dob           ne c_dob          )*(-20) +
      (month(dob)    = month(c_dob)    and dob          ne .)*3   +
      (month(dob)    ne month(c_dob)   )*(-5)  +
      (day(dob)      = day(c_dob)      and dob          ne .)*4   +
      (day(dob)      ne day(c_dob)     )*(-4)   +
      (year(dob)     = year(c_dob)     and dob          ne .)*4   +
      (year(dob)     ne year(c_dob)    )*(-4)   +
      (firstname     = c_firstname     and firstname    ne '')*10 +
      (firstname     ne c_firstname    )*(-10) +
      (hispanic      = c_hispanic      and hispanic     ne '')*5  +
      (hispanic      ne c_hispanic     )*(-5) +
      (lastname      = c_lastname      and lastname     ne '')*15  +
      (lastname      ne c_lastname     )*(-15) +
      (miname        = c_miname        and miname       ne '')*2  +
      (miname        ne c_miname       )*(-3) +
      (race_ami      = c_race_ami      and race_ami     ne '')*3  +
      (race_ami      ne c_race_ami     )*(-2) +
      (race_asi      = c_race_asi      and race_asi     ne '')*3  +
      (race_asi      ne c_race_asi     )*(-2) +
      (race_blk      = c_race_blk      and race_blk     ne '')*3  +
      (race_blk      ne c_race_blk     )*(-2) +
      (race_haw      = c_race_haw      and race_haw     ne '')*3  +
      (race_haw      ne c_race_haw     )*(-2) +
      (race_wht      = c_race_wht      and race_wht     ne '')*3  +
      (race_wht      ne c_race_wht     )*(-2) +
      (sex           = c_sex           and sex          ne '')*2  +
      (sex           ne c_sex          )*(-20) +
      (zipcode       = c_zipcode       and zipcode      ne '')*3  +
      (zipcode       ne c_zipcode      )*(-2) +
      (firstname_sdx = c_firstname_sdx and firstname_sdx ne '')*2  +
      (firstname_sdx ne c_firstname_sdx)*(-10) +
      (lastname_sdx  = c_lastname_sdx  and lastname_sdx ne '')*4  +
      (lastname_sdx  ne c_lastname_sdx )*(-10) +
      (ssnl4         = c_ssnl4         and ssnl4        ne '')*15  +
      (ssnl4         ne c_ssnl4        )*(-10) +
      (statecode     = c_statecode     and statecode       ne '')*1  +
      (statecode     ne c_statecode    )*(-5) +
      (status = '20' and dth_date = dis_date)*10 +
      (status = '20' and dth_date ne dis_date)*(-10) +
      (status = '20' and facility = substr(hospital,1,3))*5 +
      (status = '20' and facility ne substr(hospital,1,3))*(-10) +
      (dis_date ge dth_date + 2)*(-20)
      ;

      if score ge 0 then output;
      *output;

      end;
run;
proc print data=dihd.link2011plus(obs=21 );
   var score certno firstname c_firstname lastname c_lastname miname c_miname dob c_dob
       ssnL4 c_ssnL4 age c_age sex c_sex cnty_res c_cnty_res statecode c_statecode
       race_ami c_race_ami race_asi c_race_asi race_blk c_race_blk race_haw c_race_haw
       race_wht c_race_wht hispanic c_hispanic;
run;
/*
did any pairs have a high score without birthdate matching?
*/
proc freq data=dihd.link2011plus;
   where dob ne c_dob;
   tables score;
run;
\end{lstlisting}

\begin{lstlisting}[language=sas,caption=write death and CHARS files to csv for R]
/*
the length statements are to ensure fields are in a consistent order
when I read them into R, and the fields are ordered for easiest use
during the classification of the training set.
I delete the records that have no names or SSN (typically these are
deaths that occurred out-of-state).
*/
data dwnames2;
   length certno $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 cnty_res $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 deathfirst $ 20 deathlast $ 20;
   set dwnames;
   keep certno cnty_res dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date deathfirst deathlast suffix
        ;
   if firstname in ('B','BABY','BABYBOY','BABYGIRL','BOY','GIRL')
      then firstname = '';
   deathfirst = firstname;
   deathlast  = lastname;
   if firstname = '' and lastname = '' then delete;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 = '9999' then ssnL4 = '';
   format dth_date mmddyy10.;
run;
proc export data=dwnames2
   outfile = "c:\data\DIHD\death2011.txt"
   dbms = csv
   replace
   ;
run;

data clink2;
   length seq_no_enc $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 countyres $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 charslast $ 20 charsfirst $ 20;
   set clink09;
   if status = '20' then do;
      facility = substr(hospital,1,3);
      dth_date = dis_date;
      end;
   else do;
      facility = '';
      dth_date = .;
      end;
   if firstname in ('B','BABY','BABYBOY','BABYGIRL',
      'BOY','GIRL','BB','BBABY','BABYA','BABYB','BABYBOY',
      'BABYG','BABYGIRL','BABYTWIN','BABYABOY','BABYBGIRL',
      'BABYBOY','BABYBOYA','BABYBOYB','BABYFEMAL','BABYFEMALE',
      'BABYGIRL','BABYGIRLA','BABYGIRLB','BABYMALE','BABYONE',
      'BABYTWO')
      then firstname = '';
   charsfirst = firstname;
   charslast = lastname;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 = '9999' then ssnL4 = '';
   keep seq_no_enc countyres dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date charsfirst charslast suffix;
   format dth_date mmddyy10.;
run;
proc export data=clink2
   outfile = "c:\data\DIHD\chars2009.txt"
   dbms = csv
   replace
   ;
run;
\end{lstlisting}


\bfs
\begin{verbatim}
%<<>>=
library(RecordLinkage)
# save the previous model and results
save(list=c('pairs2012plus.fsWt','model2011.bag','result2012plus.bag',
        'manualreview2012plus.b','predictions.2012plusb','links2012plus'),file='Classifier2012plus')

death2011 <- read.csv("../../../data/DIHD/death2011.txt",colClasses=c(rep("character",18)),
                      col.names=c("certno","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "death.first","death.last"))
death2011$firstname.sdx <- soundex(death2011$firstname)
death2011$lastname.sdx  <- soundex(death2011$lastname)

chars09 <- read.csv("../../../data/DIHD/chars2009.txt",colClasses=c(rep("character",18)),
                      col.names=c("seq_no_enc","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "chars.last","chars.first"))
chars09$firstname.sdx <- soundex(chars09$firstname)
chars09$lastname.sdx  <- soundex(chars09$lastname)

pairs2011plus <- compare.linkage(death2011,chars09,blockfld=c(2),exclude=c(1))

# calculate Fellegi-Sunter weights
pairs2011plus.fsWt <- fsWeights(pairs2011plus)

# use the model that was trained on the 2011 data.
result2011plus.bag <- classifySupv(model2011.bag,newdata=pairs2011plus.fsWt)

manualreview2011plus <- result2011plus.bag[(result2011plus.bag$prediction=='L'&
                          result2011plus.bag$Wdata<=30)|(result2011plus.bag$prediction=='N'&
                          result2011plus.bag$Wdata>=20)]

manualreview2011plus <- editMatch(manualreview2011plus)

%@
\end{verbatim}
\efs

\bfs
\begin{verbatim}
%<<>>=
library(RecordLinkage)

manualreview2011plus.b <- manualreview2011plus
for(i in 1:length(manualreview2011plus$prediction)) {
      manualreview2011plus.b$prediction[i] <- if(manualreview2011plus$pairs$is_match[i]==0) 'N' else 'L'
}

predictions.2011plusa <- result2011plus.bag$prediction
index.r <- as.numeric(row.names(manualreview2011plus.b$pairs))
predictions.2011plusb <- predictions.2011plusa
predictions.2011plusb[index.r] <- manualreview2011plus.b$prediction

# combine death and CHARS row numbers with the predictions
newresults2011plus <- cbind(result2011plus.bag$pairs[,c(1,2)],predictions.2011plusb)

# get death certificate numbers and CHARS seq number (seq_no_enc)
deathcerts <- result2011plus.bag$data1[newresults2011plus[,1],1]
charsseq <- result2011plus.bag$data2[newresults2011plus[,2],1]
newresults2011plus.b <- data.frame(deathcerts,charsseq,predictions.2011plusb)

%@
\end{verbatim}
\efs

\subsubsection{Manual review of records with non-matching birthdates}

Now I get a file of the record pairs which had a high matching score
(10 or higher)
with non-matching birthdates, and export them to an Excel spreadsheet to conduct a manual
review on them. I chose 10 as the cutoff score for manual review
because that provides a reasonable number of records for review (about
1,100), but I think it includes nearly all the records that have much
chance of being classified a true match.

\begin{lstlisting}[language=sas,caption=get non-matching birthdate high scorers for manual review]
libname dihd 'c:\data\dihd';
data review1;
   set dihd.link2011plus(where=(dob ne c_dob and score ge 10));
run;
proc sort data=review1;
   by score;
run;
data review2(keep=dcert cseq bd fname mi lname ssn sx hosp dd zip county hisp rw
                  rb ram ras rh sc);
   length dcert $ 10 cseq $ 10 bd 8 fname $ 20 mi $ 1 lname $ 20 ssn $ 4 sx $ 1
          hosp $ 3 dd 8 zip $ 5 county $ 2 hisp rw rb ram ras rh $ 1
          sc 8;
   set review1;
   format bd dd mmddyy10.;

   dcert = certno;
   cseq = seq_no_enc;
   bd = dob;
   fname = firstname;
   mi = miname;
   lname = lastname;
   ssn = ssnL4;
   sx = sex;
   hosp = facility;
   dd = dth_date;
   zip = zipcode;
   county = cnty_res;
   hisp = hispanic;
   rw = race_wht;
   rb = race_blk;
   ram = race_ami;
   ras = race_asi;
   rh = race_haw;
   sc = score;
   output;

   bd = c_dob;
   fname = c_firstname;
   mi = c_miname;
   lname = c_lastname;
   ssn = c_ssnL4;
   sx = c_sex;
   if status = 20 or dis_date ge dth_date then do;
      hosp = hospital;
      dd = dis_date;
      end;
   else do;
      hosp = '';
      dd = .;
      end;
   zip = c_zipcode;
   county = c_cnty_res;
   hisp = c_hispanic;
   rw = c_race_wht;
   rb = c_race_blk;
   ram = c_race_ami;
   ras = c_race_asi;
   rh = c_race_haw;
   sc = .;
   output;

   bd = .;
   fname = '';
   mi = '';
   lname = '';
   ssn = '';
   sx = '';
   hosp = '';
   dd = .;
   zip = '';
   county = '';
   hisp = '';
   rw = '';
   rb = '';
   ram = '';
   ras = '';
   rh = '';
   sc = .;
   output;
run;

proc export data=review2
   outfile = "c:\user\projects\Death-CHARSlink\manreview2011plus.xls"
   dbms = excel5
   replace
   ;
run;
/*
read the reviewed links
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2011plus_done.xls"
   dbms = excel5
   replace
   ;
run;
\end{lstlisting}

Now I need to combine the links from three sources: the machine
learning results, the manual review of those results, and the manual
coding of the records on which birthdate didn't match. After combining
those links, I need to check whether there are any hospitalization
records linked to more than one death record, and if so, adjudicate
those links manually. Then I can create the final linked file.

\bfs
\begin{verbatim}
#create file containing only the linked pairs
links2011plus <- newresults2011plus.b[newresults2011plus.b$predictions.2011plusb=='L',]

write.csv(links2011plus,file="c:/data/dihd/links2011plus.csv",row.names=F)

\end{verbatim}
\efs

\begin{lstlisting}[language=sas,caption=create final expanded linked file for 2012]
libname dihd 'c:\data\dihd';

proc import out=links0
   file = "c:\data\dihd\links2011plus.csv"
   dbms = csv
   replace
   ;
run;
data links1(keep=certno seq_no_enc predict);
   length certno seq_no_enc $ 10 predict $ 1;
   set links0;
   certno = substr(deathcerts,1,10);
   seq_no_enc = substr(charsseq,1,10);
   predict = substr(predictions_2012plusb,1,1);
run;
/*
read in the reviewed links for pairs which had high scores but
   non-matching birthdates
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2011plus_done.xls"
   dbms = excel5
   replace
   ;
run;
data mlinks1(keep=certno seq_no_enc sc link);
   length certno seq_no_enc $ 10;
   retain i 0;
   set review3;
   certno = substr(dcert,1,10);
   seq_no_enc = substr(cseq,1,10);
   i+1;
   if i = 1 then output;
   if i = 3 then i = 0;
run;
proc freq data=mlinks1;
   tables sc*link/norow nocol nopercent;
run;
/*
this table shows the strong relation between score and link status
                The SAS System                                                                       12:19 Tuesday, July 22, 2014  24

              The FREQ Procedure

             Table of SC by LINK

     SC(SC)     LINK(LINK)

     Frequency|       0|       1|  Total
     ---------+--------+--------+
           10 |      7 |      3 |     10
     ---------+--------+--------+
           11 |     39 |      0 |     39
     ---------+--------+--------+
           12 |    412 |      1 |    413
     ---------+--------+--------+
           13 |      4 |      8 |     12
     ---------+--------+--------+
           14 |    130 |      0 |    130
     ---------+--------+--------+
           15 |      2 |     15 |     17
     ---------+--------+--------+
           16 |      1 |      1 |      2
     ---------+--------+--------+
           17 |     85 |      2 |     87
     ---------+--------+--------+
           18 |      0 |     10 |     10
     ---------+--------+--------+
           19 |      9 |      0 |      9
     ---------+--------+--------+
           20 |      5 |     30 |     35
     ---------+--------+--------+
           21 |      0 |      1 |      1
     ---------+--------+--------+
           22 |     10 |      1 |     11
     ---------+--------+--------+
           23 |      0 |      9 |      9
     ---------+--------+--------+
           25 |      4 |      5 |      9
     ---------+--------+--------+
           26 |      1 |      2 |      3
     ---------+--------+--------+
           28 |      1 |      0 |      1
     ---------+--------+--------+
           30 |      0 |     11 |     11
     ---------+--------+--------+
           32 |      1 |      7 |      8
     ---------+--------+--------+
           33 |      0 |      1 |      1
     ---------+--------+--------+
           34 |      0 |      1 |      1
     ---------+--------+--------+
           35 |      0 |      5 |      5
     ---------+--------+--------+
           36 |      0 |      4 |      4
     ---------+--------+--------+
           37 |      0 |      4 |      4
     ---------+--------+--------+
           38 |      0 |      2 |      2
     ---------+--------+--------+
           39 |      0 |      1 |      1
     ---------+--------+--------+
           40 |      0 |     22 |     22
     ---------+--------+--------+
           42 |      0 |     13 |     13
     ---------+--------+--------+
           43 |      0 |      2 |      2
     ---------+--------+--------+
           45 |      0 |     46 |     46
     ---------+--------+--------+
           48 |      0 |      6 |      6
     ---------+--------+--------+
           50 |      0 |     42 |     42
     ---------+--------+--------+
           53 |      0 |      5 |      5
     ---------+--------+--------+
           55 |      0 |    102 |    102
     ---------+--------+--------+
           60 |      0 |      2 |      2
     ---------+--------+--------+
           63 |      0 |      1 |      1
     ---------+--------+--------+
     Total         711      365     1076

*/
data mlinks2(keep=certno seq_no_enc);
   set mlinks1(where=(link=1));
run;
/*
combine links from the standard 2011 DIHD file, the new links from R,
and the new links from the mis-matched birth date records

Then check if any CHARS records linked to more than one death certificate
*/
data link2011plus;
   set dihd.finallink2011 links1(drop=predict) mlinks2;
run;
/*
check for CHARS records that linked to more than one death certificate
(there are no CHARS records that linked to more than one death cert)
*/
proc freq data=link2011plus noprint;
   tables seq_no_enc/out=charslist;
run;
data mults1(drop=percent);
   set charslist(where=(count ge 2));
run;
/*
create final linked file
*/
data dihd.finallink2011plus;
   set link2011plus;
run;

proc freq data=dihd.finallink2011plus noprint;
   tables certno/out=dcertlist;
run;
/*
I found that 38,056 death certificates from 2011 linked
to 112,774 hospital records from 2009-2011.
*/
\end{lstlisting}
\end{detail}

\subsection{DIHD file and Expanded DIHD file for 2013}

Here I create the 2013 DIHD file, which links 2013 deaths to the 2012
and 2013 CHARS files, and the 2013 Expanded DIHD file, which links
2013 deaths to the 2009--2013 CHARS files.

I will do this by just creating the expanded file first, then
subsetting it to produce the regular DIHD file.

\begin{lstlisting}[language=sas,caption=create death file for linking]
/*
Step 1. read the death file with names
*/
libname death 'c:\data\death';
libname chars 'c:\data\chars';

data names;
   infile "c:\data\death\deathnames\deathnamesv3.2013" lrecl=290;
   input
      @1   certno     $char10.
      @11  lastname   $char50.
      @61  firstname  $char30.
      @91  middlename $char40.
      @131 suffix     $char4.
      @158 ssnl4      $char4.
      @162 street     $char35.
      @197 city       $char30.
      @227 zipcode    $char5.
      @232 zipplus4   $char4.
      @236 statecode  $char2.
      ;
run;
/*
Step 2. merge with standard death file
*/
proc sort data=names;
   by certno;
run;
proc sort data=death.dea2013
      out=stats(keep=certno age dob sex cnty_res dth_date race_wht race_blk
      race_ami race_asi race_chi race_fil race_gua race_haw race_jap race_kor
      race_opi race_oas race_oth race_sam race_vie hisp zipcode facility fac_type);
   by certno;
run;
/*
combine statistical and name files, and recode race fields to match the reduced
set in the CHARS file (which has only white, black, american indian or alaska
native, asian, hawaiian or other Pacific Islander)
*/
proc format;
   value $stateres
     '01' = 'AL'
     '02' = 'AK'
     '03' = 'AZ'
     '04' = 'AR'
     '05' = 'CA'
     '06' = 'CO'
     '07' = 'CT'
     '08' = 'DE'
     '09' = 'DC'
     '10' = 'FL'
     '11' = 'GA'
     '12' = 'HI'
     '13' = 'ID'
     '14' = 'IL'
     '15' = 'IN'
     '16' = 'IA'
     '17' = 'KS'
     '18' = 'KY'
     '19' = 'LA'
     '20' = 'ME'
     '21' = 'MD'
     '22' = 'MA'
     '23' = 'MI'
     '24' = 'MN'
     '25' = 'MS'
     '26' = 'MO'
     '27' = 'MT'
     '28' = 'NE'
     '29' = 'NV'
     '30' = 'NH'
     '31' = 'NJ'
     '32' = 'NM'
     '33' = 'NY'
     '34' = 'NC'
     '35' = 'ND'
     '36' = 'OH'
     '37' = 'OK'
     '38' = 'OR'
     '39' = 'PA'
     '40' = 'RI'
     '41' = 'SC'
     '42' = 'SD'
     '43' = 'TN'
     '44' = 'TX'
     '45' = 'UT'
     '46' = 'VT'
     '47' = 'VA'
     '48' = 'WA'
     '49' = 'WV'
     '50' = 'WI'
     '51' = 'WY'
     '52' = 'PR'
     '53' = 'VI'
     '54' = 'GU'
     '55' = 'XX'
     '57' = 'XX'
     '59' = 'XX'
     '99' = 'XX'
     '60' = 'AS'
     '69' = 'MP'
      ;
run;
data dwnames(drop=sum_race_asi sum_race_haw race_temp1 race_temp2 race_chi race_fil
          race_gua race_jap race_kor race_opi race_oas race_oth race_sam
          race_vie firsttemp lasttemp middlename hisp firsttemp2 lasttemp2);
   length firstname lastname $ 20 miname hispanic $ 1 lastname_sdx firstname_sdx $ 4
          firsttemp2 lasttemp2 $ 25;
   merge stats(rename=(race_asi=race_temp1 race_haw=race_temp2))
         names(rename=(firstname=firsttemp lastname=lasttemp));
   by certno;
   firsttemp2 = compress(firsttemp," '`-_,.&");
   lasttemp2  = compress(lasttemp," '`-_,.&");
   firstname = substr(firsttemp2,1,20);
   lastname  = substr(lasttemp2,1,20);
   miname    = substr(middlename,1,1);
   sum_race_asi = min(1,(race_chi='Y')+(race_fil='Y')+(race_jap='Y')+(race_kor='Y')+
                    (race_oas='Y')+(race_vie='Y')+(race_temp1='Y'));
   sum_race_haw = min(1,(race_gua='Y')+(race_opi='Y')+(race_sam='Y')+(race_temp2='Y'));

   if sum_race_asi = 0 then race_asi = 'N';
   else                     race_asi = 'Y';
   if sum_race_haw = 0 then race_haw = 'N';
   else                     race_haw = 'Y';
   if race_ami in ('') then race_ami = 'U';
   if race_asi in ('') then race_asi = 'U';
   if race_blk in ('') then race_blk = 'U';
   if race_haw in ('') then race_haw = 'U';
   if race_wht in ('') then race_wht = 'U';
   if ssnL4 = '9999'      then ssnL4 = '';
   select(hisp);
      when('0')                 hispanic = 'N';
      when('1','2','3','4','5') hispanic = 'Y';
      when('','9')              hispanic = 'U';
      end;
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);
   format dob mmddyy10.;
run;
\end{lstlisting}

\begin{lstlisting}[language=sas,caption=Create CHARS file for linking]
data clink0913(keep=seq_no_enc adm_date age country countyres dis_date dob firstname
                ssnL4 hispanic hospital lastname miname race_ami race_asi race_blk
                race_haw race_wht sex statecode status zipcode zipplus4
                lastname_sdx firstname_sdx suffix);
   length firstname lastname $ 20 suffix $ 4 lastname_sdx firstname_sdx $ 4 statecode $ 2;
   set chars.chr_r2009(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp))
       chars.chr_r2010(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp))
       chars.chr_r2011(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp))
       chars.chr_r2012(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp))
       chars.chr_r2013(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp));
   if race_ami in ('','R') then race_ami = 'U';
   if race_asi in ('','R') then race_asi = 'U';
   if race_blk in ('','R') then race_blk = 'U';
   if race_haw in ('','R') then race_haw = 'U';
   if race_wht in ('','R') then race_wht = 'U';
   if hispanic in ('','R') then hispanic = 'U';
   if ssnL4 = '9999'      then ssnL4 = '';
/*
remove the suffixes II, III, IV, V, VI, VII, VIII, ESQ, JR, and SR
from lastnames and place them in a separate suffix field.
Used with UB04 data.
*/
   if _N_ = 1 then do;
   	retain __re __reIII;
   	pattern = "/( II| III| IV| V| VI| VII| VIII| ESQ|.JR|.SR)$/i";
   	__re = prxparse(pattern);
   	__reIII = prxparse('/III$/');
   end;
   lasttemp = translate(lasttemp,' ','.,');
   call prxsubstr(__re, TRIM(lasttemp), position, length);
   if position ^= 0 then do;
   	suffix    = substr(lasttemp, position + 1, length - 1);
   	lasttemp2 = substr(lasttemp, 1, position - 1);
   end;
   else lasttemp2 = lasttemp;

   firstname = compress(firsttemp," '`-_,.&");
   lastname  = compress(lasttemp2," '`-_,.&");
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);
   statecode = stateres;
   if statecode = 'XX' then statecode = '';
run;
\end{lstlisting}


\begin{lstlisting}[language=sas,caption=compute test link scores]
libname dihd 'c:\data\dihd';
/*
For each record, I will evaluate its similarity with each of the other records
by computing a score using the points described above. In the output dataset,
I will keep records that have a score of at least 0.
Maximum score is 112.
*/
data dihd.link2013nonbirthmatch;
   set clink0913(rename=(
     age           = c_age
     countyres     = c_cnty_res
     dob           = c_dob
     firstname     = c_firstname
     hispanic      = c_hispanic
     lastname      = c_lastname
     miname        = c_miname
     race_ami      = c_race_ami
     race_asi      = c_race_asi
     race_blk      = c_race_blk
     race_haw      = c_race_haw
     race_wht      = c_race_wht
     sex           = c_sex
     zipcode       = c_zipcode
     firstname_sdx = c_firstname_sdx
     lastname_sdx  = c_lastname_sdx
     ssnl4         = c_ssnl4
     statecode     = c_statecode
     ));
   do i = 1 to 52199;
      set dwnames point=i;
      if (firstname ne c_firstname and lastname ne c_lastname) or
          dob = c_dob then score = 0;
      else score =
      (age           = c_age           and age          ne .)*5  +
      (age           ne c_age          )*(-5) +
      (cnty_res      = c_cnty_res      and cnty_res     ne '')*3  +
      (cnty_res      ne c_cnty_res     )*(-5) +
      (dob           = c_dob           and dob          ne .)*20  +
      (dob           ne c_dob          )*(-20) +
      (month(dob)    = month(c_dob)    and dob          ne .)*3   +
      (month(dob)    ne month(c_dob)   )*(-5)  +
      (day(dob)      = day(c_dob)      and dob          ne .)*4   +
      (day(dob)      ne day(c_dob)     )*(-4)   +
      (year(dob)     = year(c_dob)     and dob          ne .)*4   +
      (year(dob)     ne year(c_dob)    )*(-4)   +
      (firstname     = c_firstname     and firstname    ne '')*10 +
      (firstname     ne c_firstname    )*(-10) +
      (hispanic      = c_hispanic      and hispanic     ne '')*5  +
      (hispanic      ne c_hispanic     )*(-5) +
      (lastname      = c_lastname      and lastname     ne '')*15  +
      (lastname      ne c_lastname     )*(-15) +
      (miname        = c_miname        and miname       ne '')*2  +
      (miname        ne c_miname       )*(-3) +
      (race_ami      = c_race_ami      and race_ami     ne '')*3  +
      (race_ami      ne c_race_ami     )*(-2) +
      (race_asi      = c_race_asi      and race_asi     ne '')*3  +
      (race_asi      ne c_race_asi     )*(-2) +
      (race_blk      = c_race_blk      and race_blk     ne '')*3  +
      (race_blk      ne c_race_blk     )*(-2) +
      (race_haw      = c_race_haw      and race_haw     ne '')*3  +
      (race_haw      ne c_race_haw     )*(-2) +
      (race_wht      = c_race_wht      and race_wht     ne '')*3  +
      (race_wht      ne c_race_wht     )*(-2) +
      (sex           = c_sex           and sex          ne '')*2  +
      (sex           ne c_sex          )*(-20) +
      (zipcode       = c_zipcode       and zipcode      ne '')*3  +
      (zipcode       ne c_zipcode      )*(-2) +
      (firstname_sdx = c_firstname_sdx and firstname_sdx ne '')*2  +
      (firstname_sdx ne c_firstname_sdx)*(-10) +
      (lastname_sdx  = c_lastname_sdx  and lastname_sdx ne '')*4  +
      (lastname_sdx  ne c_lastname_sdx )*(-10) +
      (ssnl4         = c_ssnl4         and ssnl4        ne '')*15  +
      (ssnl4         ne c_ssnl4        )*(-10) +
      (statecode     = c_statecode     and statecode       ne '')*1  +
      (statecode     ne c_statecode    )*(-5) +
      (status = '20' and dth_date = dis_date)*10 +
      (status = '20' and dth_date ne dis_date)*(-10) +
      (status = '20' and facility = substr(hospital,1,3))*5 +
      (status = '20' and facility ne substr(hospital,1,3))*(-10) +
      (dis_date ge dth_date + 2)*(-20)
      ;

      if score ge 1 then output;
      *output;

      end;
run;
proc print data=dihd.link2013nonbirthmatch(obs=21 );
   var score certno firstname c_firstname lastname c_lastname miname c_miname dob c_dob
       ssnL4 c_ssnL4 age c_age sex c_sex cnty_res c_cnty_res statecode c_statecode
       race_ami c_race_ami race_asi c_race_asi race_blk c_race_blk race_haw c_race_haw
       race_wht c_race_wht hispanic c_hispanic;
run;
proc freq data=dihd.link2013nonbirthmatch;
   tables score;
run;
\end{lstlisting}

\begin{lstlisting}[language=sas,caption=write death and CHARS files to csv for R]
/*
the length statements are to ensure fields are in a consistent order
when I read them into R, and the fields are ordered for easiest use
during the classification of the training set.
I delete the records that have no names or SSN (typically these are
deaths that occurred out-of-state).
*/
data dwnames2;
   length certno $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 cnty_res $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 deathfirst $ 20 deathlast $ 20;
   set dwnames;
   keep certno cnty_res dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date deathfirst deathlast suffix
        ;
   if upcase(firstname) in (
      'B ',
      'BABY ',
      'BABY 1 BOY',
      'BABY 1 GIRL',
      'BABY 2 ',
      'BABY 2 BOY',
      'BABY 2 GIRL',
      'BABY B ',
      'BABY BOY ',
      'BABY BOY 1',
      'BABY BOY 2',
      'BABY BOY A',
      'BABY BOY B',
      'BABY G',
      'BABY GIR ',
      'BABY GIRL ',
      'BABY GIRL 1',
      'BABY GIRL A',
      'BABY GIRL STILL',
      'BABY ONE',
      'BABYBOY ',
      'BABYGIRL ',
      'BABYMALE',
      'BABYONE BOY',
      'BOY ',
      'BOY 2',
      'BOY 3',
      'BOY A',
      'BOY B ',
      'BOYA',
      'BOYB',
      'BOYC',
      'BOY ONE',
      'BOY TWIN A',
      'BOY-ONE ',
      'GIRL ',
      'GIRL B ',
      'GIRL C ',
      'GIRL-ONE'
      )
      then firstname = '';
   if miname in ('(','-','0','1','2','3') then middlename = '';
   deathfirst = firstname;
   deathlast  = lastname;
   if firstname = '' and lastname = '' then delete;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if zipplus4 in ('0000','9999') then zipplus4 = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 in ('0001','1111','6789','9999') then ssnL4 = '';
   format dth_date mmddyy10.;
run;
proc export data=dwnames2
   outfile = "c:\data\DIHD\death2013.csv"
   dbms = csv
   replace
   ;
run;

data clink2;
   length seq_no_enc $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 countyres $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 charslast $ 20 charsfirst $ 20;
   set clink0913;
   if status = '20' then do;
      facility = substr(hospital,1,3);
      dth_date = dis_date;
      end;
   else do;
      facility = '';
      dth_date = .;
      end;
   if upcase(firstname) in (
      'B ',
      'BABY ',
      'BABY 1 BOY',
      'BABY 1 GIRL',
      'BABY 2 ',
      'BABY 2 BOY',
      'BABY 2 GIRL',
      'BABY B ',
      'BABY BOY ',
      'BABY BOY 1',
      'BABY BOY 2',
      'BABY BOY A',
      'BABY BOY B',
      'BABY G',
      'BABY GIR ',
      'BABY GIRL ',
      'BABY GIRL 1',
      'BABY GIRL A',
      'BABY GIRL STILL',
      'BABY ONE',
      'BABYBOY ',
      'BABYGIRL ',
      'BABYMALE',
      'BABYONE BOY',
      'BOY ',
      'BOY 2',
      'BOY 3',
      'BOY A',
      'BOY B ',
      'BOYA',
      'BOYB',
      'BOYC',
      'BOY ONE',
      'BOY TWIN A',
      'BOY-ONE ',
      'GIRL ',
      'GIRL B ',
      'GIRL C ',
      'GIRL-ONE'
      )
      then firstname = '';
   charsfirst = firstname;
   charslast = lastname;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if zipplus4 in ('0000','9999') then zipplus4 = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 in ('0001','1111','6789','9999') then ssnL4 = '';
   keep seq_no_enc countyres dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date charsfirst charslast suffix;
   format dth_date mmddyy10.;
run;
proc export data=clink2
   outfile = "c:\data\DIHD\chars2009_2013.csv"
   dbms = csv
   replace
   ;
run;
\end{lstlisting}

\bfs
\begin{verbatim}
%<<>>=
library(plyr); library(dplyr); library(magrittr)
library(RecordLinkage)

death2013 <- read.csv("../../../data/DIHD/death2013.csv",colClasses=c(rep("character",18)),
                      col.names=c("certno","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "death.first","death.last"))
death2013$firstname.sdx <- soundex(death2013$firstname)
death2013$lastname.sdx  <- soundex(death2013$lastname)

chars0913 <- read.csv("../../../data/DIHD/chars2009_2013.csv",colClasses=c(rep("character",18)),
                      col.names=c("seq_no_enc","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "chars.last","chars.first"))
chars0913$firstname.sdx <- soundex(chars0913$firstname)
chars0913$lastname.sdx  <- soundex(chars0913$lastname)

pairs2013plus <- compare.linkage(death2013,chars0913,blockfld=c(2),exclude=c(1))

# calculate Fellegi-Sunter weights
pairs2013plus <- fsWeights(pairs2013plus)

# use the model that was trained on the 2011 data.
load("model2011.RData")
result2013plus.bag <- classifySupv(model2011.bag,newdata=pairs2013plus)

ggplot(data.frame(Wdata=result2013plus.bag$Wdata, prediction=result2013plus.bag$prediction)) +
       geom_density(aes(Wdata),adjust=5, size=1.2)

ggplot(data.frame(Wdata=result2013plus.bag$Wdata, prediction=result2013plus.bag$prediction)) +
       geom_density(aes(Wdata, color=prediction),adjust=5, size=1.2)

table(cut(result2013plus.bag$Wdata, breaks=c(-72, -10, 0, 20, 30, 50, 70, 100, 180)),
      result2013plus.bag$prediction)

                  N       P       L
  (-72,-10] 4792557       0      10
  (-10,0]     26831       0      70
  (0,20]      29900       0     394
  (20,30]      3378       0     422
  (30,50]       509       0    3226
  (50,70]        30       0   11548
  (70,100]        1       0   52002
  (100,180]       0       0   77890

# I choose a weight of 30 as the cutoff in both directions for manual review
manualreview2013plus <- result2013plus.bag[(result2013plus.bag$prediction == 'L' &
                        result2013plus.bag$Wdata <= 30) | (result2013plus.bag$prediction == 'N' &
                        result2013plus.bag$Wdata >= 30)]

manualreview2013plus <- editMatch(manualreview2013plus)

%@
\end{verbatim}
\efs


\bfs
\begin{verbatim}
%<<>>=
library(plyr); library(dplyr); library(magrittr)
library(RecordLinkage)

manualreview2013plus.b <- manualreview2013plus
for(i in 1:length(manualreview2013plus$prediction)) {
      manualreview2013plus.b$prediction[i] <- if(manualreview2013plus$pairs$is_match[i] == 0) 'N' else 'L'
}

predictions.2013plus.a <- result2013plus.bag$prediction
index.r <- as.numeric(row.names(manualreview2013plus.b$pairs))
predictions.2013plus.b <- predictions.2013plus.a
predictions.2013plus.b[index.r] <- manualreview2013plus.b$prediction

# combine death and CHARS row numbers with the predictions
newresults2013plus <- cbind(result2013plus.bag$pairs[,c(1,2)],predictions.2013plus.b)

# get death certificate numbers and CHARS seq number (seq_no_enc)
deathcerts <- result2013plus.bag$data1[newresults2013plus[,1],1]
charsseq <- result2013plus.bag$data2[newresults2013plus[,2],1]
newresults2013plus.b <- data.frame(deathcerts,charsseq,predictions.2013plus.b)

%@
\end{verbatim}
\efs

\subsubsection{Manual review of records with non-matching birthdates}

Now I get a file of the record pairs which had a high matching score (15 or higher) with
non-matching birthdates, and export them to an Excel spreadsheet to conduct a manual review on
them. I chose 15 as the cutoff score for manual review because that provides a reasonable number of
records for review (about 3,000), but I think it includes nearly all the records that have
much chance of being classified a true match.

\begin{lstlisting}[language=sas,caption=get non-matching birthdate high scorers for manual review]
libname dihd 'c:\data\dihd';
data review1;
   set dihd.link2013nonbirthmatch(where=(score ge 15));
run;
proc sort data=review1;
   by score;
run;
data review2(keep=dcert cseq bd fname mi lname ssn sx hosp dd zip county hisp rw
                  rb ram ras rh sc);
   length dcert $ 10 cseq $ 10 bd 8 fname $ 20 mi $ 1 lname $ 20 ssn $ 4 sx $ 1
          hosp $ 3 dd 8 zip $ 5 county $ 2 hisp rw rb ram ras rh $ 1
          sc 8;
   set review1;
   format bd dd mmddyy10.;

   dcert = certno;
   cseq = seq_no_enc;
   bd = dob;
   fname = firstname;
   mi = miname;
   lname = lastname;
   ssn = ssnL4;
   sx = sex;
   hosp = facility;
   dd = dth_date;
   zip = zipcode;
   county = cnty_res;
   hisp = hispanic;
   rw = race_wht;
   rb = race_blk;
   ram = race_ami;
   ras = race_asi;
   rh = race_haw;
   sc = score;
   output;

   bd = c_dob;
   fname = c_firstname;
   mi = c_miname;
   lname = c_lastname;
   ssn = c_ssnL4;
   sx = c_sex;
   if status = 20 or dis_date ge dth_date then do;
      hosp = hospital;
      dd = dis_date;
      end;
   else do;
      hosp = '';
      dd = .;
      end;
   zip = c_zipcode;
   county = c_cnty_res;
   hisp = c_hispanic;
   rw = c_race_wht;
   rb = c_race_blk;
   ram = c_race_ami;
   ras = c_race_asi;
   rh = c_race_haw;
   sc = .;
   output;

   bd = .;
   fname = '';
   mi = '';
   lname = '';
   ssn = '';
   sx = '';
   hosp = '';
   dd = .;
   zip = '';
   county = '';
   hisp = '';
   rw = '';
   rb = '';
   ram = '';
   ras = '';
   rh = '';
   sc = .;
   output;
run;

/*
Excel pukes over a birthdate before 1900, so I will edit that one person's birthdate
to a later date.
*/
data review3;
   set review2;
   if . lt bd le '01jan1900'd then bd = '02jan1900'd;
run;

proc export data=review3
   outfile = "c:\user\projects\Death-CHARSlink\manreview2013plus.xls"
   dbms = excel5
   replace
   ;
run;
/*
read the reviewed links
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2013plus_done.xls"
   dbms = xls
   replace
   ;
run;
\end{lstlisting}

Now I need to combine the links from three sources: the machine
learning results, the manual review of those results, and the manual
coding of the records on which birthdate didn't match. After combining
those links, I need to check whether there are any hospitalization
records linked to more than one death record, and if so, adjudicate
those links manually. Then I can create the final linked file.

\bfs
\begin{verbatim}
#create file containing only the linked pairs
links2013plus <- newresults2013plus.b[newresults2013plus.b$predictions.2013plus.b=='L',]

write.csv(links2013plus,file="c:/data/dihd/links2013plus.csv",row.names=F)

save(chars0913, death2013, links2013plus, manualreview2013plus, model2011.bag,
     result2013plus.bag, file="Classifier2013plus.RData")
\end{verbatim}
\efs

\begin{lstlisting}[language=sas,caption=create final expanded linked file for 2012]
libname dihd 'c:\data\dihd';
proc import out=links0
   file = "c:\data\dihd\links2013plus.csv"
   dbms = csv
   replace
   ;
run;
data links1(keep=certno seq_no_enc predict);
   length certno seq_no_enc $ 10 predict $ 1;
   set links0;
   certno = substr(deathcerts,1,10);
   seq_no_enc = substr(charsseq,1,10);
   predict = substr(predictions_2013plus_b,1,1);
run;
/*
read in the reviewed links for pairs which had high scores but
   non-matching birthdates
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2013plus_done.xls"
   dbms = xls
   replace
   ;
run;
data mlinks1(keep=certno seq_no_enc sc link);
   length certno seq_no_enc $ 10;
   retain i 0;
   set review3(rename=(match=link));
   certno = substr(dcert,1,10);
   seq_no_enc = substr(cseq,1,10);
   i+1;
   if i = 1 then output;
   if i = 3 then i = 0;
run;
proc freq data=mlinks1;
   tables sc*link/norow nocol nopercent;
run;
/*
this table shows the strong relation between score and link status

                                 The SAS System                               14
                                                16:24 Thursday, January 22, 2015

                               The FREQ Procedure

                              Table of sc by link

                      sc(sc)     link(match)

                      Frequency|       0|       1|  Total
                      ---------+--------+--------+
                            15 |     25 |     38 |     63
                      ---------+--------+--------+
                            16 |     21 |      2 |     23
                      ---------+--------+--------+
                            17 |    359 |     20 |    379
                      ---------+--------+--------+
                            18 |      0 |     14 |     14
                      ---------+--------+--------+
                            19 |     88 |      2 |     90
                      ---------+--------+--------+
                            20 |     69 |     67 |    136
                      ---------+--------+--------+
                            21 |     14 |      9 |     23
                      ---------+--------+--------+
                            22 |     88 |      7 |     95
                      ---------+--------+--------+
                            23 |      1 |     16 |     17
                      ---------+--------+--------+
                            24 |      5 |      1 |      6
                      ---------+--------+--------+
                            25 |     19 |     57 |     76
                      ---------+--------+--------+
                            26 |      1 |      1 |      2
                      ---------+--------+--------+
                            27 |      7 |     12 |     19
                      ---------+--------+--------+
                            28 |      0 |     14 |     14
                      ---------+--------+--------+
                            29 |      1 |      1 |      2
                      ---------+--------+--------+
                            30 |     13 |     52 |     65
                      ---------+--------+--------+
                            32 |      0 |     31 |     31
                      ---------+--------+--------+
                            33 |      0 |     12 |     12
                      ---------+--------+--------+
                            34 |      0 |     11 |     11
                      ---------+--------+--------+
                            35 |      4 |     37 |     41
                      ---------+--------+--------+
                            36 |      0 |     11 |     11
                      ---------+--------+--------+
                            37 |      0 |     40 |     40
                      ---------+--------+--------+
                            38 |      0 |      7 |      7
                      ---------+--------+--------+
                            39 |      0 |      7 |      7
                      ---------+--------+--------+
                            40 |      2 |    121 |    123
                      ---------+--------+--------+
                            41 |      0 |      1 |      1
                      ---------+--------+--------+
                            42 |      0 |     84 |     84
                      ---------+--------+--------+
                            43 |      0 |     11 |     11
                      ---------+--------+--------+
                            44 |      0 |      1 |      1
                      ---------+--------+--------+
                            45 |      0 |    171 |    171
                      ---------+--------+--------+
                            46 |      0 |      4 |      4
                      ---------+--------+--------+
                            47 |      0 |     27 |     27
                      ---------+--------+--------+
                            48 |      0 |     20 |     20
                      ---------+--------+--------+
                            49 |      0 |      1 |      1
                      ---------+--------+--------+
                            50 |      0 |    301 |    301
                      ---------+--------+--------+
                            51 |      0 |      1 |      1
                      ---------+--------+--------+
                            52 |      0 |     15 |     15
                      ---------+--------+--------+
                            53 |      0 |     61 |     61
                      ---------+--------+--------+
                            54 |      0 |      1 |      1
                      ---------+--------+--------+
                            55 |      0 |    579 |    579
                      ---------+--------+--------+
                            57 |      0 |     16 |     16
                      ---------+--------+--------+
                            58 |      0 |      3 |      3
                      ---------+--------+--------+
                            60 |      0 |    100 |    100
                      ---------+--------+--------+
                            61 |      0 |      2 |      2
                      ---------+--------+--------+
                            62 |      0 |      2 |      2
                      ---------+--------+--------+
                            63 |      0 |     24 |     24
                      ---------+--------+--------+
                            65 |      0 |    232 |    232
                      ---------+--------+--------+
                            67 |      0 |      3 |      3
                      ---------+--------+--------+
                            68 |      0 |      1 |      1
                      ---------+--------+--------+
                            70 |      0 |     20 |     20
                      ---------+--------+--------+
                            72 |      0 |      3 |      3
                      ---------+--------+--------+
                            75 |      0 |     20 |     20
                      ---------+--------+--------+
                            80 |      0 |     60 |     60
                      ---------+--------+--------+
                      Total         717     2354     3071
*/
data mlinks2(keep=certno seq_no_enc);
   set mlinks1(where=(link=1));
run;
/*
combine links from the R-matched file with the links from the mis-matched birth date records

Then check if any CHARS records linked to more than one death certificate
*/
data link2013plus;
   set links1(drop=predict) mlinks2;
run;
/*
check for CHARS records that linked to more than one death certificate

There are 9
*/
proc freq data=link2013plus noprint;
   tables seq_no_enc/out=charslist;
run;
data mults1(drop=percent);
   set charslist(where=(count ge 2));
run;
proc sort data=link2013plus;
   by seq_no_enc;
run;
data mults2;
   merge link2013plus mults1(in=inmult);
   by seq_no_enc;
   if inmult;
run;
/*
link with the CHARS and death files in turn to get the info
*/
proc sort data=clink0913;
   by seq_no_enc;
run;
data mults3;
   merge mults2(in=inmults) clink0913(rename=(
     age           = c_age
     countyres     = c_cnty_res
     dob           = c_dob
     firstname     = c_firstname
     hispanic      = c_hispanic
     lastname      = c_lastname
     miname        = c_miname
     race_ami      = c_race_ami
     race_asi      = c_race_asi
     race_blk      = c_race_blk
     race_haw      = c_race_haw
     race_wht      = c_race_wht
     sex           = c_sex
     zipcode       = c_zipcode
     firstname_sdx = c_firstname_sdx
     lastname_sdx  = c_lastname_sdx
     ssnl4         = c_ssnl4
     statecode     = c_statecode
     ));
   by seq_no_enc;
   if inmults;
run;
proc sort data=dwnames;
   by certno;
run;
proc sort data=mults3;
   by certno;
run;
data mults4;
   merge mults3(in=inmult) dwnames;
   by certno;
   if inmult;
run;
proc sort data=mults4;
   by seq_no_enc;
run;
proc print data=mults4 headings=h;
   by seq_no_enc;
run;
/*
here are the fixes, which I hard code below.
Fixes:
 The SAS System                        16:24 Thursday, January 22, 2015  32

 Obs    seq_no_enc      certno     link

   1    2013087556    2013000401 N
   2    2013087556    2013000404 Y
   3    2013113219    2013057734 N
   4    2013113219    2013057735 N
   5    2013187111    2013019808 Y
   6    2013187111    2013021378 N
   7    2013281738    2013005713 N
   8    2013281738    2013005714 N
   9    2013336412    2013000401 Y
  10    2013336412    2013000404 N
  11    2013475643    2013016697 N
  12    2013475643    2013016698 Y
  13    2013480048    2013020844 N
  14    2013480048    2013061975 Y
  15    2013526786    2013016697 Y
  16    2013526786    2013016698 N
  17    2013626046    2013021498 N
  18    2013626046    2013021499 Y
*/
data link2013plusfixed;
   set link2013plus;
   if seq_no_enc = '2013087556' and certno = '2013000401' then delete;
   if seq_no_enc = '2013113219' and certno = '2013057734' then delete;
   if seq_no_enc = '2013113219' and certno = '2013057735' then delete;
   if seq_no_enc = '2013187111' and certno = '2013021378' then delete;
   if seq_no_enc = '2013281738' and certno = '2013005713' then delete;
   if seq_no_enc = '2013281738' and certno = '2013005714' then delete;
   if seq_no_enc = '2013336412' and certno = '2013000404' then delete;
   if seq_no_enc = '2013475643' and certno = '2013016697' then delete;
   if seq_no_enc = '2013480048' and certno = '2013020844' then delete;
   if seq_no_enc = '2013526786' and certno = '2013016698' then delete;
   if seq_no_enc = '2013626046' and certno = '2013021498' then delete;
run;
/*
create final linked file
*/
data dihd.finallink2013plus;
   set link2013plusfixed;
run;

proc freq data=dihd.finallink2013plus noprint;
   tables certno/out=dcertlist;
run;
/*
Create the regular DIHD file for 2013, which includes deaths linked to two
years of CHARS.
*/
data dihd.finallink2013;
   set dihd.finallink2013plus;
   if substr(seq_no_enc, 1, 4) in ('2012','2013');
run;
\end{lstlisting}


I found that 41,513 death certificates from 2013 linked
to 147,932 hospital records from 2009-2013.


\subsection{Half-DIHD file for 2009}

Here I create 1 half-DIHD file for 2009, which contains links between
people who died in 2009, and hospitalizations in 2009.

Unlike the other DIHD files I created, this one includes hospital
observation stays.

\begin{lstlisting}[language=sas,caption=create death file for linking]
/*
Step 1. read the death file with names
*/
libname death 'c:\data\death';
libname chars 'c:\data\chars';

data names;
   infile "c:\data\death\deathnames\deathnamesv3.2009" lrecl=290;
   input
      @1   certno     $char10.
      @11  lastname   $char50.
      @61  firstname  $char30.
      @91  middlename $char40.
      @131 suffix     $char4.
      @158 ssnl4      $char4.
      @162 street     $char35.
      @197 city       $char30.
      @227 zipcode    $char5.
      @232 zipplus4   $char4.
      @236 statecode  $char2.
      ;
run;
/*
Step 2. merge with standard death file
*/
proc sort data=names;
   by certno;
run;
proc sort data=death.dea2009
      out=stats(keep=certno age dob sex cnty_res dth_date race_wht race_blk
      race_ami race_asi race_chi race_fil race_gua race_haw race_jap race_kor
      race_opi race_oas race_oth race_sam race_vie hisp zipcode facility fac_type);
   by certno;
run;
/*
combine statistical and name files, and recode race fields to match the reduced
set in the CHARS file (which has only white, black, american indian or alaska
native, asian, hawaiian or other Pacific Islander)
*/
proc format;
   value $stateres
     '01' = 'AL'
     '02' = 'AK'
     '03' = 'AZ'
     '04' = 'AR'
     '05' = 'CA'
     '06' = 'CO'
     '07' = 'CT'
     '08' = 'DE'
     '09' = 'DC'
     '10' = 'FL'
     '11' = 'GA'
     '12' = 'HI'
     '13' = 'ID'
     '14' = 'IL'
     '15' = 'IN'
     '16' = 'IA'
     '17' = 'KS'
     '18' = 'KY'
     '19' = 'LA'
     '20' = 'ME'
     '21' = 'MD'
     '22' = 'MA'
     '23' = 'MI'
     '24' = 'MN'
     '25' = 'MS'
     '26' = 'MO'
     '27' = 'MT'
     '28' = 'NE'
     '29' = 'NV'
     '30' = 'NH'
     '31' = 'NJ'
     '32' = 'NM'
     '33' = 'NY'
     '34' = 'NC'
     '35' = 'ND'
     '36' = 'OH'
     '37' = 'OK'
     '38' = 'OR'
     '39' = 'PA'
     '40' = 'RI'
     '41' = 'SC'
     '42' = 'SD'
     '43' = 'TN'
     '44' = 'TX'
     '45' = 'UT'
     '46' = 'VT'
     '47' = 'VA'
     '48' = 'WA'
     '49' = 'WV'
     '50' = 'WI'
     '51' = 'WY'
     '52' = 'PR'
     '53' = 'VI'
     '54' = 'GU'
     '55' = 'XX'
     '57' = 'XX'
     '59' = 'XX'
     '99' = 'XX'
     '60' = 'AS'
     '69' = 'MP'
      ;
run;
data dwnames(drop=sum_race_asi sum_race_haw race_temp1 race_temp2 race_chi race_fil
          race_gua race_jap race_kor race_opi race_oas race_oth race_sam
          race_vie firsttemp lasttemp middlename hisp firsttemp2 lasttemp2);
   length firstname lastname $ 20 miname hispanic $ 1 lastname_sdx firstname_sdx $ 4
          firsttemp2 lasttemp2 $ 25;
   merge stats(rename=(race_asi=race_temp1 race_haw=race_temp2))
         names(rename=(firstname=firsttemp lastname=lasttemp));
   by certno;
   firsttemp2 = compress(firsttemp," '`-_,.&");
   lasttemp2  = compress(lasttemp," '`-_,.&");
   firstname = substr(firsttemp2,1,20);
   lastname  = substr(lasttemp2,1,20);
   miname    = substr(middlename,1,1);
   sum_race_asi = min(1,(race_chi='Y')+(race_fil='Y')+(race_jap='Y')+(race_kor='Y')+
                    (race_oas='Y')+(race_vie='Y')+(race_temp1='Y'));
   sum_race_haw = min(1,(race_gua='Y')+(race_opi='Y')+(race_sam='Y')+(race_temp2='Y'));

   if sum_race_asi = 0 then race_asi = 'N';
   else                     race_asi = 'Y';
   if sum_race_haw = 0 then race_haw = 'N';
   else                     race_haw = 'Y';
   if race_ami in ('') then race_ami = 'U';
   if race_asi in ('') then race_asi = 'U';
   if race_blk in ('') then race_blk = 'U';
   if race_haw in ('') then race_haw = 'U';
   if race_wht in ('') then race_wht = 'U';
   if ssnL4 = '9999'      then ssnL4 = '';
   select(hisp);
      when('0')                 hispanic = 'N';
      when('1','2','3','4','5') hispanic = 'Y';
      when('','9')              hispanic = 'U';
      end;
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);
   format dob mmddyy10.;
run;
\end{lstlisting}

\begin{lstlisting}[language=sas,caption=Create CHARS file for linking]
data clink09(keep=seq_no_enc staytype adm_date age country countyres dis_date dob firstname
                ssnL4 hispanic hospital lastname miname race_ami race_asi race_blk
                race_haw race_wht sex statecode status zipcode zipplus4
                lastname_sdx firstname_sdx suffix);
   length firstname lastname $ 20 suffix $ 4 lastname_sdx firstname_sdx $ 4 statecode $ 2;
   set chars.chr_r2009(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp))
       chars.chro_r2009(rename=(SSN=ssnL4 firstname=firsttemp lastname=lasttemp));
   if race_ami in ('','R') then race_ami = 'U';
   if race_asi in ('','R') then race_asi = 'U';
   if race_blk in ('','R') then race_blk = 'U';
   if race_haw in ('','R') then race_haw = 'U';
   if race_wht in ('','R') then race_wht = 'U';
   if hispanic in ('','R') then hispanic = 'U';
   if ssnL4 = '9999'      then ssnL4 = '';
/*
remove the suffixes II, III, IV, V, VI, VII, VIII, ESQ, JR, and SR
from lastnames and place them in a separate suffix field.
Used with UB04 data.
*/
   if _N_ = 1 then do;
   	retain __re __reIII;
   	pattern = "/( II| III| IV| V| VI| VII| VIII| ESQ|.JR|.SR)$/i";
   	__re = prxparse(pattern);
   	__reIII = prxparse('/III$/');
   end;
   lasttemp = translate(lasttemp,' ','.,');
   call prxsubstr(__re, TRIM(lasttemp), position, length);
   if position ^= 0 then do;
   	suffix    = substr(lasttemp, position + 1, length - 1);
   	lasttemp2 = substr(lasttemp, 1, position - 1);
   end;
   else lasttemp2 = lasttemp;

   firstname = compress(firsttemp," '`-_,.&");
   lastname  = compress(lasttemp2," '`-_,.&");
   lastname_sdx  = soundex(lastname);
   firstname_sdx = soundex(firstname);
   statecode = stateres;
   if statecode = 'XX' then statecode = '';
run;
\end{lstlisting}


\begin{lstlisting}[language=sas,caption=compute test link scores]
libname dihd 'c:\data\dihd';
/*
For each record, I will evaluate its similarity with each of the other records
by computing a score using the points described above. In the output dataset,
I will keep records that have a score of at least 1.
Maximum score is 112.
*/
data dihd.link2009nonbirthmatch;
   set clink09(rename=(
     age           = c_age
     countyres     = c_cnty_res
     dob           = c_dob
     firstname     = c_firstname
     hispanic      = c_hispanic
     lastname      = c_lastname
     miname        = c_miname
     race_ami      = c_race_ami
     race_asi      = c_race_asi
     race_blk      = c_race_blk
     race_haw      = c_race_haw
     race_wht      = c_race_wht
     sex           = c_sex
     zipcode       = c_zipcode
     firstname_sdx = c_firstname_sdx
     lastname_sdx  = c_lastname_sdx
     ssnl4         = c_ssnl4
     statecode     = c_statecode
     ));
   do i = 1 to 49415;
      set dwnames point=i;
      if (firstname ne c_firstname and lastname ne c_lastname) or
          dob = c_dob then score = 0;
      else score =
      (age           = c_age           and age          ne .)*5  +
      (age           ne c_age          )*(-5) +
      (cnty_res      = c_cnty_res      and cnty_res     ne '')*3  +
      (cnty_res      ne c_cnty_res     )*(-5) +
      (dob           = c_dob           and dob          ne .)*20  +
      (dob           ne c_dob          )*(-20) +
      (month(dob)    = month(c_dob)    and dob          ne .)*3   +
      (month(dob)    ne month(c_dob)   )*(-5)  +
      (day(dob)      = day(c_dob)      and dob          ne .)*4   +
      (day(dob)      ne day(c_dob)     )*(-4)   +
      (year(dob)     = year(c_dob)     and dob          ne .)*4   +
      (year(dob)     ne year(c_dob)    )*(-4)   +
      (firstname     = c_firstname     and firstname    ne '')*10 +
      (firstname     ne c_firstname    )*(-10) +
      (hispanic      = c_hispanic      and hispanic     ne '')*5  +
      (hispanic      ne c_hispanic     )*(-5) +
      (lastname      = c_lastname      and lastname     ne '')*15  +
      (lastname      ne c_lastname     )*(-15) +
      (miname        = c_miname        and miname       ne '')*2  +
      (miname        ne c_miname       )*(-3) +
      (race_ami      = c_race_ami      and race_ami     ne '')*3  +
      (race_ami      ne c_race_ami     )*(-2) +
      (race_asi      = c_race_asi      and race_asi     ne '')*3  +
      (race_asi      ne c_race_asi     )*(-2) +
      (race_blk      = c_race_blk      and race_blk     ne '')*3  +
      (race_blk      ne c_race_blk     )*(-2) +
      (race_haw      = c_race_haw      and race_haw     ne '')*3  +
      (race_haw      ne c_race_haw     )*(-2) +
      (race_wht      = c_race_wht      and race_wht     ne '')*3  +
      (race_wht      ne c_race_wht     )*(-2) +
      (sex           = c_sex           and sex          ne '')*2  +
      (sex           ne c_sex          )*(-20) +
      (zipcode       = c_zipcode       and zipcode      ne '')*3  +
      (zipcode       ne c_zipcode      )*(-2) +
      (firstname_sdx = c_firstname_sdx and firstname_sdx ne '')*2  +
      (firstname_sdx ne c_firstname_sdx)*(-10) +
      (lastname_sdx  = c_lastname_sdx  and lastname_sdx ne '')*4  +
      (lastname_sdx  ne c_lastname_sdx )*(-10) +
      (ssnl4         = c_ssnl4         and ssnl4        ne '')*15  +
      (ssnl4         ne c_ssnl4        )*(-10) +
      (statecode     = c_statecode     and statecode       ne '')*1  +
      (statecode     ne c_statecode    )*(-5) +
      (status = '20' and dth_date = dis_date)*10 +
      (status = '20' and dth_date ne dis_date)*(-10) +
      (status = '20' and facility = substr(hospital,1,3))*5 +
      (status = '20' and facility ne substr(hospital,1,3))*(-10) +
      (dis_date ge dth_date + 2)*(-20)
      ;

      if score ge 1 then output;
      *output;

      end;
run;
proc print data=dihd.link2009nonbirthmatch(obs=21 );
   var score certno firstname c_firstname lastname c_lastname miname c_miname dob c_dob
       ssnL4 c_ssnL4 age c_age sex c_sex cnty_res c_cnty_res statecode c_statecode
       race_ami c_race_ami race_asi c_race_asi race_blk c_race_blk race_haw c_race_haw
       race_wht c_race_wht hispanic c_hispanic;
run;
proc freq data=dihd.link2009nonbirthmatch;
   tables score;
run;
\end{lstlisting}

\begin{lstlisting}[language=sas,caption=write death and CHARS files to csv for R]
/*
the length statements are to ensure fields are in a consistent order
when I read them into R, and the fields are ordered for easiest use
during the classification of the training set.
I delete the records that have no names or SSN (typically these are
deaths that occurred out-of-state).
*/
data dwnames2;
   length certno $ 10 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 cnty_res $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 deathfirst $ 20 deathlast $ 20;
   set dwnames;
   keep certno cnty_res dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date deathfirst deathlast suffix
        ;
   if upcase(firstname) in (
      'B ',
      'BABY ',
      'BABY 1 BOY',
      'BABY 1 GIRL',
      'BABY 2 ',
      'BABY 2 BOY',
      'BABY 2 GIRL',
      'BABY B ',
      'BABY BOY ',
      'BABY BOY 1',
      'BABY BOY 2',
      'BABY BOY A',
      'BABY BOY B',
      'BABY G',
      'BABY GIR ',
      'BABY GIRL ',
      'BABY GIRL 1',
      'BABY GIRL A',
      'BABY GIRL STILL',
      'BABY ONE',
      'BABYBOY ',
      'BABYGIRL ',
      'BABYMALE',
      'BABYONE BOY',
      'BOY ',
      'BOY 2',
      'BOY 3',
      'BOY A',
      'BOY B ',
      'BOYA',
      'BOYB',
      'BOYC',
      'BOY ONE',
      'BOY TWIN A',
      'BOY-ONE ',
      'GIRL ',
      'GIRL B ',
      'GIRL C ',
      'GIRL-ONE'
      )
      then firstname = '';
   if miname in ('(','-','0','1','2','3') then middlename = '';
   deathfirst = firstname;
   deathlast  = lastname;
   if firstname = '' and lastname = '' then delete;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if zipplus4 in ('0000','9999') then zipplus4 = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 in ('0001','1111','6789','9999') then ssnL4 = '';
   format dth_date mmddyy10.;
run;
proc export data=dwnames2
   outfile = "c:\data\DIHD\death2009.csv"
   dbms = csv
   replace
   ;
run;

data clink2;
   length seqno $ 11 dob 8 firstname $ 20 miname $ 1 lastname $ 20
          suffix $ 4 ssnL4 $ 4 sex $ 1 zipcode $ 5 countyres $ 2 facility $ 3
          dth_date 8 hispanic race_wht race_blk race_ami race_asi
          race_haw $ 1 statecode $ 2 charslast $ 20 charsfirst $ 20;
   set clink09;
   seqno = seq_no_enc||staytype;
   if status = '20' then do;
      facility = substr(hospital,1,3);
      dth_date = dis_date;
      end;
   else do;
      facility = '';
      dth_date = .;
      end;
   if upcase(firstname) in (
      'B ',
      'BABY ',
      'BABY 1 BOY',
      'BABY 1 GIRL',
      'BABY 2 ',
      'BABY 2 BOY',
      'BABY 2 GIRL',
      'BABY B ',
      'BABY BOY ',
      'BABY BOY 1',
      'BABY BOY 2',
      'BABY BOY A',
      'BABY BOY B',
      'BABY G',
      'BABY GIR ',
      'BABY GIRL ',
      'BABY GIRL 1',
      'BABY GIRL A',
      'BABY GIRL STILL',
      'BABY ONE',
      'BABYBOY ',
      'BABYGIRL ',
      'BABYMALE',
      'BABYONE BOY',
      'BOY ',
      'BOY 2',
      'BOY 3',
      'BOY A',
      'BOY B ',
      'BOYA',
      'BOYB',
      'BOYC',
      'BOY ONE',
      'BOY TWIN A',
      'BOY-ONE ',
      'GIRL ',
      'GIRL B ',
      'GIRL C ',
      'GIRL-ONE'
      )
      then firstname = '';
   charsfirst = firstname;
   charslast = lastname;
   if hispanic = 'U' then hispanic = '';
   if race_wht = 'U' then race_wht = '';
   if race_blk = 'U' then race_blk = '';
   if race_ami = 'U' then race_ami = '';
   if race_asi = 'U' then race_asi = '';
   if race_haw = 'U' then race_haw = '';
   if sex = 'U' then sex = '';
   if statecode = '99' then statecode = '';
   if zipcode = '99999' then zipcode = '';
   if zipplus4 in ('0000','9999') then zipplus4 = '';
   if facility in ('899','999') then facility = '';
   if ssnL4 in ('0001','1111','6789','9999') then ssnL4 = '';
   keep seqno countyres dob firstname hispanic lastname miname race_ami
   	race_asi race_blk race_haw race_wht sex ssnL4 statecode
        zipcode facility dth_date charsfirst charslast suffix;
   format dth_date mmddyy10.;
run;
proc export data=clink2
   outfile = "c:\data\DIHD\chars2009.csv"
   dbms = csv
   replace
   ;
run;
\end{lstlisting}

\bfs
\begin{verbatim}
%<<>>=
library(plyr); library(dplyr); library(magrittr)
library(RecordLinkage)

death2009 <- read.csv("../../../data/DIHD/death2009.csv",colClasses=c(rep("character",18)),
                      col.names=c("certno","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "death.first","death.last"))
death2009$firstname.sdx <- soundex(death2009$firstname)
death2009$lastname.sdx  <- soundex(death2009$lastname)

chars09 <- read.csv("../../../data/DIHD/chars2009.csv",colClasses=c(rep("character",18)),
                      col.names=c("seq_no_enc","dob","firstname","miname","lastname","suffix",
                      "ssnL4","sex","zipcode","county","facility","deathdate","hispanic",
                      "race.wht","race.blk","race.ami","race.asi","race.haw","statecode",
                      "chars.last","chars.first"))
chars09$firstname.sdx <- soundex(chars09$firstname)
chars09$lastname.sdx  <- soundex(chars09$lastname)

pairs2009 <- compare.linkage(death2009,chars09,blockfld=c(2),exclude=c(1))

# calculate Fellegi-Sunter weights
pairs2009 <- fsWeights(pairs2009)

# use the model that was trained on the 2011 data.
load("model2011.RData")
result2009.bag <- classifySupv(model2011.bag,newdata=pairs2009)

ggplot(data.frame(Wdata=result2009.bag$Wdata, prediction=result2009.bag$prediction)) +
       geom_density(aes(Wdata),adjust=5, size=1.2)

ggplot(data.frame(Wdata=result2009.bag$Wdata, prediction=result2009.bag$prediction)) +
       geom_density(aes(Wdata, color=prediction),adjust=5, size=1.2)

table(cut(result2009.bag$Wdata, breaks=c(-72, -10, 0, 20, 30, 40, 50, 60, 70, 100, 180)),
      result2009.bag$prediction)

                  N       P       L
  (-72,-10] 1061093       0      13
  (-10,0]      5235       0      22
  (0,20]       5919       0     167
  (20,30]       606       0     307
  (30,40]        88       0     574
  (40,50]        17       0     995
  (50,60]         2       0    2525
  (60,70]         0       0    2744
  (70,100]        0       0   23372
  (100,180]       0       0   26010

# I chose to review links with a weight of 40 or less, and non-links
# with weights above 20.
manualreview2009 <- result2009.bag[(result2009.bag$prediction == 'L' &
                        result2009.bag$Wdata <= 40) | (result2009.bag$prediction == 'N' &
                        result2009.bag$Wdata > 20)]

# there is a bug in the v 0.4-6 and v 0.4-7 editMatch function on
# Windows, so that it does not save edits
# manualreview2009 <- editMatch(manualreview2009)
# so I have to do this:
# (this does not work if I assign a new variable first, and try to fill it in!!)
reviewpairs2009 <- getPairs(manualreview2009, sort=F)
reviewpairs2009.edited <- edit(reviewpairs2009)

# get the is_match variable into the manualreview2009 object
match1 <- reviewpairs2009.edited[seq(from=1, to=5386, by=3), c(1,26)]
match2 <- reviewpairs2009.edited[seq(from=2, to=5387, by=3), 1]
match <- data.frame(id1=as.integer(match1[,1]), id2=as.integer(match2), is_match=match1[,2])

# although I think match and the pairs frame in manualreview2009 are in the
# same row order, I will merge on id1 and id2 to make sure I get it right

newpairs <- merge(manualreview2009$pairs[,c(1:24)], match, by = c('id1','id2'),
                  all=T, sort=F)

manualreview2009$pairs_is_match <- newpairs$is_match
%@
\end{verbatim}
\efs


\bfs
\begin{verbatim}
%<<>>=
library(plyr); library(dplyr); library(magrittr)
library(RecordLinkage)

manualreview2009.b <- manualreview2009
for(i in 1:length(manualreview2009$prediction)) {
      manualreview2009.b$prediction[i] <- if(manualreview2009$pairs$is_match[i] == 0) 'N' else 'L'
}

predictions.2009.a <- result2009.bag$prediction
index.r <- as.numeric(row.names(manualreview2009.b$pairs))
predictions.2009.b <- predictions.2009.a
predictions.2009.b[index.r] <- manualreview2009.b$prediction

# combine death and CHARS row numbers with the predictions
newresults2009 <- cbind(result2009.bag$pairs[,c(1,2)],predictions.2009.b)

# get death certificate numbers and CHARS seq number (seq_no_enc)
deathcerts <- result2009.bag$data1[newresults2009[,1],1]
charsseq <- result2009.bag$data2[newresults2009[,2],1]
newresults2009.b <- data.frame(deathcerts,charsseq,predictions.2009.b)

%@
\end{verbatim}
\efs

\subsubsection{Manual review of records with non-matching birthdates}

Now I get a file of the record pairs which had a high matching score (15 or higher) with
non-matching birthdates, and export them to an Excel spreadsheet to conduct a manual review on
them. I chose 10 as the cutoff score for manual review because that provides a reasonable number of
records for review (about 1,400), but I think it includes nearly all the records that have
much chance of being classified a true match.

\begin{lstlisting}[language=sas,caption=get non-matching birthdate high scorers for manual review]
libname dihd 'c:\data\dihd';
data review1;
   set dihd.link2009nonbirthmatch(where=(score ge 10));
run;
proc sort data=review1;
   by score;
run;
data review2(keep=dcert cseq bd fname mi lname ssn sx hosp dd zip county hisp rw
                  rb ram ras rh sc);
   length dcert $ 10 cseq $ 11 bd 8 fname $ 20 mi $ 1 lname $ 20 ssn $ 4 sx $ 1
          hosp $ 3 dd 8 zip $ 5 county $ 2 hisp rw rb ram ras rh $ 1
          sc 8;
   set review1;
   format bd dd mmddyy10.;

   dcert = certno;
   cseq = seq_no_enc||staytype;
   bd = dob;
   fname = firstname;
   mi = miname;
   lname = lastname;
   ssn = ssnL4;
   sx = sex;
   hosp = facility;
   dd = dth_date;
   zip = zipcode;
   county = cnty_res;
   hisp = hispanic;
   rw = race_wht;
   rb = race_blk;
   ram = race_ami;
   ras = race_asi;
   rh = race_haw;
   sc = score;
   output;

   bd = c_dob;
   fname = c_firstname;
   mi = c_miname;
   lname = c_lastname;
   ssn = c_ssnL4;
   sx = c_sex;
   if status = 20 or dis_date ge dth_date then do;
      hosp = hospital;
      dd = dis_date;
      end;
   else do;
      hosp = '';
      dd = .;
      end;
   zip = c_zipcode;
   county = c_cnty_res;
   hisp = c_hispanic;
   rw = c_race_wht;
   rb = c_race_blk;
   ram = c_race_ami;
   ras = c_race_asi;
   rh = c_race_haw;
   sc = .;
   output;

   bd = .;
   fname = '';
   mi = '';
   lname = '';
   ssn = '';
   sx = '';
   hosp = '';
   dd = .;
   zip = '';
   county = '';
   hisp = '';
   rw = '';
   rb = '';
   ram = '';
   ras = '';
   rh = '';
   sc = .;
   output;
run;
proc export data=review2
   outfile = "c:\user\projects\Death-CHARSlink\manreview2009.xls"
   dbms = excel5
   replace
   ;
run;
/*
read the reviewed links
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2009_done.xls"
   dbms = xls
   replace
   ;
run;
\end{lstlisting}

Now I need to combine the links from three sources: the machine
learning results, the manual review of those results, and the manual
coding of the records on which birthdate didn't match. After combining
those links, I need to check whether there are any hospitalization
records linked to more than one death record, and if so, adjudicate
those links manually. Then I can create the final linked file.

\bfs
\begin{verbatim}
#create file containing only the linked pairs
links2009 <- newresults2009.b[newresults2009.b$predictions.2009.b=='L',]

write.csv(links2009,file="c:/data/dihd/links2009.csv",row.names=F)

save(chars09, death2009, links2009, manualreview2009, result2009.bag, model2011.bag,
     reviewpairs2009.edited, file="Classifier2009.RData")

\end{verbatim}
\efs

\begin{lstlisting}[language=sas,caption=create final expanded linked file for 2012]
libname dihd 'c:\data\dihd';
proc import out=links0
   file = "c:\data\dihd\links2009.csv"
   dbms = csv
   replace
   ;
run;
data links1(keep=certno seq_no_enc staytype predict);
   length certno seq_no_enc $ 10 staytype predict $ 1;
   set links0;
   certno     = substr(deathcerts,1,10);
   seq_no_enc = substr(charsseq,1,10);
   staytype   = substr(charsseq,11,1);
   predict    = substr(predictions_2009_b,1,1);
run;
/*
read in the reviewed links for pairs which had high scores but
   non-matching birthdates
*/
proc import out=review3
   file = "c:\user\projects\Death-CHARSlink\manreview2009_done.xls"
   dbms = xls
   replace
   ;
run;
data mlinks1(keep=certno seq_no_enc staytype sc link);
   length certno seq_no_enc $ 10 staytype $ 1;
   retain i 0;
   set review3(rename=(match=link));
   certno = substr(dcert,1,10);
   seq_no_enc = substr(cseq,1,10);
   staytype = substr(cseq,11,1);
   i+1;
   if i = 1 then output;
   if i = 3 then i = 0;
run;
proc freq data=mlinks1;
   tables sc*link/norow nocol nopercent;
run;
/*
this table shows the strong relation between score and link status
    The SAS System                                         08:37 Tuesday, January 27, 2015  20

          The FREQ Procedure

          Table of sc by link

  sc(sc)     link(match)

  Frequency|       0|       1|  Total
  ---------+--------+--------+
        10 |      5 |      4 |      9
  ---------+--------+--------+
        11 |     10 |      3 |     13
  ---------+--------+--------+
        12 |    228 |      4 |    232
  ---------+--------+--------+
        13 |      1 |      0 |      1
  ---------+--------+--------+
        14 |    171 |      0 |    171
  ---------+--------+--------+
        15 |      3 |      8 |     11
  ---------+--------+--------+
        16 |      1 |      2 |      3
  ---------+--------+--------+
        17 |     19 |      4 |     23
  ---------+--------+--------+
        18 |      1 |     17 |     18
  ---------+--------+--------+
        19 |     19 |      0 |     19
  ---------+--------+--------+
        20 |      2 |     14 |     16
  ---------+--------+--------+
        21 |      0 |      3 |      3
  ---------+--------+--------+
        22 |     40 |      2 |     42
  ---------+--------+--------+
        23 |      0 |      7 |      7
  ---------+--------+--------+
        24 |      4 |      1 |      5
  ---------+--------+--------+
        25 |      2 |     30 |     32
  ---------+--------+--------+
        27 |      5 |      3 |      8
  ---------+--------+--------+
        28 |      0 |      7 |      7
  ---------+--------+--------+
        29 |      3 |      4 |      7
  ---------+--------+--------+
        30 |      2 |     35 |     37
  ---------+--------+--------+
        31 |      0 |      1 |      1
  ---------+--------+--------+
        32 |      0 |      7 |      7
  ---------+--------+--------+
        33 |      0 |      6 |      6
  ---------+--------+--------+
        34 |      0 |      3 |      3
  ---------+--------+--------+
        35 |      1 |     17 |     18
  ---------+--------+--------+
        36 |      0 |      2 |      2
  ---------+--------+--------+
        37 |      0 |      6 |      6
  ---------+--------+--------+
        38 |      0 |      5 |      5
  ---------+--------+--------+
        39 |      0 |      1 |      1
  ---------+--------+--------+
        40 |      0 |     37 |     37
  ---------+--------+--------+
        42 |      0 |     16 |     16
  ---------+--------+--------+
        43 |      0 |      5 |      5
  ---------+--------+--------+
        44 |      0 |      4 |      4
  ---------+--------+--------+
        45 |      0 |     47 |     47
  ---------+--------+--------+
        46 |      0 |      3 |      3
  ---------+--------+--------+
        47 |      0 |      6 |      6
  ---------+--------+--------+
        48 |      0 |      2 |      2
  ---------+--------+--------+
        49 |      0 |      3 |      3
  ---------+--------+--------+
        50 |      0 |     75 |     75
  ---------+--------+--------+
        52 |      0 |      7 |      7
  ---------+--------+--------+
        53 |      0 |     15 |     15
  ---------+--------+--------+
        54 |      0 |      1 |      1
  ---------+--------+--------+
        55 |      0 |    150 |    150
  ---------+--------+--------+
        57 |      0 |      5 |      5
  ---------+--------+--------+
        58 |      0 |      2 |      2
  ---------+--------+--------+
        59 |      0 |      1 |      1
  ---------+--------+--------+
        60 |      0 |     63 |     63
  ---------+--------+--------+
        62 |      0 |      3 |      3
  ---------+--------+--------+
        63 |      0 |      8 |      8
  ---------+--------+--------+
        65 |      0 |    157 |    157
  ---------+--------+--------+
        67 |      0 |      3 |      3
  ---------+--------+--------+
        68 |      0 |      1 |      1
  ---------+--------+--------+
        69 |      0 |      1 |      1
  ---------+--------+--------+
        70 |      0 |     29 |     29
  ---------+--------+--------+
        72 |      0 |      1 |      1
  ---------+--------+--------+
        75 |      0 |     14 |     14
  ---------+--------+--------+
        78 |      0 |      5 |      5
  ---------+--------+--------+
        80 |      0 |     37 |     37
  ---------+--------+--------+
  Total         517      897     1414
*/
data mlinks2(keep=certno seq_no_enc staytype);
   set mlinks1(where=(link=1));
run;
/*
combine links from the R-matched file with the links from the mis-matched birth date records

Then check if any CHARS records linked to more than one death certificate
*/
data link2009;
   set links1(drop=predict) mlinks2;
run;
/*
check for CHARS records that linked to more than one death certificate

There are 8
*/
proc freq data=link2009 noprint;
   tables seq_no_enc*staytype/out=charslist;
run;
data mults1(drop=percent);
   set charslist(where=(count ge 2));
run;
proc sort data=link2009;
   by seq_no_enc staytype;
run;
data mults2;
   merge link2009 mults1(in=inmult);
   by seq_no_enc staytype;
   if inmult;
run;
/*
link with the CHARS and death files in turn to get the info
*/
proc sort data=clink09;
   by seq_no_enc staytype;
run;
data mults3;
   merge mults2(in=inmults) clink09(rename=(
     age           = c_age
     countyres     = c_cnty_res
     dob           = c_dob
     firstname     = c_firstname
     hispanic      = c_hispanic
     lastname      = c_lastname
     miname        = c_miname
     race_ami      = c_race_ami
     race_asi      = c_race_asi
     race_blk      = c_race_blk
     race_haw      = c_race_haw
     race_wht      = c_race_wht
     sex           = c_sex
     zipcode       = c_zipcode
     firstname_sdx = c_firstname_sdx
     lastname_sdx  = c_lastname_sdx
     ssnl4         = c_ssnl4
     statecode     = c_statecode
     ));
   by seq_no_enc staytype;
   if inmults;
run;
proc sort data=dwnames;
   by certno;
run;
proc sort data=mults3;
   by certno;
run;
data mults4;
   merge mults3(in=inmult) dwnames;
   by certno;
   if inmult;
run;
proc sort data=mults4;
   by seq_no_enc staytype;
run;
proc print data=mults4 headings=h;
   by seq_no_enc staytype;
run;
/*
here are the fixes, which I hard code below.
Fixes:
The SAS System                                         08:37 Tuesday, January 27, 2015  29

Obs    seq_no_enc    staytype      certno      link

  1    2009055581       1        2009007737     y
  2    2009055581       1        2009009434     n
  3    2009059687       1        2009008800     y
  4    2009059687       1        2009061444     n
  5    2009096680       1        2009008800     y
  6    2009096680       1        2009061444     n
  7    2009226872       1        2009008800     y
  8    2009226872       1        2009061444     n
  9    2009448040       1        2009008800     y
 10    2009448040       1        2009061444     n
 11    2009517160       1        2009002042     n
 12    2009517160       1        2009002043     y
 13    2009550384       1        2009007737     n
 14    2009550384       1        2009009434     y
 15    2009632624       1        2009002042     y
 16    2009632624       1        2009002043     n
*/
data link2009fixed;
   set link2009;
   if seq_no_enc = '2009055581' and staytype = '1' and certno = '2009009434' then delete;
   if seq_no_enc = '2009059687' and staytype = '1' and certno = '2009061444' then delete;
   if seq_no_enc = '2009096680' and staytype = '1' and certno = '2009061444' then delete;
   if seq_no_enc = '2009226872' and staytype = '1' and certno = '2009061444' then delete;
   if seq_no_enc = '2009448040' and staytype = '1' and certno = '2009061444' then delete;
   if seq_no_enc = '2009517160' and staytype = '1' and certno = '2009002042' then delete;
   if seq_no_enc = '2009550384' and staytype = '1' and certno = '2009007737' then delete;
   if seq_no_enc = '2009632624' and staytype = '1' and certno = '2009002043' then delete;
run;
/*
create final linked file
*/
data dihd.finallink2009;
   set link2009fixed;
run;

proc freq data=dihd.finallink2009 noprint;
   tables certno/out=dcertlist;
run;
\end{lstlisting}


I found that 29,771 death certificates from 2009 linked
to 57,595 hospital records from 2009.



\end{document}
